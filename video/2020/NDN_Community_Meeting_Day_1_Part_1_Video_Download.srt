1
00:00:04,702 --> 00:00:11,470
Good morning, everyone, and
welcome to the NDN Community Meeting,

2
00:00:11,470 --> 00:00:17,089
hosted by NIST as a two-day
virtual event with an exciting

3
00:00:17,089 --> 00:00:22,021
agenda made up of seven
technical sessions, two or

4
00:00:22,021 --> 00:00:27,790
three panels, and
the posters and demonstration.

5
00:00:27,790 --> 00:00:32,490
The agenda details and abstracts of
all presentations are available under

6
00:00:32,490 --> 00:00:38,876
the Agenda tab on the Events page,
as shown here, in this slide.

7
00:00:38,876 --> 00:00:43,980
And the NDN Community Meeting is organized

8
00:00:43,980 --> 00:00:48,490
in collaboration with NIST and
the NDN Consortium.

9
00:00:50,180 --> 00:00:55,853
And as some of you may know,
this year, we completed the transfer

10
00:00:55,853 --> 00:01:00,405
of the NDN consortium
management from UCLA to NIST.

11
00:01:00,405 --> 00:01:05,373
It happened earlier this year, and the
consortium will play the role of single

12
00:01:05,373 --> 00:01:09,890
point of collaborative participation for
industry, universities,

13
00:01:09,890 --> 00:01:14,257
government agencies and others
interested in NDN to be connected and

14
00:01:14,257 --> 00:01:17,440
to participate in NDN research and
development.

15
00:01:18,910 --> 00:01:23,220
It will also provide general support
of the NDN effort especially for

16
00:01:23,220 --> 00:01:26,740
outreach communication and
open source development.

17
00:01:28,440 --> 00:01:33,260
This will work with the NDN community
to address and standardize NDN and

18
00:01:33,260 --> 00:01:36,550
have the industry evaluate the technology.

19
00:01:36,550 --> 00:01:39,260
And as some of you know,
we have a number of efforts,

20
00:01:39,260 --> 00:01:44,380
one of them being the NDN-DPDK
forwarder that some of you are using,

21
00:01:44,380 --> 00:01:48,930
and we have some ongoing work on
NDN measurement and management.

22
00:01:51,050 --> 00:01:55,250
A template CRADA, Cooperative Research and
Development Agreement, is ready.

23
00:01:55,250 --> 00:01:59,130
It has been developed and
signed by NIST and UCLA.

24
00:01:59,130 --> 00:02:02,710
And I'd like to take this
opportunity to thank the UCLA

25
00:02:02,710 --> 00:02:06,668
team who took care of the consortium
management when it was hosted at UCLA,

26
00:02:06,668 --> 00:02:10,310
in particular Lixia Zhang and Jeff Burke.

27
00:02:11,370 --> 00:02:13,800
And I think Jeff is on the line and

28
00:02:13,800 --> 00:02:17,660
then the probably wants
to say a word here, Jeff?

29
00:02:19,060 --> 00:02:20,466
>> Sure, yeah, thanks.

30
00:02:20,466 --> 00:02:24,436
So the consortium,
the mission is essentially the same

31
00:02:24,436 --> 00:02:29,419
as the consortium that was started
by the academic institutions, but

32
00:02:29,419 --> 00:02:34,318
with the hope that by hosting it at NIST,
it will have sorta increased

33
00:02:34,318 --> 00:02:39,132
administrative stability and
reached the work with government and

34
00:02:39,132 --> 00:02:44,310
industry partners, as well as number
of nonprofits and universities.

35
00:02:44,310 --> 00:02:49,210
So we're excited to complete
the transfer and ready to

36
00:02:49,210 --> 00:02:54,800
start publishing new information about the
consortium and get organizations aboard.

37
00:02:54,800 --> 00:02:59,890
Based on feedback, we've created a new
fee structure for the voting members that

38
00:02:59,890 --> 00:03:04,870
wish to be able to voting key decisions
regarding the direction of the consortium

39
00:03:04,870 --> 00:03:09,530
that's listed here on the slides including
a reduction of the fee remission in this

40
00:03:09,530 --> 00:03:14,550
pilot fiscal year in light of
the challenging global circumstances.

41
00:03:14,550 --> 00:03:19,680
Also, there's an opportunity for
especially oriented towards nonprofits and

42
00:03:19,680 --> 00:03:24,410
universities to provide in-kind
contributions of equivalent value that

43
00:03:24,410 --> 00:03:30,740
allow voting participation
through in-kind contributions.

44
00:03:30,740 --> 00:03:37,409
It's also a mechanism for
industry partners to provide services or

45
00:03:37,409 --> 00:03:43,502
support to the consortium for
some reduction of the cash fee.

46
00:03:43,502 --> 00:03:46,406
So hopefully this provides
more flexibility for

47
00:03:46,406 --> 00:03:49,388
a large number of
organizations to participate.

48
00:03:49,388 --> 00:03:50,610
If we can go to the next slide.

49
00:03:52,370 --> 00:03:57,910
So hopefully in time for a ACM ICN,
you should see the release of

50
00:03:57,910 --> 00:04:02,991
a new identity for the consortium,
as well as a civilian

51
00:04:02,991 --> 00:04:07,820
friendly website that makes the case for
the the technology,

52
00:04:07,820 --> 00:04:12,112
the consortium, the ongoing research
that's continuing around the world.

53
00:04:12,112 --> 00:04:17,420
And so, this is a little bit of a teaser
of the identity and we should have that

54
00:04:17,420 --> 00:04:20,350
up for people to start taking a look
at towards the end of the month.

55
00:04:20,350 --> 00:04:22,330
So we're excited about that, as well.

56
00:04:22,330 --> 00:04:23,460
That's it for me, thank you.

57
00:04:24,640 --> 00:04:26,210
>> Thank you, Jeff.

58
00:04:26,210 --> 00:04:28,150
Back to the agenda.

59
00:04:28,150 --> 00:04:34,580
For the posters and
demo session this afternoon, we have seven

60
00:04:34,580 --> 00:04:39,680
with two groups in the same BlueJeans Room
because they have the same presenter.

61
00:04:39,680 --> 00:04:44,300
So we have a total of six BlueJeans
links as shown in this table.

62
00:04:44,300 --> 00:04:49,110
They will each have a short presentation
at the lightning talk session.

63
00:04:49,110 --> 00:04:53,950
But four of them have provided the longer
pre-recorded version of the thoughts

64
00:04:53,950 --> 00:04:57,110
that we made available
online at this link here.

65
00:04:58,440 --> 00:05:01,050
And if you go to that link,

66
00:05:01,050 --> 00:05:07,550
you will see the four videos in
the browser window as shown on the left.

67
00:05:07,550 --> 00:05:10,460
And when you click on one of them,
the video will be streamed

68
00:05:10,460 --> 00:05:14,330
over at the end without installing
any software on your laptop.

69
00:05:14,330 --> 00:05:18,950
It uses the video streaming platform
iViSa, iCN Video Streaming Application,

70
00:05:18,950 --> 00:05:24,640
developed at University of Arizona, which
runs over the global and the untested.

71
00:05:24,640 --> 00:05:29,210
And we should probably try to run
NDN next time over NDN, as well.

72
00:05:30,790 --> 00:05:38,943
For panels, we have two today moderated
by NDN co-chairs Christos and Kathy.

73
00:05:38,943 --> 00:05:43,443
And tomorrow we have one moderated
by Christian on lessons learned over

74
00:05:43,443 --> 00:05:44,720
the last ten years.

75
00:05:46,700 --> 00:05:51,040
As many of you know, this year 2020
is the ten-year anniversary of

76
00:05:51,040 --> 00:05:56,739
the NSF Funded Agent Project,
which started years ago in 2010.

77
00:05:58,430 --> 00:06:02,380
Before I hand it to Susmit for
session one,

78
00:06:02,380 --> 00:06:08,770
I'd like to thank the co-chairs,
Christos and Kathy,

79
00:06:08,770 --> 00:06:15,510
the panel chairs, and the panelists, the
session chairs, and all the presenters.

80
00:06:15,510 --> 00:06:23,230
And thanks also to Debbie and for
their help with the local arrangement.

81
00:06:23,230 --> 00:06:26,100
Finally, just one reminder about Q&A.

82
00:06:26,100 --> 00:06:30,940
You could use either the chat
window shown in this picture,

83
00:06:30,940 --> 00:06:33,790
or the raise hand feature.

84
00:06:33,790 --> 00:06:39,590
And the chair will pick from both
the chat and the raise hand list.

85
00:06:41,910 --> 00:06:46,430
With that,
I think it's time to hand it to Susmit for

86
00:06:46,430 --> 00:06:49,245
session one on NDN Trial Deployments.

87
00:06:49,245 --> 00:06:51,970
Susmit?

88
00:06:51,970 --> 00:06:52,820
>> Thank you, Lofti.

89
00:06:52,820 --> 00:06:54,490
Good morning, everyone.

90
00:06:54,490 --> 00:06:59,881
My name is Susmit Shannigrahi, I'm
an assistant professor at Tennessee Tech.

91
00:06:59,881 --> 00:07:02,410
So in this session,
we're going to have four talks.

92
00:07:03,482 --> 00:07:07,500
We are thinking about 10 to 12 minutes for
the talks and then 2 minutes for

93
00:07:07,500 --> 00:07:09,110
discussions.

94
00:07:09,110 --> 00:07:13,520
I'll be giving a reminder
before two minutes.

95
00:07:14,880 --> 00:07:22,730
So let me introduce this first speaker,
Dr. Alex Feltus from Clemson University.

96
00:07:22,730 --> 00:07:26,931
He received a BAC in biochemistry
from Auburn University,

97
00:07:26,931 --> 00:07:29,710
served in Peace Corps in Fiji Islands.

98
00:07:29,710 --> 00:07:33,220
And then completed advanced
training in Biomedical Sciences at

99
00:07:33,220 --> 00:07:34,230
Vanderbilt and Emory.

100
00:07:35,250 --> 00:07:38,950
He has performed research in artificial
intelligence, bioinformatics,

101
00:07:38,950 --> 00:07:44,245
cyberinfrastructure, high performance
computing, network biology, tumor biology,

102
00:07:44,245 --> 00:07:51,002
agrigenomics, system genomics,
and bioenergy feedstock genetics.

103
00:07:51,002 --> 00:07:55,570
Currently, he's a professor in Clemson
University's Department of genetics and

104
00:07:55,570 --> 00:08:00,390
biochemistry and
co-founder of practice AI, LLC.

105
00:08:00,390 --> 00:08:05,060
He will be sharing his experience in
publishing genomics data sets into an NDN

106
00:08:05,060 --> 00:08:08,450
testbed and
integrating with cloud workflows.

107
00:08:10,410 --> 00:08:11,871
Alex, please.

108
00:08:15,789 --> 00:08:17,014
>> Hey, can you see my slides?

109
00:08:21,216 --> 00:08:22,547
Is it good?

110
00:08:22,547 --> 00:08:24,455
>> Yes.

111
00:08:24,455 --> 00:08:26,744
>> Hey everybody, so yeah,
thanks for having me here.

112
00:08:26,744 --> 00:08:28,910
This is an honor actually
to be the first speaker,

113
00:08:28,910 --> 00:08:30,569
that's never happened to me before.

114
00:08:30,569 --> 00:08:32,023
That's pretty cool.

115
00:08:32,023 --> 00:08:34,200
But so I'm an end user, I'm a biologist.

116
00:08:34,200 --> 00:08:37,911
I'm trying to understand lots
of different biological things.

117
00:08:37,911 --> 00:08:42,176
I have an interest in cancer biology and
agricultural genomics too, a lot for

118
00:08:42,176 --> 00:08:44,551
food security and health, human health.

119
00:08:44,551 --> 00:08:46,836
They're both really important for
human health.

120
00:08:46,836 --> 00:08:51,124
And to do my work, I have to use, I'm
working at the terascale, petascale, now,

121
00:08:51,124 --> 00:08:54,251
and I'll be working at the exascale
I think before I retire,

122
00:08:54,251 --> 00:08:56,550
given the exponential growth of data sets.

123
00:08:56,550 --> 00:08:59,800
So NDN to me is a really important

124
00:09:01,080 --> 00:09:05,660
layer of storage where you can
have data accessed by name and

125
00:09:05,660 --> 00:09:09,640
not all the vagaries of
repositories that you have to

126
00:09:09,640 --> 00:09:12,660
understand how to navigate to be able
to get the data in the first place.

127
00:09:12,660 --> 00:09:16,920
So anyway, this is an incredible
opportunity to be part of this

128
00:09:16,920 --> 00:09:17,600
development.

129
00:09:17,600 --> 00:09:22,240
I think it's critical for
genomics and of course, other fields.

130
00:09:22,240 --> 00:09:25,628
My lab is, I just love biology.

131
00:09:25,628 --> 00:09:28,655
I'm sort of attracted to chaos,
I think, and I just keep,

132
00:09:28,655 --> 00:09:30,330
see how far I can expand things.

133
00:09:30,330 --> 00:09:34,150
But I study plants, animals,
vertebrates, and angiosperms.

134
00:09:34,150 --> 00:09:37,531
And these are some of the organisms
that I've studied over the years,

135
00:09:37,531 --> 00:09:38,972
if I can get a pointer up here.

136
00:09:43,453 --> 00:09:46,829
And again, to do all this work, we have
to do a lot of algorithm development.

137
00:09:46,829 --> 00:09:48,329
We do a lot of workflow engineering.

138
00:09:48,329 --> 00:09:49,610
We're doing a lot of stuff in the cloud.

139
00:09:49,610 --> 00:09:54,348
We have to understand CUDA and
we have to understand bioformatics and

140
00:09:54,348 --> 00:09:57,704
all sorts of stuff to be
able to get our work done.

141
00:09:57,704 --> 00:10:01,259
Because the problem is that
biological measurements now,

142
00:10:01,259 --> 00:10:04,490
DNA sequencers are pushing
us towards the exascale.

143
00:10:04,490 --> 00:10:07,886
We're in the terascale,
most biologists are now for measurement.

144
00:10:07,886 --> 00:10:11,318
And most people don't know how to deal
with terascale when there's a terabyte of

145
00:10:11,318 --> 00:10:13,666
hard drive space on their laptops.

146
00:10:13,666 --> 00:10:17,830
So in my research we're using a lot of
AI right now, actually a lot of image

147
00:10:17,830 --> 00:10:20,718
analysis techniques to be able to
deal with gene expression data.

148
00:10:20,718 --> 00:10:24,800
And there's a recent paper we published
where we're actually taking data

149
00:10:24,800 --> 00:10:28,686
from patients and integrating it with
other data sets like tumor data,

150
00:10:28,686 --> 00:10:31,617
and in this case,
kidney cancer data specifically.

151
00:10:31,617 --> 00:10:34,574
And actually tomorrow at Clemson,
there's a speaker, the patient,

152
00:10:34,574 --> 00:10:37,710
is gonna be presenting at our
department seminar about our work.

153
00:10:37,710 --> 00:10:41,689
Together, he's a collaborator that
we're trying to draw targets for him.

154
00:10:41,689 --> 00:10:45,325
So we do a lot of that kinda work, a lot
of personalized precision medicine work,

155
00:10:45,325 --> 00:10:47,910
and with protected data sets and
unprotected data sets.

156
00:10:47,910 --> 00:10:52,164
And we also do a lot of work trying to
understand root biology and how roots will

157
00:10:52,164 --> 00:10:56,171
fix nitrogen from the air with
a symbiotic relationship with bacteria.

158
00:10:56,171 --> 00:10:58,300
This is an NSF-funded project.

159
00:10:58,300 --> 00:11:02,249
And I'm also very interested in
training people how to use clouds or

160
00:11:02,249 --> 00:11:04,822
HPC in cloud systems to
get their work done.

161
00:11:04,822 --> 00:11:09,115
And I have a company called Practice AI,
where we actually have scalable data

162
00:11:09,115 --> 00:11:12,560
intensive computing training and
we're open for business.

163
00:11:13,830 --> 00:11:16,725
This is a big part of biology now.

164
00:11:16,725 --> 00:11:21,062
This is database records from the NCBI,
National Center for

165
00:11:21,062 --> 00:11:23,760
Biotechnology Information.

166
00:11:23,760 --> 00:11:26,840
Sequence read archive
database is one database.

167
00:11:26,840 --> 00:11:28,760
They used to be mirrored in Japan and
UK, and

168
00:11:28,760 --> 00:11:32,160
it's no longer mirror-able,
if that's a word.

169
00:11:32,160 --> 00:11:36,787
Because this is, just one of
the databases has 44.2 petabytes of

170
00:11:36,787 --> 00:11:40,390
DNA sequence data and
you know this will be exabytes.

171
00:11:40,390 --> 00:11:44,727
There's an exponential curve
in the not too distant future.

172
00:11:44,727 --> 00:11:47,963
So we want to mine this data,
we do mine this data.

173
00:11:47,963 --> 00:11:51,696
There's almost 7 million experiments now,
for mining.

174
00:11:51,696 --> 00:11:53,505
It's available to anybody in the world,
right?

175
00:11:53,505 --> 00:11:58,175
And so we're trying to deal with this
massive volume, and the cure for

176
00:11:58,175 --> 00:12:02,400
cancer is sitting there at
6.9 million experiments.

177
00:12:02,400 --> 00:12:04,874
It's just connecting the right dots.

178
00:12:04,874 --> 00:12:09,065
There's 478,000 species now with at
least one sequence in these databases,

179
00:12:09,065 --> 00:12:13,170
they're just exploding with amazing,
valuable information.

180
00:12:13,170 --> 00:12:14,610
This is one database.

181
00:12:14,610 --> 00:12:17,713
We're also pulling data from
NASA's gene lab database,

182
00:12:17,713 --> 00:12:21,213
which has similar types of data,
but at a different repository.

183
00:12:21,213 --> 00:12:25,402
The Ensembl database in UK we pull from,
we also have community databases, laser,

184
00:12:25,402 --> 00:12:26,759
agricultural, genomic.

185
00:12:28,710 --> 00:12:32,759
So the idea is to cut to the chase,
that's the right first thing,

186
00:12:32,759 --> 00:12:35,630
is that we're putting data in a testbed.

187
00:12:35,630 --> 00:12:39,884
We're actually trying to put
all of this data in a testbed.

188
00:12:39,884 --> 00:12:42,802
Not at one time, but actually have
pointers to the data to be able

189
00:12:42,802 --> 00:12:45,612
to pull it in as users request
it using NDN naming strategies,

190
00:12:45,612 --> 00:12:48,050
which I'll show you in a second.

191
00:12:48,050 --> 00:12:51,600
But this is kind of the overview
of our compute environment.

192
00:12:51,600 --> 00:12:55,411
We're pulling data from lots of
different repositories, local storage,

193
00:12:55,411 --> 00:12:58,162
putting into the NDN testbed and
publishing it there.

194
00:12:58,162 --> 00:13:02,591
And pulling it into cloud systems
where we work on campus HPC,

195
00:13:02,591 --> 00:13:07,520
traditional HPC, but
also did a lot of work in Google Cloud.

196
00:13:07,520 --> 00:13:10,734
And also some commercialized clouds
like the Pacific Research Platform and

197
00:13:10,734 --> 00:13:12,760
TACC have Kubernetes systems.

198
00:13:12,760 --> 00:13:17,610
And we're pulling this data using some
tools we've developed as part of our

199
00:13:17,610 --> 00:13:20,489
NSF science project into
PVCs in the cloud and

200
00:13:20,489 --> 00:13:25,448
running workflows contain everything
we're doing here is containerized.

201
00:13:25,448 --> 00:13:26,736
This is one example.

202
00:13:26,736 --> 00:13:30,027
GEMmaker is sort of a standard procedure
that you have to do to build or

203
00:13:30,027 --> 00:13:31,916
process DNA sequencing information.

204
00:13:31,916 --> 00:13:35,190
It requires lots and lots of
different containerized applications.

205
00:13:35,190 --> 00:13:38,690
It's really complicated stuff, but
we've got this working pretty well.

206
00:13:38,690 --> 00:13:39,599
So we can run this at scale.

207
00:13:39,599 --> 00:13:42,739
We've run this petabytes of data.

208
00:13:42,739 --> 00:13:45,000
So in the end,
we're publishing data in NDN.

209
00:13:45,000 --> 00:13:49,601
We also, just yesterday actually,
were able to publish from,

210
00:13:49,601 --> 00:13:54,118
with collaboration with Cisco and
Internet2 is helping too,

211
00:13:54,118 --> 00:13:57,629
publishing in an hICM
testbed too we have set up.

212
00:13:57,629 --> 00:14:00,629
So we're actually trying
to do this in parallel and

213
00:14:00,629 --> 00:14:04,884
I'd love to have testbeds with the same
code running on the same nodes and

214
00:14:04,884 --> 00:14:07,000
sort of as a lofty goal that we have.

215
00:14:08,800 --> 00:14:11,302
About all of our, everything I
have on here, all of our data,

216
00:14:11,302 --> 00:14:13,579
all of our code is open source,
and it's all on GitHub.

217
00:14:13,579 --> 00:14:19,359
And these are, if I put them on here,
they're probably tools that actually work.

218
00:14:19,359 --> 00:14:23,994
A big part of we're trying to do is with
the NDN is with some of the problems being

219
00:14:23,994 --> 00:14:27,670
addressed, one of them is
the fair data principles.

220
00:14:27,670 --> 00:14:32,370
So findability, accessibility,
interoperability, and reusability.

221
00:14:32,370 --> 00:14:35,038
And so
there's a complicated diagram here, but

222
00:14:35,038 --> 00:14:39,343
the idea is you have data in different
repositories, local storage, right?

223
00:14:39,343 --> 00:14:41,472
And people want to keep
their data as biologists for

224
00:14:41,472 --> 00:14:43,542
a while before they publish.

225
00:14:43,542 --> 00:14:47,910
And so things like findability, you can't
find stuff on people's hard drives, right?

226
00:14:47,910 --> 00:14:50,770
Finding it in public
databases is very doable.

227
00:14:50,770 --> 00:14:55,090
Accessing it can be tricky, and
I've been working with NCBI databases for

228
00:14:55,090 --> 00:14:59,080
25 years and I still don't
quite understand their schema.

229
00:14:59,080 --> 00:15:02,675
So learning the tricks to be
able to pull data is important.

230
00:15:02,675 --> 00:15:06,624
Interoperability, a lot of genomics
data is in common file formats and and

231
00:15:06,624 --> 00:15:08,650
sometimes you have to preprocess it.

232
00:15:08,650 --> 00:15:13,599
We're putting a lot of preprocessed
data into NDN, the NDN testbed.

233
00:15:13,599 --> 00:15:17,232
And reusability is a lot
of this data storage so

234
00:15:17,232 --> 00:15:21,808
you can go and reuse it,
repurpose it for other purposes.

235
00:15:21,808 --> 00:15:24,426
And so we're trying to address all
these problems with NDN, right?

236
00:15:24,426 --> 00:15:29,280
Especially the accessibility part is
abstracting all the metadata weirdness and

237
00:15:29,280 --> 00:15:32,453
putting it into here so
you can extract it with names.

238
00:15:35,569 --> 00:15:39,855
One thing cool about biology data is it's
organized, well, biology is crazy, right?

239
00:15:39,855 --> 00:15:43,490
It's like the craziest thing ever,
like we were trying to explain biology.

240
00:15:43,490 --> 00:15:49,398
But if you organize data by evolutionary
principles, it becomes actually rational.

241
00:15:49,398 --> 00:15:54,790
And so we actually have hierarchies
of data sets from different species.

242
00:15:54,790 --> 00:15:58,406
Like armadillos and humans are both
animals, there's a common ancestor

243
00:15:58,406 --> 00:16:02,160
thought to be from animals and
humans 60 million years ago.

244
00:16:02,160 --> 00:16:05,332
Find a time machine, I would go back and
see if I could spot this little guy

245
00:16:05,332 --> 00:16:08,259
running around, probably sequence
with genome too just for fun.

246
00:16:08,259 --> 00:16:11,295
But we have relationships
between the data sets, so

247
00:16:11,295 --> 00:16:13,918
we can organize things by genus and
species.

248
00:16:13,918 --> 00:16:17,531
Geno phylum in family order,
I can't even do it right now,

249
00:16:17,531 --> 00:16:20,369
all the different levels
of taxonomy levels.

250
00:16:21,430 --> 00:16:24,600
Which we have baked into
our naming conventions,

251
00:16:24,600 --> 00:16:26,300
as a natural way to name data.

252
00:16:27,580 --> 00:16:31,373
For example, there's over 4700
genomes we're indexing right now,

253
00:16:31,373 --> 00:16:33,680
pre-processing for workflows.

254
00:16:33,680 --> 00:16:35,340
And we have a naming convention for them.

255
00:16:35,340 --> 00:16:39,850
I won't go into all the details, but
we're actually processing all of these and

256
00:16:39,850 --> 00:16:43,652
publishing them right now into one
place of access, named access.

257
00:16:43,652 --> 00:16:48,837
All of the RNA expression databases,
data sets out there if anybody knows

258
00:16:48,837 --> 00:16:54,035
what RNA-seq is, we have a naming
convention too based upon biodomain.

259
00:16:54,035 --> 00:16:58,602
And then the different levels of naming,
and we actually have a UI setup for

260
00:16:58,602 --> 00:17:01,954
this to be able to search the names,
and be able to get.

261
00:17:01,954 --> 00:17:05,664
Really, what we're trying to do is deal
with these endpoint unique identifiers,

262
00:17:05,664 --> 00:17:08,271
which means a lot to the biologists
to be able to pull data.

263
00:17:13,655 --> 00:17:17,303
We have a test, an NDN type report.

264
00:17:17,303 --> 00:17:18,737
There were,
I don't think we actually published yet.

265
00:17:18,737 --> 00:17:22,243
We're still it finishing it up about
how we're actually publishing data

266
00:17:22,243 --> 00:17:23,267
into the databases.

267
00:17:23,267 --> 00:17:27,726
This is one of the test nodes that
we're using right now to be able

268
00:17:27,726 --> 00:17:29,224
to publish our data.

269
00:17:29,224 --> 00:17:31,221
And so we're able to have students now,

270
00:17:31,221 --> 00:17:34,925
biology students who publish the data
with help from people like Susmit and

271
00:17:34,925 --> 00:17:38,770
others who are really helping us
with the technical aspects of it.

272
00:17:38,770 --> 00:17:41,910
And we're learning how to pull data,
so we're focusing on the naming, and

273
00:17:41,910 --> 00:17:45,710
pulling, and pushing into workflows.

274
00:17:45,710 --> 00:17:48,337
And then a lot of the backend stuff,
we ask the people in my lab, actually,

275
00:17:48,337 --> 00:17:50,442
we have a pretty interdisciplinary
lab helping with this.

276
00:17:50,442 --> 00:17:54,912
But the Indiana community has been
fantastic in helping us try to get this

277
00:17:54,912 --> 00:17:59,748
working for us, because ultimately,
we care about just getting the result,

278
00:17:59,748 --> 00:18:03,070
right, and not so
much the process underneath that.

279
00:18:04,620 --> 00:18:07,854
These are some test data sets
that we have, or experiments.

280
00:18:07,854 --> 00:18:10,840
We actually have two key
data sets right now.

281
00:18:10,840 --> 00:18:12,579
One is a human kidney data set.

282
00:18:12,579 --> 00:18:16,068
It's about, well, 36x2 files,

283
00:18:16,068 --> 00:18:21,094
1.16 terabytes, but
we also have a rice data set.

284
00:18:21,094 --> 00:18:24,730
It's about 1.14 terabytes,
almost 1000 samples.

285
00:18:24,730 --> 00:18:26,140
A lot of genomes are there.

286
00:18:26,140 --> 00:18:30,350
We're trying to plug in all the genomes
into the testbed, as well as trying to get

287
00:18:30,350 --> 00:18:36,540
lofty with a lot of our goals, and
trying to get more data in there.

288
00:18:36,540 --> 00:18:39,440
This is real quick
preliminary results here.

289
00:18:39,440 --> 00:18:43,640
So this is downloading
the rice data sets here.

290
00:18:43,640 --> 00:18:44,860
This is time in minutes.

291
00:18:44,860 --> 00:18:47,860
It's very fast to get them onto
the computer that we're then we're gonna

292
00:18:47,860 --> 00:18:50,720
publish them on with the publishing and
pulling rates here.

293
00:18:50,720 --> 00:18:53,140
This is for almost 1000 data sets.

294
00:18:53,140 --> 00:18:55,160
It's taken a long time,
right, to be able to do this.

295
00:18:55,160 --> 00:18:57,850
And we're optimizing right now.

296
00:18:57,850 --> 00:19:01,221
And we've performed some
experiments with caching,

297
00:19:01,221 --> 00:19:05,080
where we actually did with
using commercial Internet.

298
00:19:05,080 --> 00:19:09,138
This is using no caching, and
this is first transferred, and

299
00:19:09,138 --> 00:19:13,754
the cache kicks in, and we get much,
much faster pull rates from NDN.

300
00:19:16,320 --> 00:19:20,851
And then so opportunities,
we can talk about this after this.

301
00:19:20,851 --> 00:19:24,830
But we can exchange ideas to
work containerizing stuff, and

302
00:19:24,830 --> 00:19:27,880
learning how to do stuff
like put data on PVCs.

303
00:19:27,880 --> 00:19:29,340
Other communities need to do this.

304
00:19:29,340 --> 00:19:31,730
I think Edmund's gonna
be talking about this.

305
00:19:31,730 --> 00:19:36,150
We need better tools for publishing data,
and more optimized tools to make it.

306
00:19:36,150 --> 00:19:38,550
Optimization is pretty key for
us right now.

307
00:19:38,550 --> 00:19:40,250
We need bigger places to host data.

308
00:19:40,250 --> 00:19:42,582
We wanna host exabytes of data eventually,
right?

309
00:19:42,582 --> 00:19:46,190
I wanna be able to post about 10
petabytes a day, it would be ideal.

310
00:19:46,190 --> 00:19:49,650
Be bigger data lakes writing grants
to do this kinda stuff right now.

311
00:19:49,650 --> 00:19:54,170
And we need testbeds to be able to test
out these containerized solutions,

312
00:19:54,170 --> 00:19:57,020
because if you do this in the cloud,
you'll be broke.

313
00:19:57,020 --> 00:19:59,720
You'll be going to
debtors prison real fast.

314
00:19:59,720 --> 00:20:02,735
And so we're using democratized systems
like the Pacific Research Platform.

315
00:20:02,735 --> 00:20:06,360
And TACC has a Kubernetes cluster that
we're running a lot of our tests on.

316
00:20:07,850 --> 00:20:11,090
And with that,
my team is highly interdisciplinary.

317
00:20:11,090 --> 00:20:14,687
Funded by NSF, Cisco has been very
generous with money, DOE USDA,

318
00:20:14,687 --> 00:20:19,070
working with lots of institutions,
lots of people to get this done,

319
00:20:19,070 --> 00:20:23,130
trying to help genomics out to
cure cancer and feed the world.

320
00:20:24,570 --> 00:20:25,070
I'll stop there.

321
00:20:29,370 --> 00:20:30,070
>> Thank you, Alex.

322
00:20:31,220 --> 00:20:32,858
So are there any questions?

323
00:20:42,131 --> 00:20:44,630
I have a question for you, Alex.

324
00:20:44,630 --> 00:20:47,770
So you mentioned the support
from Indian community.

325
00:20:47,770 --> 00:20:49,880
So can you elaborate on that?

326
00:20:49,880 --> 00:20:52,090
What kind of support
would you like to see?

327
00:20:52,090 --> 00:20:53,710
Is it optimization?

328
00:20:53,710 --> 00:20:55,710
Is it better APIs?

329
00:20:57,030 --> 00:21:00,458
>> I think for me, if you ask my students,
they might say something different.

330
00:21:00,458 --> 00:21:04,301
But it's optimization at this point,
cuz we have it functional.

331
00:21:04,301 --> 00:21:06,430
We can pull data into workflows.

332
00:21:06,430 --> 00:21:10,870
And we're focusing on that integration,
modifying the workflows to pull data in

333
00:21:10,870 --> 00:21:16,100
from the network, as opposed to the file
system on the PVC, like is shown here.

334
00:21:16,100 --> 00:21:18,860
And so
we need to be able to do that publish and

335
00:21:18,860 --> 00:21:23,140
pull faster, but
I think we actually have the pieces now.

336
00:21:23,140 --> 00:21:24,714
I think we just need to make it faster,
yeah.

337
00:21:27,553 --> 00:21:29,116
>> Okay, thank you.

338
00:21:29,116 --> 00:21:36,730
So there is no other questions,
then I think we can thank the speaker.

339
00:21:41,810 --> 00:21:42,670
Thank you, Alex.

340
00:21:42,670 --> 00:21:43,170
>> Thank you.

341
00:21:48,490 --> 00:21:52,890
>> So the next talk is by Edmund Yeh.

342
00:21:52,890 --> 00:21:56,520
Edmund is currently
a professor of Electrical and

343
00:21:56,520 --> 00:21:58,970
Computer Engineering at
Northeastern University.

344
00:22:00,040 --> 00:22:03,290
He was previously assistant and
associate professor

345
00:22:05,260 --> 00:22:08,782
of Electrical Engineering Computer Science
and Statistics at El.

346
00:22:08,782 --> 00:22:16,500
Professor Yeh was one of the PIs on
the original NSF funded Project.

347
00:22:16,500 --> 00:22:23,210
He served as as the general chair for
ACM Sigmetrics in 2020,

348
00:22:23,210 --> 00:22:29,810
and will serve as the TPC co-chair for
ACM MobiHoc in 2021.

349
00:22:29,810 --> 00:22:36,855
His talk today is Data-Centric Ecosystems
for Large-Scale Data-Intensive Science.

350
00:22:46,141 --> 00:22:46,880
Hello, Edmund?

351
00:22:52,580 --> 00:22:54,180
>> Okay, hear me now?

352
00:22:54,180 --> 00:22:54,700
>> Yes, yeah.

353
00:22:54,700 --> 00:22:56,190
And we can see the slides as well.

354
00:22:56,190 --> 00:22:57,000
>> Okay, great.

355
00:22:57,000 --> 00:22:58,621
So great.

356
00:23:00,662 --> 00:23:03,850
All right, so
great pleasure to be here today.

357
00:23:05,640 --> 00:23:09,939
And [COUGH] so I'll be talking
about data-centric ecosystems for

358
00:23:09,939 --> 00:23:13,720
large-scale data-intensive science.

359
00:23:13,720 --> 00:23:18,382
And this is something that we've been
working on the last couple of years,

360
00:23:18,382 --> 00:23:19,127
actually.

361
00:23:19,127 --> 00:23:25,312
So data-intensive science, we're talking
about some of the world's most exciting

362
00:23:25,312 --> 00:23:31,003
research projects, including Large
Hadron Collider, high energy physics.

363
00:23:31,003 --> 00:23:35,642
The Large Synoptic Survey Telescope
in astrophysics, and

364
00:23:35,642 --> 00:23:40,050
Square Kilometre Array, and also genomics.

365
00:23:40,050 --> 00:23:43,084
So there are many such examples
of large science projects,

366
00:23:43,084 --> 00:23:47,152
collaborative projects involving many,
many different institutions around

367
00:23:47,152 --> 00:23:52,310
the world,
That has to handle large volumes of data.

368
00:23:53,360 --> 00:23:55,782
They face similar set of problems.

369
00:23:55,782 --> 00:24:00,600
These challenges that
go through all of them

370
00:24:00,600 --> 00:24:05,015
include How to index data,
how to secure the data,

371
00:24:05,015 --> 00:24:09,732
how to store the data,
how to distribute the data efficiently.

372
00:24:09,732 --> 00:24:15,743
And very importantly, how to analyze
the data, how to learn from the data.

373
00:24:15,743 --> 00:24:21,163
This is a common theme that goes through
many, many of these different areas.

374
00:24:21,163 --> 00:24:26,509
One needs to coordinate the use of
computing storage network resources.

375
00:24:26,509 --> 00:24:31,237
Which, while they're ample, is still quite
limited compared to the scale of the data

376
00:24:31,237 --> 00:24:34,236
and computation tasks that
these applications face.

377
00:24:36,032 --> 00:24:41,157
Now today, what's happening is,
these experts in these various domains

378
00:24:41,157 --> 00:24:46,618
are dealing with these systems problems,
often in isolation from each other.

379
00:24:46,618 --> 00:24:52,211
So they've had to develop their own
solutions to deal with these problems.

380
00:24:52,211 --> 00:24:58,995
And actually, a lot of these efforts
are being replicated across these domains.

381
00:24:58,995 --> 00:25:01,663
And one can see a kind of stovepipe

382
00:25:01,663 --> 00:25:05,861
kind of situation across
these different domains.

383
00:25:05,861 --> 00:25:08,643
And one might ask, well,
why is this happening,

384
00:25:08,643 --> 00:25:13,082
that these smart people in these different
domains all have to develop their own

385
00:25:13,082 --> 00:25:15,422
systems to handle all of these problems?

386
00:25:15,422 --> 00:25:20,714
Well, one underlying reason
is that there exists this gap

387
00:25:20,714 --> 00:25:27,200
between the application needs and
the existing networks and systems.

388
00:25:27,200 --> 00:25:31,498
So the current networks and
systems focus on addresses,

389
00:25:31,498 --> 00:25:34,460
processes, servers, connections.

390
00:25:34,460 --> 00:25:39,302
And consequently, the security solutions
that they have also focus on securing

391
00:25:39,302 --> 00:25:41,591
data containers and delivery pipes.

392
00:25:41,591 --> 00:25:45,257
Whereas the applications
actually care about the data.

393
00:25:45,257 --> 00:25:50,356
And so this is a gap, of course,
that's been identified

394
00:25:50,356 --> 00:25:54,831
also as a primary motivation for
things like NDN.

395
00:25:54,831 --> 00:26:00,291
But this gap, I think, is one of
the primary reasons why you're seeing

396
00:26:00,291 --> 00:26:06,218
these systems solutions being replicated
across these different domains.

397
00:26:06,218 --> 00:26:10,579
And so what we're focusing
on is taking a data-centric

398
00:26:10,579 --> 00:26:13,838
approach to systems and network design.

399
00:26:13,838 --> 00:26:20,111
And apply this approach to the large-scale
data-intensive science area.

400
00:26:20,111 --> 00:26:24,251
So this approach,
the idea is to provide system

401
00:26:24,251 --> 00:26:28,090
support through the whole data life cycle.

402
00:26:28,090 --> 00:26:31,133
From the data production, naming the data,

403
00:26:31,133 --> 00:26:35,709
securing the data directly,
to delivering the data using naming.

404
00:26:35,709 --> 00:26:41,131
Therefore enabling scalable data
retrieval, enabling in-network caching,

405
00:26:41,131 --> 00:26:45,442
automated joint caching,
forwarding, multicast delivery.

406
00:26:45,442 --> 00:26:50,298
We wanna develop a common framework that
can support different application domains,

407
00:26:50,298 --> 00:26:54,632
and not have to replicate these efforts
every time we have a new application.

408
00:26:54,632 --> 00:26:58,239
And NDN is something that enables that,
and

409
00:26:58,239 --> 00:27:02,042
is in fact a very
appropriate architecture for

410
00:27:02,042 --> 00:27:06,540
solving these large
data-intensive science areas.

411
00:27:06,540 --> 00:27:12,133
So one of the first projects to take
this approach is the SANDIE project,

412
00:27:12,133 --> 00:27:18,478
SDN-Assisted NDN for Data Intensive
Experiments, which started In 2017.

413
00:27:18,478 --> 00:27:24,262
So the team consisted of Northeastern
headed by myself, Harvey Newman,

414
00:27:24,262 --> 00:27:29,877
a very influential physicist and
networking physicist from Caltech.

415
00:27:29,877 --> 00:27:33,641
And Christos Papadopoulos
from Florida State, and

416
00:27:33,641 --> 00:27:38,526
then transitioning to Craig Partridge
after Christos went to DHS.

417
00:27:38,526 --> 00:27:45,238
And of course, and in partnership with
other LHC sites and the NDN project team.

418
00:27:45,238 --> 00:27:52,106
The approach of the SANDIE project was to
use SDN-assisted NDN to redesign the LHC,

419
00:27:52,106 --> 00:27:58,798
the Large Hadron Collider high energy
physics network to optimize the workflow.

420
00:27:58,798 --> 00:28:01,979
We developed an NDN naming scheme for
fast access and

421
00:28:01,979 --> 00:28:05,091
efficient communication
in high energy physics.

422
00:28:05,091 --> 00:28:09,280
We deployed NDN edge caches
with SSDs in multiple sites.

423
00:28:09,280 --> 00:28:13,163
And we used simultaneous
optimization of caching and

424
00:28:13,163 --> 00:28:16,794
forwarding to make the data
delivery efficient.

425
00:28:16,794 --> 00:28:21,844
Now, this is, of course, we're
actually building a real system here.

426
00:28:21,844 --> 00:28:26,590
So the feasibility of an NDN-based
data distribution system for

427
00:28:26,590 --> 00:28:31,518
LHC was first demonstrated at
supercomputing 2018 in Dallas.

428
00:28:31,518 --> 00:28:36,917
And last year in Denver at SC 19,
we show greatly improved throughput and

429
00:28:36,917 --> 00:28:40,786
delay performance by
leveraging a couple of things.

430
00:28:40,786 --> 00:28:43,799
One was the joint
optimization of caching and

431
00:28:43,799 --> 00:28:48,721
forwarding using the VIP algorithm
that was developed by Northeastern.

432
00:28:48,721 --> 00:28:53,426
We then leveraged
the NDN-DPDK forwarder which

433
00:28:53,426 --> 00:28:57,332
Lotfi mentioned was developed by NIST.

434
00:28:57,332 --> 00:29:01,998
And we used an NDN-DPDK-based consumer and

435
00:29:01,998 --> 00:29:05,442
producer developed by Caltech.

436
00:29:05,442 --> 00:29:11,770
And then we had a live demo at SC 19 over
a transcontinental layer two demo testbed

437
00:29:11,770 --> 00:29:18,391
that was running from the SC 19 floor to
Caltech to Northeastern to Colorado State.

438
00:29:18,391 --> 00:29:24,304
We were able to achieve over 6.7
gigabits per second throughput

439
00:29:24,304 --> 00:29:31,178
using a single thread between
the NDN-DPDK-based consumer and producer.

440
00:29:31,178 --> 00:29:35,333
And we also showed in another experiment
that, using the optimized caching and

441
00:29:35,333 --> 00:29:36,699
forwarding algorithms,

442
00:29:36,699 --> 00:29:39,748
we were able to decrease download
times by a factor of ten.

443
00:29:39,748 --> 00:29:43,372
So that was a very exciting
demo that we had last year.

444
00:29:43,372 --> 00:29:46,324
And this is a picture of
the throughput that we obtained.

445
00:29:46,324 --> 00:29:49,866
You can see on the upper
left-hand corner there,

446
00:29:49,866 --> 00:29:53,245
the 6.71 gigabits per second throughput.

447
00:29:53,245 --> 00:29:56,336
And by the way, assessment was very

448
00:29:56,336 --> 00:30:01,087
much a part of that demo that
we had last year in Denver.

449
00:30:01,087 --> 00:30:06,189
Now what is the latest
development this year?

450
00:30:06,189 --> 00:30:10,671
NSF has just awarded a new
project called N-DISE.

451
00:30:10,671 --> 00:30:16,109
N-DISE stands for NDN for
Data Intensive Science Experiments.

452
00:30:16,109 --> 00:30:20,034
This is gonna start this year,
and in some sense,

453
00:30:20,034 --> 00:30:23,681
this is a continuation
of the SANDIE project,

454
00:30:23,681 --> 00:30:28,370
a much expanded version headed
by Northeastern, myself.

455
00:30:28,370 --> 00:30:32,680
And participating co-PIs, Harvey Newman,

456
00:30:32,680 --> 00:30:37,319
Lixia Zhang from UCLA,
Jason Cong from UCLA, and

457
00:30:37,319 --> 00:30:41,310
Susmit Shannigrahi from Tennessee Tech.

458
00:30:41,310 --> 00:30:45,631
In partnership with LHC, and
other genomics collaborators such as

459
00:30:45,631 --> 00:30:49,288
Alex Feltus, who just spoke,
and the NDN project team.

460
00:30:49,288 --> 00:30:54,656
So the challenges for N-DISE,
we had SANDIE for the last three years.

461
00:30:54,656 --> 00:30:58,744
But LHC, the data volume is gonna
grow by another ten times due

462
00:30:58,744 --> 00:31:02,845
to the high luminosity LHC
experiment starting in 2027.

463
00:31:02,845 --> 00:31:07,629
It's gonna be much increased data
complexity, human genome data,

464
00:31:07,629 --> 00:31:11,596
Earth biogenome data,
is going into the exabyte range.

465
00:31:11,596 --> 00:31:14,553
So that's a part of this
N-DISE project as well.

466
00:31:14,553 --> 00:31:18,132
There's a need to use diverse computation,
storage, network, resources.

467
00:31:18,132 --> 00:31:22,211
And our approach is to build
a data-centric ecosystem to provide agile,

468
00:31:22,211 --> 00:31:26,885
integrated, interoperable, scalable,
robust, and trustworthy solutions for

469
00:31:26,885 --> 00:31:30,178
heterogeneous data-intensive
domains in the manner that

470
00:31:30,178 --> 00:31:32,046
I described earlier in the talk.

471
00:31:32,046 --> 00:31:37,119
So the goal of N-DISE is to deploy and
condition the first prototype

472
00:31:37,119 --> 00:31:42,726
production-ready NDN-based petascale
data distribution, caching,

473
00:31:42,726 --> 00:31:47,804
access, and computation system
serving major science programs.

474
00:31:47,804 --> 00:31:52,280
The LHC high energy physics program
will be a leading target use case.

475
00:31:52,280 --> 00:31:57,673
But the other application we'll
be focusing on is the BioGenome,

476
00:31:57,673 --> 00:32:04,541
human genome projects And as future use
cases we'll be looking at LSST, SKA.

477
00:32:04,541 --> 00:32:09,263
We'll leverage NDN protocols, high
throughput forwarding caching techniques,

478
00:32:09,263 --> 00:32:14,118
containerization techniques, as Alex was
talking about in order to handle different

479
00:32:14,118 --> 00:32:16,858
operating systems to be
able to upgrade easily.

480
00:32:16,858 --> 00:32:22,790
Integrated with SDN techniques and
as well as FPGA acceleration subsystems.

481
00:32:22,790 --> 00:32:26,430
So Jason Tong is an FPGA
expert that's on the team.

482
00:32:26,430 --> 00:32:30,770
We're aiming to deliver LHC data over
wide area network at throughputs near 100

483
00:32:30,770 --> 00:32:31,950
gigabits per second.

484
00:32:31,950 --> 00:32:37,762
That'll be our target achievable because
of when we use, we're planning to do multi

485
00:32:37,762 --> 00:32:44,050
threaded implementations which is going to
allow for linear scaling of throughput.

486
00:32:44,050 --> 00:32:47,250
We'll be looking at dramatically
decreasing download times by using

487
00:32:47,250 --> 00:32:49,070
optimized caching.

488
00:32:49,070 --> 00:32:53,065
And we'll have built an enhanced
testbed with high performance

489
00:32:53,065 --> 00:32:55,850
NDN data cache servers.

490
00:32:55,850 --> 00:32:59,318
So how much time do I have left to spend?

491
00:32:59,318 --> 00:33:00,890
>> About five minutes.

492
00:33:02,130 --> 00:33:03,090
>> Okay, good.

493
00:33:03,090 --> 00:33:07,770
So to go into the research
agenda a bit more in detail.

494
00:33:07,770 --> 00:33:13,710
So we had built the NBN-DPDK consumer and
producer Caltech had done that.

495
00:33:13,710 --> 00:33:18,290
We're now going to look at developing
multi threaded consumer and

496
00:33:18,290 --> 00:33:22,850
producer applications to aim for
linear throughput scaling.

497
00:33:22,850 --> 00:33:28,768
This is going to be integrated
with a NDN-DPDK, XRootD plugin.

498
00:33:28,768 --> 00:33:34,520
XRootD is the current redirector tool
application that's used in LHC in

499
00:33:34,520 --> 00:33:40,790
order for people to discover data and
to map requests to different servers.

500
00:33:40,790 --> 00:33:45,625
And so what we previously did in
Sandy was to build a plugin that

501
00:33:45,625 --> 00:33:50,730
allowed you to interface with
an NDN networking system.

502
00:33:50,730 --> 00:33:55,710
And so this has actually been developed or
now integrated with NDN-DPDK.

503
00:33:55,710 --> 00:33:59,868
And now we're going to integrate that
with a multi threaded consumer producer

504
00:33:59,868 --> 00:34:00,692
application.

505
00:34:00,692 --> 00:34:04,384
We're going to be looking at
containers for NDN-DPDK and

506
00:34:04,384 --> 00:34:08,830
other applications in order to
handle diverse server requirements,

507
00:34:08,830 --> 00:34:11,660
server equipment and interfaces.

508
00:34:11,660 --> 00:34:16,360
We're looking at using docker
containers so that we can host guest

509
00:34:16,360 --> 00:34:21,310
operating systems, enables easy
state restoration, ease upgrading.

510
00:34:21,310 --> 00:34:24,217
We'll be looking at data integrity and
provenance.

511
00:34:24,217 --> 00:34:27,690
This is we want to do data
origin authentication.

512
00:34:27,690 --> 00:34:33,440
So even though maybe security is not
a huge concern in let's say LHC data,

513
00:34:33,440 --> 00:34:36,000
authentication is a huge concern.

514
00:34:36,000 --> 00:34:39,010
Not only do we want to
authenticate to data origin, but

515
00:34:39,010 --> 00:34:43,190
we wanna authenticate,
we want to do authenticated traces.

516
00:34:43,190 --> 00:34:47,950
Because what happens in these applications
is that the output data from one

517
00:34:47,950 --> 00:34:52,820
group of scientists is going to be used as
input data for other research scientists.

518
00:34:52,820 --> 00:34:57,355
So we want to authenticate, we want to do
authenticated tracing as the data moves

519
00:34:57,355 --> 00:34:59,567
through a multiple processing steps.

520
00:34:59,567 --> 00:35:03,890
So this will be extremely valuable for
data scientists in this area.

521
00:35:03,890 --> 00:35:08,190
And we're aiming to do this through data
manifests where you compute hashes of data

522
00:35:08,190 --> 00:35:10,350
segments and then you sign the hashes.

523
00:35:10,350 --> 00:35:13,555
We want to do congestion control
retransmission using something called

524
00:35:13,555 --> 00:35:14,145
NETBLT.

525
00:35:15,886 --> 00:35:20,150
Which, I think, developed many years ago,
but we're gonna put it

526
00:35:20,150 --> 00:35:24,810
at the network layer so that we can
effectively interface with caching.

527
00:35:24,810 --> 00:35:29,020
We're gonna be looking at advanced
caching storage solutions.

528
00:35:29,020 --> 00:35:34,473
So we want to extend
the VIP caching forwarding

529
00:35:34,473 --> 00:35:39,640
algorithm to interact with
multi threaded borders.

530
00:35:39,640 --> 00:35:43,260
We're going to look at hierarchical
caching systems involving different types

531
00:35:43,260 --> 00:35:47,840
of memory SSDs, Intel Optane for
handling large data volumes.

532
00:35:47,840 --> 00:35:48,980
So in these applications,

533
00:35:48,980 --> 00:35:53,820
the volume is still huge that
one has to exploit all kinds of

534
00:35:53,820 --> 00:35:58,730
storage one has access to and this
requires a hierarchical caching system.

535
00:35:58,730 --> 00:36:04,990
We want to use FPGA acceleration with so
FPGA is known to be programming adaptive,

536
00:36:04,990 --> 00:36:09,580
it can give us a high throughput,
low latency energy efficiency.

537
00:36:09,580 --> 00:36:17,631
The primary focus here will be to use FPGA
acceleration to accelerate hash functions,

538
00:36:17,631 --> 00:36:22,043
lookups in
the NDN-DPDK Name Dispatch Table,

539
00:36:22,043 --> 00:36:26,361
the PIT-CS Composite Table and
also the FIB.

540
00:36:26,361 --> 00:36:31,936
So, to wrap up the talk, so data intensive
science applications such as LHC,

541
00:36:31,936 --> 00:36:36,412
Genomics and various other
applications require fundamental

542
00:36:36,412 --> 00:36:40,810
network system solutions
to address common needs.

543
00:36:40,810 --> 00:36:45,440
NDN provides such a common
framework that data-centric

544
00:36:45,440 --> 00:36:50,570
systems support that provides support
through the whole data lifecycle.

545
00:36:50,570 --> 00:36:54,550
It's a natural fit for
applications like LHC, genomics and

546
00:36:54,550 --> 00:36:56,830
other data intensive applications.

547
00:36:56,830 --> 00:37:00,020
We've already shown in the SANDIE
project that we can get

548
00:37:01,490 --> 00:37:03,610
very high performance with NDN.

549
00:37:03,610 --> 00:37:08,680
We should have throughput at 6.7 gigabits
per second over wide area network

550
00:37:08,680 --> 00:37:14,374
using NDN-DPDK forwarder using
the optimized caching voting algorithms.

551
00:37:14,374 --> 00:37:17,556
So the point is that we can get
very high performance using

552
00:37:17,556 --> 00:37:20,554
NDN approach to large scale
data intensive science.

553
00:37:20,554 --> 00:37:25,684
And the new project N-DISE,
we're working toward the first prototype,

554
00:37:25,684 --> 00:37:30,653
production ready NDN system,
which is going to be integrated with SDN,

555
00:37:30,653 --> 00:37:33,030
with FPGA and containerization.

556
00:37:34,040 --> 00:37:38,200
And of course, we're seeking long-term
collaboration with various domain

557
00:37:38,200 --> 00:37:44,940
scientists, networking computer system
communities in order to push forward this

558
00:37:44,940 --> 00:37:50,730
project to build data-centric ecosystems
for large scale data intensive science.

559
00:37:50,730 --> 00:37:51,380
Thanks very much.

560
00:37:53,600 --> 00:37:54,900
>> Thank you Edmund.

561
00:37:54,900 --> 00:38:00,831
I think Dave has a question for
you or a comment.

562
00:38:04,761 --> 00:38:06,793
>> Am I muted?

563
00:38:06,793 --> 00:38:08,250
>> No, we can hear you.

564
00:38:08,250 --> 00:38:13,150
>> Good, so
you're calling something tracing.

565
00:38:13,150 --> 00:38:15,530
Which I've always heard
called Data provenance.

566
00:38:17,000 --> 00:38:20,090
I'm curious if you think of
it as something different or

567
00:38:20,090 --> 00:38:22,430
is this the same stuff
that Margo Seltzer and

568
00:38:22,430 --> 00:38:25,340
her collaborators have been working on for
10 years.

569
00:38:28,885 --> 00:38:36,592
>> So I'm actually not aware of
that to admit what you said but

570
00:38:36,592 --> 00:38:40,681
the idea here is to basically,

571
00:38:40,681 --> 00:38:46,835
essentially do a multistep
provenance cell.

572
00:38:46,835 --> 00:38:48,950
>> Yeah, right, right, right, right.

573
00:38:48,950 --> 00:38:50,321
>> So.
>> There's like 10 years of

574
00:38:50,321 --> 00:38:51,027
papers on this.

575
00:38:51,027 --> 00:38:55,040
I think you people should look at it
before you go invent something new.

576
00:38:55,040 --> 00:39:01,377
>> Yeah, I didn't really actually mean
to suggest necessarily it's a new thing.

577
00:39:01,377 --> 00:39:05,983
But we're just going to do that in
the context of large scale data intensive

578
00:39:05,983 --> 00:39:08,847
science, I guess and
within this ecosystem.

579
00:39:08,847 --> 00:39:11,980
>> That is really useful to
talk to Margo about this.

580
00:39:11,980 --> 00:39:17,037
She's known at UBC because when I heard
her last talk, she basically said,

581
00:39:17,037 --> 00:39:21,000
yeah, we know,
pretty much understand how to do all this.

582
00:39:21,000 --> 00:39:25,800
The technical means of doing
with multi signatures and

583
00:39:25,800 --> 00:39:27,630
backward pointers and stuff like that.

584
00:39:27,630 --> 00:39:29,300
You know, we sorta know how to do it.

585
00:39:30,340 --> 00:39:35,011
What happened was when we tried to
do this, the scientists hated it.

586
00:39:35,011 --> 00:39:35,884
>> Okay.

587
00:39:35,884 --> 00:39:38,779
Okay, so.

588
00:39:38,779 --> 00:39:43,162
>> So figuring out how to get the
scientists on board with a data provenance

589
00:39:43,162 --> 00:39:48,920
system under NDN might be easier than what
they've discovered with other systems.

590
00:39:48,920 --> 00:39:50,190
>> Right.

591
00:39:50,190 --> 00:39:55,250
That's a good I mean, so you know,
security and provinance has not been so

592
00:39:55,250 --> 00:40:00,070
far a major concern in the physics
community just because I think that they

593
00:40:00,070 --> 00:40:03,020
Control access to their
network very tightly.

594
00:40:03,020 --> 00:40:06,593
At the moment, so
maybe they don't worry about it.

595
00:40:06,593 --> 00:40:11,165
But I think in at least in
other data intensive areas.

596
00:40:11,165 --> 00:40:15,105
>> Our environment really, important.

597
00:40:15,105 --> 00:40:16,524
>> Yeah.

598
00:40:16,524 --> 00:40:18,070
>> Right.
>> So we will have but yeah,

599
00:40:18,070 --> 00:40:20,790
they probably they will
need some convincing.

600
00:40:20,790 --> 00:40:23,800
Yes, and that effort is just starting.

601
00:40:23,800 --> 00:40:25,800
So we'll know.

602
00:40:25,800 --> 00:40:30,596
>> All I'm saying is that,
anybody who's actually doing the technical

603
00:40:30,596 --> 00:40:34,345
work to develop tracing algorithms,
friend Deanne.

604
00:40:34,345 --> 00:40:38,586
What a review of the literature
on data provenance.

605
00:40:39,934 --> 00:40:40,970
>> Okay, yeah.

606
00:40:40,970 --> 00:40:43,614
Thank you, thanks for pointing that out.

607
00:40:43,614 --> 00:40:45,346
>> Thanks.

608
00:40:45,346 --> 00:40:47,023
>> Thank you.

609
00:40:47,023 --> 00:40:48,620
>> Alright, thank you Edmund.

610
00:40:49,670 --> 00:40:51,138
Flip the, flip the
>> Next subject.

611
00:40:54,742 --> 00:40:57,846
>> Our next speaker is Lan Wang.

612
00:40:57,846 --> 00:40:59,608
Lan is gonna be a professor and

613
00:40:59,608 --> 00:41:04,570
chair of the Computer Science Department
at University of Memphis.

614
00:41:04,570 --> 00:41:07,777
So, you will be speaking about M card,

615
00:41:07,777 --> 00:41:11,668
secure, real time data
distribution system,

616
00:41:11,668 --> 00:41:16,336
with fine grain access control for,
M health research,

617
00:41:16,336 --> 00:41:21,610
the continuation of the discussion
that we just had, planned.

618
00:41:21,610 --> 00:41:24,210
>> Yes, but how do I share?

619
00:41:24,210 --> 00:41:26,388
I think admin needs to stop sharing.

620
00:41:28,360 --> 00:41:31,860
>> Even start sharing just put you
can push them out if you start yours.

621
00:41:31,860 --> 00:41:38,405
>> Okay, See my screen

622
00:41:42,376 --> 00:41:44,347
>> Yes.

623
00:41:44,347 --> 00:41:48,084
>> Okay, good morning.

624
00:41:48,084 --> 00:41:53,980
I'm going to talk about a new
initiative funded project mGuard.

625
00:41:53,980 --> 00:41:57,382
This is a collaboration between me,

626
00:41:57,382 --> 00:42:02,220
my colleague Santosh Kumar and
Lixia Zhang at UCLA.

627
00:42:04,038 --> 00:42:10,918
Today, many of us have smartwatches,
smartphones, smart scales.

628
00:42:10,918 --> 00:42:15,598
These devices monitor our heart rate,
blood oxygen levels,

629
00:42:15,598 --> 00:42:20,140
sleep, weight, and
various other biometrics.

630
00:42:20,140 --> 00:42:24,160
Such mobile health data, it can be used to

631
00:42:25,160 --> 00:42:30,860
study a wide range of health and
wellness issues, such as stress,

632
00:42:30,860 --> 00:42:36,410
sleep disorders,
congestive heart failures, and migraine.

633
00:42:36,410 --> 00:42:42,860
But the data reveals a lot
of our own private lives.

634
00:42:42,860 --> 00:42:48,845
So the privacy and security issues here,

635
00:42:48,845 --> 00:42:52,608
need to be investigated.

636
00:42:52,608 --> 00:42:57,372
But existing mobile health
data infrastructure

637
00:42:57,372 --> 00:43:02,259
lack support for
fine-grained access control.

638
00:43:03,570 --> 00:43:08,832
For example,
you can get access to a whole data set.

639
00:43:08,832 --> 00:43:14,035
But you can they cannot
control which users data you

640
00:43:14,035 --> 00:43:19,722
can look at which users data you cannot,
they can also,

641
00:43:19,722 --> 00:43:27,660
they cannot enforce Access Control
based on time or location either.

642
00:43:27,660 --> 00:43:30,510
So that is a big constraint.

643
00:43:30,510 --> 00:43:35,570
Also, researchers cannot get real time

644
00:43:37,540 --> 00:43:40,480
many times, they cannot get
real time access to the data.

645
00:43:41,590 --> 00:43:48,590
They are only send the data
after everything is collected.

646
00:43:48,590 --> 00:43:52,270
But if you want to do
real time intervention,

647
00:43:52,270 --> 00:43:58,380
then that's not feasible
with current access.

648
00:43:58,380 --> 00:44:07,540
So we want to apply NDN's name based data
centric approach to solve these problems.

649
00:44:07,540 --> 00:44:10,860
And because here we have

650
00:44:12,050 --> 00:44:16,150
NIH funded mobile health data center.

651
00:44:17,150 --> 00:44:21,830
So it's very natural for
us to collaborate with this

652
00:44:21,830 --> 00:44:26,720
NIH MD2K centre to work on this problem.

653
00:44:28,060 --> 00:44:32,280
So MD2K stands for
mobile sensor data to knowledge.

654
00:44:32,280 --> 00:44:37,038
It is one of 11 National NIH
big data centres of excellence.

655
00:44:37,038 --> 00:44:41,030
It's led by my colleague Santosh Kumar.

656
00:44:41,030 --> 00:44:45,168
Their mission is to develop tools,
to gather, analyze,

657
00:44:45,168 --> 00:44:50,158
and interpret health data generated
by mobile and wearable sensors.

658
00:44:50,158 --> 00:44:54,939
The, MD2K center,
is a collaboration amongst

659
00:44:54,939 --> 00:45:00,186
17 universities involving
many faculty members,

660
00:45:00,186 --> 00:45:03,113
students and staff members.

661
00:45:05,873 --> 00:45:11,664
So they conduct many
health related studies.

662
00:45:11,664 --> 00:45:17,254
And the studies produce
a lot of sensor data and

663
00:45:17,254 --> 00:45:23,130
all the data is collected
by the MD2K's enter,

664
00:45:23,130 --> 00:45:26,443
into a cloud based system.

665
00:45:26,443 --> 00:45:31,097
And through the system,
the study coordinators can

666
00:45:31,097 --> 00:45:34,914
monitor their participants in real time.

667
00:45:34,914 --> 00:45:39,963
The data science researchers can use
the data to develop bile markers and

668
00:45:39,963 --> 00:45:41,628
validate the markers.

669
00:45:41,628 --> 00:45:44,790
And then the health researchers,

670
00:45:44,790 --> 00:45:50,785
can you use the bile markers to
analyze their patients' health,

671
00:45:50,785 --> 00:45:55,376
and study the effectiveness
of the bile markers.

672
00:45:55,376 --> 00:46:02,954
This data has more than 2200 participants.

673
00:46:02,954 --> 00:46:07,257
More than 100,000 participant days.

674
00:46:07,257 --> 00:46:14,210
4.7 trillion data points and
more than 300 terabytes of data size.

675
00:46:14,210 --> 00:46:16,980
These numbers are from last year.

676
00:46:16,980 --> 00:46:20,100
Probably the current
data size is much bigger.

677
00:46:21,814 --> 00:46:27,050
So, here's the proposed mGuard system.

678
00:46:28,440 --> 00:46:33,450
We don't want to change the existing
system, we want to enhance it.

679
00:46:34,700 --> 00:46:41,500
So, we will continue to use
the existing MD2K components.

680
00:46:41,500 --> 00:46:43,585
There are two major components.

681
00:46:43,585 --> 00:46:46,180
One is called M cerebellum?

682
00:46:46,180 --> 00:46:51,710
It's a data collection platform
composed of sensors and

683
00:46:51,710 --> 00:46:56,080
mobile phones to collect data
from study participants.

684
00:46:56,080 --> 00:47:02,320
And this platform will send
data to cerebral cortex.

685
00:47:02,320 --> 00:47:10,040
That's a cloud based system to store and
support computing on the data.

686
00:47:10,040 --> 00:47:15,341
And what we are going to do is
to add an NDN data adapter that

687
00:47:15,341 --> 00:47:20,538
will encrypt sign and
packetize the data in NDN format.

688
00:47:20,538 --> 00:47:24,622
And store the packets in MDN repo.

689
00:47:24,622 --> 00:47:31,207
And these two systems,
sorry these two components will work on

690
00:47:31,207 --> 00:47:36,809
top of NDN forwarder to send and
receive NDN packets.

691
00:47:36,809 --> 00:47:41,750
That's on the server side, on the receiver
side, the users can continue to use

692
00:47:41,750 --> 00:47:45,762
their legacy applications, or
their existing applications.

693
00:47:45,762 --> 00:47:50,605
But we will develop new
Indian based research

694
00:47:50,605 --> 00:47:55,703
application that can
subscribe to the data from

695
00:47:55,703 --> 00:48:00,846
the server and then
>> I mean,

696
00:48:00,846 --> 00:48:04,022
decrypt to the data and
verify the data and

697
00:48:04,022 --> 00:48:10,027
then store the data in a database that
can be used by the existing application.

698
00:48:10,027 --> 00:48:15,088
And we will also have
an NDN data consumer that

699
00:48:15,088 --> 00:48:19,883
will perform the substance corruption and

700
00:48:19,883 --> 00:48:24,545
publication activities and also send and

701
00:48:24,545 --> 00:48:30,420
receive data, sorry,
interest and data packets.

702
00:48:30,420 --> 00:48:36,510
So this overall enhanced
system will provide the fine

703
00:48:36,510 --> 00:48:41,519
grained data access control capability and

704
00:48:41,519 --> 00:48:47,214
also real-time data
distribution capability.

705
00:48:47,214 --> 00:48:52,233
Here's the proposed naming structure for
the system.

706
00:48:52,233 --> 00:48:55,634
This is strictly directly
from the proposal.

707
00:48:55,634 --> 00:48:58,420
We still need to refine it.

708
00:48:58,420 --> 00:49:03,310
So we have the data organization name as

709
00:49:03,310 --> 00:49:08,750
the root prefix and
then under that we have different studies.

710
00:49:08,750 --> 00:49:12,290
And for each study, depending on
what kind of data they collect,

711
00:49:13,580 --> 00:49:18,830
the each type of data is
the branch under that study.

712
00:49:18,830 --> 00:49:24,440
And then we have more finer grain,
data type and user ID.

713
00:49:24,440 --> 00:49:28,145
And then below the user,
we have a branch for

714
00:49:28,145 --> 00:49:31,562
the actual data and the encryption key.

715
00:49:31,562 --> 00:49:35,981
We also have branch for
access control to encrypt

716
00:49:35,981 --> 00:49:40,092
the content key and
decrypt the content key.

717
00:49:40,092 --> 00:49:43,970
So these are used by the producers and
consumers of the data.

718
00:49:45,030 --> 00:49:51,610
That's the overall naming scheme and
we also have a trust model.

719
00:49:51,610 --> 00:49:54,020
This is a preliminary model.

720
00:49:54,020 --> 00:49:56,400
It also needs to be refined.

721
00:49:56,400 --> 00:50:03,350
At the top level, we have the overall
md2k organizations trust,

722
00:50:03,350 --> 00:50:09,150
anchor T which signs each
research studies key and

723
00:50:09,150 --> 00:50:14,410
each research study is
key will sign their data.

724
00:50:14,410 --> 00:50:19,138
So that's how you authenticate
the data produced by

725
00:50:19,138 --> 00:50:23,122
a particular user from a particular study.

726
00:50:23,122 --> 00:50:27,967
Everything will be traced back to
the trust anchor key which is the empty

727
00:50:27,967 --> 00:50:33,136
two-key organizations key and we have
developed a preliminary schemas for

728
00:50:33,136 --> 00:50:35,655
validating the keys, and the data.

729
00:50:37,668 --> 00:50:42,820
And how do we support the real time
data distribution and access control?

730
00:50:42,820 --> 00:50:48,204
We will continue to use the existing

731
00:50:48,204 --> 00:50:51,975
NDN libraries and code.

732
00:50:51,975 --> 00:50:55,796
For the subscription to the data,

733
00:50:55,796 --> 00:51:01,593
we will use the PSync library
which has a Pub/Sub API

734
00:51:01,593 --> 00:51:06,490
to discover and subscribe to data streams.

735
00:51:07,490 --> 00:51:12,321
And then the producers
are here is actually just

736
00:51:12,321 --> 00:51:17,756
the md2k center after they
have collected the data,

737
00:51:17,756 --> 00:51:25,033
they will use the name based access
control scheme to protect the data.

738
00:51:25,033 --> 00:51:31,016
The data is encrypted based on
the access control policies.

739
00:51:31,016 --> 00:51:38,303
Here we need to develop a schema to
specify these access control policies.

740
00:51:38,303 --> 00:51:40,920
Here is just an example.

741
00:51:40,920 --> 00:51:46,023
For example, the users who
are allowed to access the data,

742
00:51:46,023 --> 00:51:52,350
here you can specify which data
set the user is allowed to access.

743
00:51:52,350 --> 00:51:57,300
And the user is only allowed
to access a user's data if

744
00:51:57,300 --> 00:52:01,370
the timestamp is between 9 AM and
6 PM, and

745
00:52:01,370 --> 00:52:05,660
the location is in this person's office,
and

746
00:52:05,660 --> 00:52:10,060
the permission is to read
not to write the data.

747
00:52:10,060 --> 00:52:18,318
So we will develop this kind of schema to
specify the access control policies and

748
00:52:18,318 --> 00:52:23,125
then the library will be
used to automatically

749
00:52:23,125 --> 00:52:28,809
generate the keys to site to encrypt and
sign the data.

750
00:52:28,809 --> 00:52:33,535
And then use the next scheme to distribute

751
00:52:33,535 --> 00:52:38,270
the key encryption and decryption keys.

752
00:52:40,530 --> 00:52:44,388
>> Have about another minute.

753
00:52:44,388 --> 00:52:49,909
>> Okay, so in this past summer,
we have developed a next scheme

754
00:52:49,909 --> 00:52:56,289
that can enforce policies that have
spatial and temporal attributes.

755
00:52:56,289 --> 00:53:02,931
For example, you can specify the time
interval and the location of the user and

756
00:53:02,931 --> 00:53:08,880
my student launching will present
this particular scheme tomorrow.

757
00:53:10,010 --> 00:53:11,617
This is the last slide.

758
00:53:11,617 --> 00:53:13,672
The project hasn't started yet.

759
00:53:13,672 --> 00:53:16,420
It will officially start next month.

760
00:53:16,420 --> 00:53:19,673
And when the system is ready,

761
00:53:19,673 --> 00:53:25,529
we plan to do a trial deployment
over the NDN test bed,

762
00:53:25,529 --> 00:53:30,996
so that researchers can
connect to the test bed and

763
00:53:30,996 --> 00:53:34,660
receive the data in real-time.

764
00:53:34,660 --> 00:53:42,264
And this, we have a team composed of me
and the three students from my group.

765
00:53:42,264 --> 00:53:47,125
Santosh Kumar and
Nasir Ali who is a research assistant

766
00:53:47,125 --> 00:53:52,842
professor in my department, and
Lixia and two of her students.

767
00:53:52,842 --> 00:53:57,649
The website is at mguarded.md2k.org.

768
00:53:57,649 --> 00:54:00,757
That's for the presentation.

769
00:54:00,757 --> 00:54:02,074
>> Thank you, Lan.

770
00:54:02,074 --> 00:54:03,652
Are there any questions?

771
00:54:03,652 --> 00:54:06,553
Think we have time for this one?

772
00:54:11,762 --> 00:54:12,998
>> Okay.

773
00:54:18,250 --> 00:54:19,771
Hey, hear me?

774
00:54:19,771 --> 00:54:20,325
>> Yes.

775
00:54:20,325 --> 00:54:21,262
>> Yes.

776
00:54:21,262 --> 00:54:24,152
>> Hi, this is a Ageque from Canada.

777
00:54:24,152 --> 00:54:29,162
I want to ask the professor
plan one is have

778
00:54:29,162 --> 00:54:33,745
you ever considered combined NDN with

779
00:54:33,745 --> 00:54:39,056
the IPMFS all together
to do the same thing?

780
00:54:43,683 --> 00:54:49,342
>> We actually discussed internally

781
00:54:49,342 --> 00:54:53,444
about IPFS a while back.

782
00:54:53,444 --> 00:54:59,722
So I think they're trying to do
what NDN is trying to achieve,

783
00:54:59,722 --> 00:55:07,103
but at a higher level at the application
level and being a network layer.

784
00:55:10,844 --> 00:55:17,134
Being an architecture that
starts from the network layer,

785
00:55:17,134 --> 00:55:21,675
I think NDN has some advantages over IPFS.

786
00:55:21,675 --> 00:55:28,096
So I think for this project,

787
00:55:28,096 --> 00:55:36,397
we we are not going to try to use IPFS.

788
00:55:36,397 --> 00:55:41,192
But because NDN already
provides the capabilities

789
00:55:41,192 --> 00:55:45,380
of what IPFS track is trying to achieve.

790
00:55:45,380 --> 00:55:50,390
At least for this particular project,
we can just directly use NDN.

791
00:55:52,690 --> 00:55:54,040
>> Thank you.

792
00:55:54,040 --> 00:55:57,720
>> Yeah, well,
it just is the I would stand for file.

793
00:55:57,720 --> 00:56:02,800
So therefore I think ipfs
handles the file objects

794
00:56:02,800 --> 00:56:06,590
as opposed to hear more
generic data objects.

795
00:56:07,940 --> 00:56:13,709
It's a kind of design the into
the system as opposed

796
00:56:13,709 --> 00:56:20,969
to running an overlay on top of
underlying delivery substrate.

797
00:56:25,913 --> 00:56:30,500
>> Okay, so thank you Lamb,
very nice presentation.

798
00:56:30,500 --> 00:56:32,990
The last talk of the session is.

799
00:56:34,400 --> 00:56:39,160
From Ilya Balding, he is the director for
network research and

800
00:56:39,160 --> 00:56:41,410
infrastructure at Renzi.

801
00:56:41,410 --> 00:56:46,310
He has played a leading leading
role in deploying EXA Genie and

802
00:56:46,310 --> 00:56:50,160
then now he is the lead bi for fabric.

803
00:56:50,160 --> 00:56:55,228
He's going to share with us a talk on
fabric scan capabilities and use cases.

804
00:57:06,142 --> 00:57:11,990
>> Ilya can you share your screen please.

805
00:57:11,990 --> 00:57:15,780
>> Susmit,
I think Ilya is having trouble connecting,

806
00:57:17,780 --> 00:57:21,700
okay, replied to his email with
the phone number to dial in instead.

807
00:57:22,860 --> 00:57:25,280
I don't know what are you able to do so
in time.

808
00:57:27,630 --> 00:57:30,670
>> Do you want me to share the slides?

809
00:57:32,200 --> 00:57:33,620
>> If he does dialing.

810
00:57:33,620 --> 00:57:35,610
I gave him the number the blue
jeans dialing number.

811
00:57:37,260 --> 00:57:38,990
>> Okay.
Just a minute.

812
00:57:38,990 --> 00:57:44,570
>> Let me get it ready
in case he can join, but

813
00:57:44,570 --> 00:57:47,090
if you want to move it to another session,
that's fine.

814
00:57:50,330 --> 00:57:56,113
>> We can probably start the panel and
if he shows up,

815
00:57:56,113 --> 00:58:01,222
we give him an opportunity
after the panel.

816
00:58:01,222 --> 00:58:02,900
>> Thank you.

817
00:58:02,900 --> 00:58:07,145
>> Thank you Susmit and
all the presenters.

818
00:58:07,145 --> 00:58:10,706
Christos, are you ready?

819
00:58:10,706 --> 00:58:14,755
>> Yes, I am here.

820
00:58:14,755 --> 00:58:15,576
>> All right.

821
00:58:15,576 --> 00:58:16,640
Thank you, everybody.

822
00:58:17,860 --> 00:58:21,290
So we're moving on to
the automotive panel and

823
00:58:22,760 --> 00:58:27,720
a pleasure to welcome the three
panelists on the automotive panel.

824
00:58:27,720 --> 00:58:33,207
Mike Westra from Ford, Ted Guild from
MIT and W3C and Tao Zhang from NIST,

825
00:58:33,207 --> 00:58:39,240
this is gonna be a slightly different
panel, we don't have any slides.

826
00:58:39,240 --> 00:58:45,200
And I think that's the right approach for
a panel on automotive

827
00:58:45,200 --> 00:58:51,670
networking which seems to be fairly new,
very new rather in the Indian community.

828
00:58:51,670 --> 00:58:56,970
So, we will have about ten minute
introductions from each of the panelists

829
00:58:56,970 --> 00:59:01,830
and then we will devote the time to
taking questions from the audience and

830
00:59:01,830 --> 00:59:06,360
even give you an opportunity for the
panelists to ask questions to each other.

831
00:59:07,390 --> 00:59:10,820
I am very excited about
automotive networking.

832
00:59:10,820 --> 00:59:14,000
To me, it seems that it's
a new frontier in networking.

833
00:59:15,000 --> 00:59:20,040
And with this panel, I think it's
a great opportunity to hear from people

834
00:59:20,040 --> 00:59:24,980
who are deep into the automotive
world industry, data.

835
00:59:26,430 --> 00:59:33,090
Sharing and standards and so
forth and also new types of uses for

836
00:59:33,090 --> 00:59:38,440
smart and connected vehicles,
including remote controlled cars.

837
00:59:38,440 --> 00:59:41,380
The automotive networks are unique.

838
00:59:41,380 --> 00:59:47,430
They do combine pretty much everything
that we've done as networking researchers.

839
00:59:47,430 --> 00:59:53,230
So there is large data coming
out of multiple cameras in cars.

840
00:59:53,230 --> 00:59:56,640
And from HD cameras and lighters.

841
00:59:56,640 --> 00:59:59,680
There's real time requirements.

842
00:59:59,680 --> 01:00:03,570
Obviously, there's a lot of heterogeneous
communication between different

843
01:00:03,570 --> 01:00:04,620
components.

844
01:00:04,620 --> 01:00:08,490
There's aspects of IOT given
all the various ECU and

845
01:00:08,490 --> 01:00:10,960
other sensors that are in a car.

846
01:00:10,960 --> 01:00:15,190
But it also goes through areas
such as cloud computing,

847
01:00:15,190 --> 01:00:17,510
where telematics is being collected.

848
01:00:17,510 --> 01:00:24,070
There's edge computing where data has
been processed for video x communication.

849
01:00:24,070 --> 01:00:27,970
There's a lot of security and
privacy issues and of course

850
01:00:27,970 --> 01:00:32,810
on top of all of that, the industry has to
deal with cars that can be on the road for

851
01:00:32,810 --> 01:00:39,640
the next ten twenty years and
potentially support these cars and

852
01:00:39,640 --> 01:00:43,750
keep them up to date for the safety and
cyber security and so forth.

853
01:00:45,260 --> 01:00:50,640
So, pretty tall order for
the automotive industry in this regard.

854
01:00:50,640 --> 01:00:56,150
The other challenge comes from telematics
or the data that comes from cars.

855
01:00:56,150 --> 01:00:59,330
We've heard the expression
there are sensors on wheels.

856
01:00:59,330 --> 01:01:04,210
And all these data has great potential
to benefit the drivers in terms of

857
01:01:04,210 --> 01:01:06,770
maintenance, in terms of safety.

858
01:01:06,770 --> 01:01:10,030
In terms of monitoring vehicles for
intrusions and

859
01:01:10,030 --> 01:01:15,140
providing cybersecurity, but also other
users such as the insurance company,

860
01:01:15,140 --> 01:01:19,620
who would love to have these data to
create better insurance models and

861
01:01:19,620 --> 01:01:24,150
hopefully help the rest of us
with reduced interest rates.

862
01:01:24,150 --> 01:01:28,040
The data can also benefit society.

863
01:01:28,040 --> 01:01:32,180
We've seen cases with connected cars,

864
01:01:32,180 --> 01:01:35,240
where the cars in front of you
alert the cars behind them for

865
01:01:35,240 --> 01:01:40,550
hazards and making the road safer for
everybody else.

866
01:01:40,550 --> 01:01:45,500
But of course with all the data come big
issues in privacy, data ownership and

867
01:01:45,500 --> 01:01:46,039
so forth.

868
01:01:47,040 --> 01:01:53,270
And finally as we're moving into level
four, level five autonomous vehicles, and

869
01:01:53,270 --> 01:01:58,820
as we are working on societal acceptance
and driver acceptance and so forth,

870
01:01:58,820 --> 01:02:04,168
there's issues that we can
explore on the way there.

871
01:02:04,168 --> 01:02:08,610
For example, Tao was working on
remotely controlled vehicles,

872
01:02:09,830 --> 01:02:14,910
which, could be thought as an inter
in STEM to autonomous vehicles.

873
01:02:14,910 --> 01:02:19,690
But it could also be thought,
as a model, by itself.

874
01:02:19,690 --> 01:02:23,990
Looking at the future of smart vehicles.

875
01:02:23,990 --> 01:02:28,780
So, with that, hopefully brief
introduction, I will let our panelists

876
01:02:28,780 --> 01:02:33,600
give us a brief introduction of
themselves and talk about these

877
01:02:33,600 --> 01:02:39,620
the issues that their industry and
organizations are concerned about.

878
01:02:39,620 --> 01:02:44,720
And then we will move on to
discussion the sequence will be

879
01:02:44,720 --> 01:02:49,050
I will have Mike Westra from Ford first,
followed by Ted Guild.

880
01:02:49,050 --> 01:02:53,560
And then finally, Tao from NIST.

881
01:02:53,560 --> 01:02:57,390
So Mike,
if you're ready please go ahead and

882
01:02:57,390 --> 01:03:01,380
unmute and give us your perspective.

883
01:03:02,460 --> 01:03:05,441
>> Okay.
Great, thank you, can you hear me?

884
01:03:05,441 --> 01:03:06,121
>> Yeah.

885
01:03:06,121 --> 01:03:07,841
>> [COUGH] You can.

886
01:03:07,841 --> 01:03:10,625
I'm Mike Westra.

887
01:03:10,625 --> 01:03:17,780
I'm the manager of connected product
cyber security at Ford Motor Company

888
01:03:19,360 --> 01:03:24,568
and, to just want to thank everybody
on the panel for being here today.

889
01:03:24,568 --> 01:03:31,680
And so Christos asked to kind of highlight
really quickly in just a minute or two,

890
01:03:31,680 --> 01:03:38,963
some of the challenges that automakers
are facing around data at the moment.

891
01:03:38,963 --> 01:03:43,550
And so he highlighted especially

892
01:03:43,550 --> 01:03:47,970
the data that's being collected
into the back end and

893
01:03:47,970 --> 01:03:52,170
it's kind of a confluence
of cyber security and

894
01:03:53,260 --> 01:03:58,830
government policy in some ways
ironically at the at the moment.

895
01:03:58,830 --> 01:03:59,910
So Europe.

896
01:03:59,910 --> 01:04:03,520
Is kinda working through a lot
of the challenges right now, and

897
01:04:03,520 --> 01:04:06,871
there's a couple of models
that they've explored from.

898
01:04:06,871 --> 01:04:13,351
So their end goal is to provide
sort of an open ecosystem,

899
01:04:13,351 --> 01:04:18,481
where the data can be
shared among interested

900
01:04:18,481 --> 01:04:24,423
parties based on the model
that you're looking at.

901
01:04:24,423 --> 01:04:28,470
It's kinda along a continuum
from the OEMs, or

902
01:04:28,470 --> 01:04:35,060
kinda intended to be the stewards of
the data with an extended sorta vehicle.

903
01:04:35,060 --> 01:04:39,725
And this can be data from
what had historically been

904
01:04:39,725 --> 01:04:44,240
repair data all the way to geolocation
data, driving behavior data.

905
01:04:44,240 --> 01:04:46,600
So there's obviously
a lot of PII concerns.

906
01:04:47,720 --> 01:04:52,870
So from one end to the extreme where
the automakers are kinda the stewards,

907
01:04:52,870 --> 01:04:56,270
Europe seems to be advocating
a neutral server sort of approach,

908
01:04:56,270 --> 01:05:02,000
where there's a neutral server that is
kinda where the data gets collected.

909
01:05:02,000 --> 01:05:07,120
To requirements that the vehicle directly

910
01:05:07,120 --> 01:05:12,666
connect to any third party, theoretically,

911
01:05:12,666 --> 01:05:18,485
the user has authorized
to collect that data.

912
01:05:18,485 --> 01:05:23,435
To even some models that some of the
aftermarket folks are advocating, where it

913
01:05:23,435 --> 01:05:29,325
mandates that their code actually execute
inside of the safety vehicle environment,

914
01:05:29,325 --> 01:05:35,210
which automakers have a great
deal of sort of heartburn over.

915
01:05:35,210 --> 01:05:38,780
I'll focus mostly on kinda the side, and

916
01:05:38,780 --> 01:05:44,290
some of the challenges really
are data collection is not free.

917
01:05:44,290 --> 01:05:47,120
And so a lot of the expectation,

918
01:05:47,120 --> 01:05:51,810
unfortunately from some of
the aftermarket folks has been, well,

919
01:05:51,810 --> 01:05:55,948
we'll make you guys collect the data and
then and then give it to us.

920
01:05:55,948 --> 01:06:00,860
And that's kinda unfortunately
the approach that's occurring in some

921
01:06:00,860 --> 01:06:04,493
places in the US as the policy
battle is being fought.

922
01:06:04,493 --> 01:06:09,900
It's supposed extension
of right to repair.

923
01:06:09,900 --> 01:06:14,793
The challenges is less,
the normal IT kinds of

924
01:06:14,793 --> 01:06:19,685
mechanisms to share the data with PKI and
TLS,

925
01:06:19,685 --> 01:06:24,210
and some of that, is fairly well adapted.

926
01:06:24,210 --> 01:06:29,760
The bigger challenge is around
a lot of the policy aspects.

927
01:06:29,760 --> 01:06:34,700
And so there's a lot of hand waving on,
well, who's gonna authorize that

928
01:06:35,880 --> 01:06:40,310
customers and entities are really
truly who they say they are?

929
01:06:40,310 --> 01:06:44,040
And that's really
the cracks of the problem.

930
01:06:44,040 --> 01:06:46,150
It's less the technical aspects,

931
01:06:46,150 --> 01:06:50,970
and it's really boils down to much
more of a policy kinda concern.

932
01:06:50,970 --> 01:06:55,490
Where, historically,
the OEM is kinda the steward of the data,

933
01:06:55,490 --> 01:06:58,204
steward of the customer.

934
01:06:58,204 --> 01:07:02,855
Folks are trying to challenge that,
and then there's not

935
01:07:02,855 --> 01:07:07,970
sorta the corresponding understanding of,
well, how do I know that this person

936
01:07:07,970 --> 01:07:13,380
that is demanding data from a particular
vehicle is in fact the customer?

937
01:07:13,380 --> 01:07:18,940
Or is truly a valid aftermarket,

938
01:07:18,940 --> 01:07:21,610
entity that should actually
have access to the data?

939
01:07:21,610 --> 01:07:26,480
One of the things that we fortunately
do see when we look at the data for

940
01:07:26,480 --> 01:07:29,980
right to repair data,
we see a lot of data that comes in from

941
01:07:31,750 --> 01:07:34,930
places in China and Eastern Europe.

942
01:07:34,930 --> 01:07:39,600
And the data isn't sort of
as sensitive today, but

943
01:07:39,600 --> 01:07:46,990
there's certainly a large concern
just handing over sensitive PII data

944
01:07:46,990 --> 01:07:51,797
to entities that haven't been
properly sorta authenticated.

945
01:07:53,160 --> 01:08:00,630
And truly capturing customer consent,
that they really want that data exchanged.

946
01:08:00,630 --> 01:08:06,410
And so a lot of those policy areas
are really underdeveloped or

947
01:08:06,410 --> 01:08:09,110
not really robustly defined.

948
01:08:09,110 --> 01:08:14,740
As well as just the business aspects of,
well, who's paying to collect that data?

949
01:08:14,740 --> 01:08:20,290
Because cellular data is not free nor
necessarily cheap in mass.

950
01:08:20,290 --> 01:08:24,210
And so there's a lot of challenges that
will need to get sorted out probably over

951
01:08:24,210 --> 01:08:30,160
the next couple of years as to how
that how that's all going to work.

952
01:08:30,160 --> 01:08:32,940
And so it's less on the vehicle side, but

953
01:08:32,940 --> 01:08:36,560
it's a lot more on how is
the data gonna be managed.

954
01:08:36,560 --> 01:08:39,190
So that's what I've got to share.

955
01:08:39,190 --> 01:08:42,270
So Chris, if you want to hand
it off to the next person.

956
01:08:44,200 --> 01:08:44,820
>> Thank you, Mike.

957
01:08:44,820 --> 01:08:45,756
Thank you.
Thank you for

958
01:08:45,756 --> 01:08:48,413
highlighting all these
important issues with data.

959
01:08:48,413 --> 01:08:51,287
So Ted, we'll let you come in.

960
01:08:51,287 --> 01:08:56,050
And I'm sure you have a few
things to say about data.

961
01:08:56,050 --> 01:08:57,437
So go ahead.

962
01:08:57,437 --> 01:08:59,993
>> Sure, my name is Ted Guild.

963
01:08:59,993 --> 01:09:04,523
I'm a researcher at MIT where
I've been the last 20 years.

964
01:09:04,523 --> 01:09:09,563
A good chunk of that has been, well,
all that's been working for the W3C.

965
01:09:09,563 --> 01:09:14,304
Good chunk, that is the head of IT
organization where we also did,

966
01:09:14,304 --> 01:09:19,048
not just the infrastructure for
the organization and defenses for

967
01:09:19,048 --> 01:09:24,230
ourselves, but working on sort of
new web security sort of prototypes.

968
01:09:26,010 --> 01:09:29,070
Try to sorta lead by example kinda thing.

969
01:09:29,070 --> 01:09:34,090
Currently, I am the lead of
the WC automotive activity,

970
01:09:34,090 --> 01:09:35,870
which I'll describe in brief.

971
01:09:35,870 --> 01:09:41,673
I'm also the stock contact for
the geospatial on the web activity.

972
01:09:41,673 --> 01:09:46,275
And I also do some secondary research on

973
01:09:46,275 --> 01:09:50,744
connective vehicles and [INAUDIBLE].

974
01:09:50,744 --> 01:09:56,900
So in brief,
the [INAUDIBLE] vehicle ecosystem.

975
01:09:56,900 --> 01:10:01,630
It's also possible to run this on data
that's already been off boarded and

976
01:10:01,630 --> 01:10:04,160
resides in the cloud.

977
01:10:04,160 --> 01:10:06,530
We're using a common data model.

978
01:10:06,530 --> 01:10:09,580
Every auto manufacturer
currently does data differently,

979
01:10:09,580 --> 01:10:13,750
which makes trying to normalize and
use that more difficult.

980
01:10:13,750 --> 01:10:17,829
And I'm enjoying a Mike Westra's
photo problem in the background.

981
01:10:19,130 --> 01:10:22,960
Better someone's messing
with him real time.

982
01:10:22,960 --> 01:10:25,739
Always be careful of security conferences,
even remote ones.

983
01:10:25,739 --> 01:10:32,120
So come in data model,
we're joined in collaboration Genivi.

984
01:10:32,120 --> 01:10:34,840
We're using web technologies because
the various people that are.

985
01:10:36,330 --> 01:10:40,590
OEMs, something they've watched it in
the vehicle now established partnerships,

986
01:10:40,590 --> 01:10:44,480
some they may be coerced to in time.

987
01:10:44,480 --> 01:10:47,680
These guys are not
the Automotive Engineers.

988
01:10:47,680 --> 01:10:51,720
But most of them should be familiar
with web technologies since

989
01:10:51,720 --> 01:10:55,130
that's the most dominant platform
on the planet on the planet.

990
01:10:56,380 --> 01:10:57,570
We're bringing to the cloud.

991
01:10:57,570 --> 01:11:03,010
We have an ontology that we build on
top of this common data model, the SSO,

992
01:11:03,010 --> 01:11:08,100
which enables artificial intelligence
machine learning, various analytics and

993
01:11:09,120 --> 01:11:13,020
enables WC's web of things, which is
an abstraction layer on top of IoT,

994
01:11:13,020 --> 01:11:16,990
which is fragmented as badly
if not worse than automotive.

995
01:11:16,990 --> 01:11:22,210
Ask for help sorta abstract out normalize
things and you can define a car as

996
01:11:22,210 --> 01:11:28,570
a thing on the WC's web of things, decide
what capabilities you want to expose.

997
01:11:30,420 --> 01:11:35,016
There's also sort of a whole laundry
list of things that this sorta opens up.

998
01:11:35,016 --> 01:11:39,804
As far as these technologies,
there's definitely a need for it and

999
01:11:39,804 --> 01:11:45,684
via best practices, things that can help
other manufacturers feel comfortable,

1000
01:11:45,684 --> 01:11:51,732
laying people in as far as this periodic
reviews, what they're allowed to awkward,

1001
01:11:51,732 --> 01:11:57,276
that sort of a resources making sure
that in bandwidth is being paid for

1002
01:11:57,276 --> 01:12:01,380
in a reasonable and
ideally non-discriminatory turns.

1003
01:12:02,505 --> 01:12:03,691
Various things like that.

1004
01:12:03,691 --> 01:12:09,275
We're also have a few things on the back
burner as far as going forward.

1005
01:12:09,275 --> 01:12:12,782
I try to stay on
the technical solutions and

1006
01:12:12,782 --> 01:12:16,199
avoid the political topics in the space.

1007
01:12:16,199 --> 01:12:19,202
But of course, I have my own views,

1008
01:12:19,202 --> 01:12:23,710
I think that there is
a possibility to have a medium and

1009
01:12:23,710 --> 01:12:30,339
safe environment between OEMs, these
third parties are clamoring for data.

1010
01:12:30,339 --> 01:12:33,431
And I agree that is if OEMs
are incurring costs and

1011
01:12:33,431 --> 01:12:36,229
provides to them, they should be charged.

1012
01:12:40,471 --> 01:12:42,036
>> Very good.

1013
01:12:42,036 --> 01:12:43,071
Thank you, Ted.

1014
01:12:43,071 --> 01:12:46,445
[COUGH] All right, so
Tao, please go ahead,

1015
01:12:46,445 --> 01:12:51,200
introduce yourself and
tell us a little bit about what you do.

1016
01:12:52,470 --> 01:12:57,297
>> Okay, hi everyone,
this is Tao Zhang from NIST.

1017
01:12:57,297 --> 01:13:00,728
I joined NIST last year,
just about a year ago.

1018
01:13:00,728 --> 01:13:05,810
I manage the Emerging Network
Technologies Group at NIST.

1019
01:13:05,810 --> 01:13:10,761
So before joining NIST, I was in
the private sector, doing research and

1020
01:13:10,761 --> 01:13:14,185
product development,
and corporate strategy.

1021
01:13:14,185 --> 01:13:20,057
I was with Cisco Systems for about six
weeks, I was the CTO chief scientist for

1022
01:13:20,057 --> 01:13:23,800
Cisco's smart connected vehicles business.

1023
01:13:23,800 --> 01:13:30,086
Helped actually build that business,
and I was a chief scientist,

1024
01:13:30,086 --> 01:13:35,190
and director of research
groups in Bellcore/Telcordia.

1025
01:13:35,190 --> 01:13:40,240
So which is part of the system
over the data focus of

1026
01:13:40,240 --> 01:13:45,520
work has been vehicle to
networking andwireless.

1027
01:13:45,520 --> 01:13:50,670
So today, really a great pleasure
to be here to share with everyone

1028
01:13:50,670 --> 01:13:55,480
some thoughts as I'd like
to mention maybe two areas.

1029
01:13:55,480 --> 01:14:03,070
One of them, so we all know as Ted and
Mike mentioned already,

1030
01:14:03,070 --> 01:14:09,310
data generated by the cars
is an tremendous new issue.

1031
01:14:09,310 --> 01:14:14,670
And we all know there's a ton of data
being generated on an hourly basis,

1032
01:14:14,670 --> 01:14:20,030
those are the data we need to train our
machine learning models to do things,

1033
01:14:20,030 --> 01:14:25,272
to monitor the car, to control the car,
and to protect a car.

1034
01:14:25,272 --> 01:14:32,340
So currently, what we do is that we
send all this data to the cloud.

1035
01:14:32,340 --> 01:14:34,710
And we train machine learning
models over there and

1036
01:14:34,710 --> 01:14:37,810
that was sent the models
back to the cars to use.

1037
01:14:37,810 --> 01:14:43,640
And sending those data to the cloud
is getting more and more invisible.

1038
01:14:43,640 --> 01:14:49,801
So then the question is,
did we explore other other capabilities?

1039
01:14:49,801 --> 01:14:51,790
For example, agile learning.

1040
01:14:51,790 --> 01:14:56,730
Can we have those cars to learn locally?

1041
01:14:56,730 --> 01:14:59,660
But of course, the cars
are limited in process and powers,

1042
01:14:59,660 --> 01:15:01,990
they're limited in data,
even though they have a lot,

1043
01:15:01,990 --> 01:15:05,450
but they don't have to global view of it,
everything.

1044
01:15:05,450 --> 01:15:10,090
And the question is what
can those cars learn?

1045
01:15:10,090 --> 01:15:14,580
And how can they share the knowledge
they learned from their local data

1046
01:15:14,580 --> 01:15:15,940
with the cloud?

1047
01:15:15,940 --> 01:15:20,296
So the cloud rather than collecting
raw data from every cars,

1048
01:15:20,296 --> 01:15:25,842
can be collecting knowledge learned by
the cars and transferred to the cloud.

1049
01:15:25,842 --> 01:15:32,547
And then they can leverage those to
build better and more powerful models.

1050
01:15:32,547 --> 01:15:37,277
So the knowledge learn, for example,
in terms of machine learning models,

1051
01:15:37,277 --> 01:15:39,894
parameters and so on, and it will be much,

1052
01:15:39,894 --> 01:15:43,400
much smaller than
the size of the raw data.

1053
01:15:43,400 --> 01:15:44,310
And so

1054
01:15:44,310 --> 01:15:48,859
that's one of the areas I think maybe
worth while looking into in the future.

1055
01:15:50,350 --> 01:15:55,990
Another area is over the past several
yeas, two, three years I will say,

1056
01:15:55,990 --> 01:16:01,640
and there is an increasing amount
of effort in the industry and

1057
01:16:01,640 --> 01:16:08,300
developing not just self driving cars but
remote controlled cars.

1058
01:16:08,300 --> 01:16:12,599
So remote driving are tiny operation.

1059
01:16:12,599 --> 01:16:17,982
So today for example, that effort
has been focused mostly on use and

1060
01:16:17,982 --> 01:16:23,556
human remote drivers to help autonomous
cars to handle tougher tricky

1061
01:16:23,556 --> 01:16:29,807
cases that the cars themselves do not
have enough intelligence to handle yet.

1062
01:16:29,807 --> 01:16:33,849
And there happens to be quite a lot still.

1063
01:16:33,849 --> 01:16:38,550
And they are already a lot of
interesting issues over there,

1064
01:16:38,550 --> 01:16:42,770
trying to overcome.

1065
01:16:42,770 --> 01:16:45,680
But for researchers,

1066
01:16:45,680 --> 01:16:51,099
actually you can see bigger
potentials along that direction.

1067
01:16:52,110 --> 01:16:57,120
So we don't have to stop
at human teleoperators

1068
01:16:57,120 --> 01:17:01,790
as the network's become better
well as we move into 5G.

1069
01:17:01,790 --> 01:17:07,850
As the AI capabilities become more
advanced, you could envision that one day,

1070
01:17:07,850 --> 01:17:12,090
it could become possible that
the technologies will allow us to

1071
01:17:12,090 --> 01:17:17,290
even offload some of the driving
intelligence away from the cars.

1072
01:17:17,290 --> 01:17:21,440
And to the edge systems
to the cloud systems.

1073
01:17:21,440 --> 01:17:25,230
And so you'll see and
as sort of an interesting

1074
01:17:26,290 --> 01:17:30,760
framework that allows
you to distribute and

1075
01:17:30,760 --> 01:17:37,790
driving intelligence along that continuum
between the vehicle and the cloud.

1076
01:17:37,790 --> 01:17:42,170
And so with the two extremes being who is
the white straight away extreme being all

1077
01:17:42,170 --> 01:17:46,670
the intelligence and being placed on
the car that is what we have today.

1078
01:17:47,700 --> 01:17:52,455
And so the question then becomes,
and will that be visible,

1079
01:17:52,455 --> 01:17:56,194
how would that be visible,
what it depends on?

1080
01:17:56,194 --> 01:17:58,601
And what would you be challenges for
example,

1081
01:17:58,601 --> 01:18:02,270
people will immediately point out,
hey, what about the network?

1082
01:18:02,270 --> 01:18:07,240
What happens if the natural
delays get bad and so on?

1083
01:18:07,240 --> 01:18:08,960
So there are challenges.

1084
01:18:08,960 --> 01:18:16,330
And so that is another area that I
think maybe it was loud looking into.

1085
01:18:16,330 --> 01:18:23,530
So I'll stop there, thank you
>> Thank you, Tao, thank you very much.

1086
01:18:23,530 --> 01:18:28,630
So those were the presentations
from our presenters and

1087
01:18:28,630 --> 01:18:35,430
I do encourage the audience to ask
questions as as they come along.

1088
01:18:35,430 --> 01:18:43,330
I wanted to start by sort of addressing
what the Tao said and ask Mike.

1089
01:18:43,330 --> 01:18:47,870
So Mike,
I'll put on a very compelling view for

1090
01:18:47,870 --> 01:18:53,970
what the future of smart and
connected vehicles might look like.

1091
01:18:53,970 --> 01:18:59,150
Is this something that
the automakers are looking at?

1092
01:18:59,150 --> 01:19:03,587
Can you tell us a little bit about how
Ford and in general, the automakers,

1093
01:19:03,587 --> 01:19:07,520
are looking at the future
of autonomous vehicles?

1094
01:19:07,520 --> 01:19:12,152
Is this still l four, l five, or
are we looking at interim solutions or

1095
01:19:12,152 --> 01:19:13,498
ten alternatives?

1096
01:19:17,472 --> 01:19:22,996
>> I think you'll see this is
the state of the art advanced for

1097
01:19:22,996 --> 01:19:25,943
long to two kind of pipelines.

1098
01:19:25,943 --> 01:19:30,968
One's sort of what really
is kind of advanced and

1099
01:19:30,968 --> 01:19:35,770
those will start to bleed
into like level two.

1100
01:19:35,770 --> 01:19:40,135
And they'll have more and
more connectivity, and

1101
01:19:40,135 --> 01:19:45,719
they'll allow more to be done kind
of with the with the operator,

1102
01:19:45,719 --> 01:19:48,474
sort of ultimately in control.

1103
01:19:48,474 --> 01:19:53,259
And you'll start to see more sort
of vision systems, radar, and

1104
01:19:53,259 --> 01:19:58,840
more sensors sort of supporting that
beyond even what Tesla is doing today.

1105
01:20:00,290 --> 01:20:07,021
And then the autonomous vehicles
will kind of work from the top down,

1106
01:20:07,021 --> 01:20:11,896
where pretty much the state
of the art now is sort of

1107
01:20:11,896 --> 01:20:17,378
safety operator driven level
4 autonomous vehicles.

1108
01:20:17,378 --> 01:20:22,296
And they have probably a couple
of 100,000$ in sensors

1109
01:20:22,296 --> 01:20:25,830
that will all become
much cheaper over time.

1110
01:20:25,830 --> 01:20:33,685
I think a lot of people see those
as being more fleet centric,

1111
01:20:33,685 --> 01:20:38,779
at least for the short and medium term.

1112
01:20:38,779 --> 01:20:43,808
You read the press where a lot of
that investment is, is being driven

1113
01:20:43,808 --> 01:20:49,296
by the likes of Google and Uber,
along with the traditional automakers.

1114
01:20:49,296 --> 01:20:57,819
And so you'll see a lot of that
kind of driven lower and lower.

1115
01:20:57,819 --> 01:21:02,471
But the reality is a lot of that where
the intent there is to get rid of

1116
01:21:02,471 --> 01:21:05,891
the steering wheel and
provide sort of service.

1117
01:21:05,891 --> 01:21:11,730
That requires a whole
different level of safety and

1118
01:21:11,730 --> 01:21:19,078
compute and sensors,
sort of completely different than Edaf.

1119
01:21:19,078 --> 01:21:23,447
Where Edaf can kind of just say,
you know what it's raining,

1120
01:21:23,447 --> 01:21:27,313
I don't know how to deal
with this current situation,

1121
01:21:27,313 --> 01:21:31,110
I'm gonna make the operator
sort of deal with it.

1122
01:21:31,110 --> 01:21:35,360
level 4 has to be fully autonomous
within a geo fenced area and

1123
01:21:35,360 --> 01:21:39,180
level 5 is in theory
anywhere in the country.

1124
01:21:39,180 --> 01:21:41,390
It could fully operate autonomously and

1125
01:21:41,390 --> 01:21:46,870
I think even the most aggressive
sort of futurists say level 5

1126
01:21:46,870 --> 01:21:51,880
is quite a ways out where level 4 is
where everybody's trying to shoot

1127
01:21:51,880 --> 01:21:57,130
first a sweet spot in terms of how much
is going to be onboard versus off board.

1128
01:21:57,130 --> 01:22:01,200
I think,
I don't think we're necessarily unique.

1129
01:22:02,210 --> 01:22:07,260
In the sort of approach,
I think from a safety standpoint, and

1130
01:22:07,260 --> 01:22:14,440
this is even less cybersecurity, the final
decisions as to sort of braking, steering,

1131
01:22:14,440 --> 01:22:20,480
all of the safety operations are done
sort of locally on the edge.

1132
01:22:20,480 --> 01:22:25,180
And where the cloud comes in,
is it will help with the learning,

1133
01:22:25,180 --> 01:22:29,380
the process that the tons of
processing that's needed for maps and

1134
01:22:29,380 --> 01:22:32,370
for helping around sort of exception.

1135
01:22:32,370 --> 01:22:33,710
So the autonomous vehicle

1136
01:22:34,850 --> 01:22:39,910
encounters something it's not,it's
sort of anticipating, such as a sort

1137
01:22:40,980 --> 01:22:44,930
of construction zone that
wasn't previously known.

1138
01:22:44,930 --> 01:22:48,970
It may stop alert, the back end and

1139
01:22:48,970 --> 01:22:52,890
then have to have the back end
with some operators support.

1140
01:22:52,890 --> 01:22:56,045
Add that to the to the mapping on the fly.

1141
01:22:57,170 --> 01:23:02,330
That in routing types of sort of
macro routing types of things would

1142
01:23:02,330 --> 01:23:05,370
could be happening on the back
end the local decision.

1143
01:23:06,470 --> 01:23:11,347
In terms of this object will almost
certainly be done on the edge

1144
01:23:11,347 --> 01:23:14,027
just because of safety concerns.

1145
01:23:18,006 --> 01:23:18,570
>> Great.

1146
01:23:18,570 --> 01:23:19,090
Thank you, Mike.

1147
01:23:20,870 --> 01:23:26,560
Before I let you off the hook, Mike I,
wanted to, so well, let me do this first.

1148
01:23:26,560 --> 01:23:29,510
First of all, let me see if
the other two panelists have any.

1149
01:23:29,510 --> 01:23:34,570
Follow one on what Mike said though Tao or
Ted?

1150
01:23:34,570 --> 01:23:38,940
>> A little bit so I agree with Mike that.

1151
01:23:40,270 --> 01:23:43,940
As far as decisions things need to be
done on the edge on the vehicle itself

1152
01:23:43,940 --> 01:23:45,130
directly.

1153
01:23:45,130 --> 01:23:49,450
You don't have the time for the
turnarounds at the send something off and

1154
01:23:49,450 --> 01:23:51,070
hope for a decision.

1155
01:23:51,070 --> 01:23:55,380
But to tell us point sort of earlier
insert combining with Mike's.

1156
01:23:55,380 --> 01:24:01,650
I do want that information to be off
boarded as well and sort of feed.

1157
01:24:01,650 --> 01:24:03,490
Right now we're seeing quite

1158
01:24:04,560 --> 01:24:07,990
a bit of competition sort of a race
towards autonomous vehicles and

1159
01:24:07,990 --> 01:24:12,240
automated pastures are traditionally
both collaborative and competitive.

1160
01:24:12,240 --> 01:24:15,130
Limit how and where they collaborate.

1161
01:24:15,130 --> 01:24:19,250
I think we'll see some partnerships start
emerge, more partnerships start emerged

1162
01:24:19,250 --> 01:24:23,240
around autonomous vehicles that some of
them feel there may be falling behind.

1163
01:24:23,240 --> 01:24:28,420
And I see them start to get
into federated learning and

1164
01:24:28,420 --> 01:24:34,360
be able to use the data available
on both are multiple fleets

1165
01:24:34,360 --> 01:24:38,380
from different auto manufacturers and be
able to feed those in and learn from them.

1166
01:24:38,380 --> 01:24:44,590
Because the variation of sensors and

1167
01:24:44,590 --> 01:24:49,740
these mechanics of the vehicles together
will help to create a better understanding

1168
01:24:49,740 --> 01:24:53,310
of the physical world that
these objects are moving.

1169
01:24:53,310 --> 01:24:55,680
I think I'll just,
he wants to say something as well.

1170
01:24:58,260 --> 01:24:59,040
Go ahead.
Sorry.

1171
01:25:00,070 --> 01:25:00,590
>> No, I'm good.

1172
01:25:00,590 --> 01:25:02,250
No, no, I was done.

1173
01:25:02,250 --> 01:25:02,875
Off to you, sir.

1174
01:25:02,875 --> 01:25:08,320
[BLANK_AUDO]
>> Yeah,

1175
01:25:08,320 --> 01:25:12,210
so I view this collective
learning between for

1176
01:25:12,210 --> 01:25:15,700
example and a vehicle and in the cloud.

1177
01:25:15,700 --> 01:25:20,620
Sort of as the next step, we do a lot of
pre processing of data on the vehicle,

1178
01:25:20,620 --> 01:25:21,320
right?

1179
01:25:21,320 --> 01:25:28,320
We try to filter out things we think,
are not useful for certain applications.

1180
01:25:28,320 --> 01:25:33,680
And we don't send everything generated
by the vehicle to the cloud or

1181
01:25:33,680 --> 01:25:38,430
IT, but this sort of collective
collaborative learning.

1182
01:25:38,430 --> 01:25:42,550
Between those two entities one and
the cloud and

1183
01:25:42,550 --> 01:25:48,140
a car sort of represent a next step, right
now, rather than sort of a selectively

1184
01:25:48,140 --> 01:25:53,590
transform, transporting data back and
forth, we actually move to one step up.

1185
01:25:53,590 --> 01:25:57,660
We actually build knowledge and we started
to select which knowledge will learn to

1186
01:25:57,660 --> 01:26:03,060
share with other people and how do you
share and sharing knowledge actually.

1187
01:26:03,060 --> 01:26:07,260
Turns out to be and
the more complicated matter.

1188
01:26:07,260 --> 01:26:14,300
And then sharing all that has that
opens up a lot of interesting research

1189
01:26:14,300 --> 01:26:19,160
questions for
the researchers on this call.

1190
01:26:19,160 --> 01:26:22,750
So that's where I think it's important and
it and

1191
01:26:22,750 --> 01:26:26,120
also this distributed sort of learning.

1192
01:26:26,120 --> 01:26:29,850
And goes beyond what
the traditional does do.

1193
01:26:29,850 --> 01:26:33,740
As you know today, distributed learning
has been going on for quite some time.

1194
01:26:35,600 --> 01:26:41,610
But they tend to focus on distributed
learning in a cloud setup.

1195
01:26:41,610 --> 01:26:42,550
So which is very,

1196
01:26:42,550 --> 01:26:48,430
very different from the collaborative
edge learning and cloud learning.

1197
01:26:48,430 --> 01:26:49,350
In the cloud, for example,

1198
01:26:49,350 --> 01:26:53,080
you will have data that's accessible
by all the distributee knows.

1199
01:26:53,080 --> 01:26:53,800
Right.

1200
01:26:53,800 --> 01:26:56,780
And it's the same day and they did it.

1201
01:26:56,780 --> 01:26:58,390
Yeah.
The computers and

1202
01:26:58,390 --> 01:27:03,490
the cloud nodes are not that
limited by processing power.

1203
01:27:03,490 --> 01:27:09,130
They're much secure and much more secure
than for example, the edge nodes.

1204
01:27:09,130 --> 01:27:12,780
And so you can have different
ways to handle robustness and

1205
01:27:12,780 --> 01:27:15,015
trustworthiness of the models.

1206
01:27:16,050 --> 01:27:22,670
And when you have sort of cars
helping you learn, and all of those

1207
01:27:22,670 --> 01:27:28,710
fundamental assumptions change and
most of them don't hold true anymore.

1208
01:27:28,710 --> 01:27:32,570
That impacts the way you develop
methods and methods for learning so

1209
01:27:34,790 --> 01:27:40,040
and in the future,
not even very far future.

1210
01:27:40,040 --> 01:27:44,491
So, those learning at edge
may become a necessity just

1211
01:27:44,491 --> 01:27:49,041
because the sheer amount of
data you're generating and

1212
01:27:49,041 --> 01:27:53,683
you can or you don't want to
send them all into the cloud so

1213
01:27:53,683 --> 01:27:56,712
they just sort of want to add to that.

1214
01:27:59,225 --> 01:27:59,890
>> Very good.

1215
01:27:59,890 --> 01:28:00,540
Thank you Tao.

1216
01:28:02,090 --> 01:28:05,412
Another question for
all three of you right now.

1217
01:28:05,412 --> 01:28:12,560
So we're seeing sort of a convergence
between internet technologies and

1218
01:28:12,560 --> 01:28:19,352
automotive communication systems and part
of it has been facilitated by the move.

1219
01:28:19,352 --> 01:28:25,590
Or the apparent adoption
of automotive Ethernet

1220
01:28:25,590 --> 01:28:30,180
by the automotive industry,
which, with automotive Ethernet,

1221
01:28:30,180 --> 01:28:35,980
we're now looking at much higher speeds,
much bigger packets.

1222
01:28:35,980 --> 01:28:40,610
An environment where
the internet folks now feel

1223
01:28:40,610 --> 01:28:44,740
more comfortable in terms of bringing in
technologies that they've developed for

1224
01:28:44,740 --> 01:28:50,020
the internet such as security encryption,
authentication and so forth.

1225
01:28:50,020 --> 01:28:53,289
Our audience is mostly
internet researchers.

1226
01:28:54,650 --> 01:29:00,880
So what would you like to see
from internet researchers

1227
01:29:00,880 --> 01:29:06,270
in terms of contributing or
collaborating with the automotive sector?

1228
01:29:06,270 --> 01:29:09,052
Are there other good opportunities?

1229
01:29:09,052 --> 01:29:13,496
Are there obvious things
that the automotive sector

1230
01:29:13,496 --> 01:29:17,441
can collaborate with internet researchers?

1231
01:29:22,942 --> 01:29:26,022
>> Sure, I'll take the first swing at it.

1232
01:29:26,022 --> 01:29:29,800
I think yeah, I mean,

1233
01:29:29,800 --> 01:29:35,520
it's very true that sort of Ethernet
is becoming kind of a, I think well.

1234
01:29:36,640 --> 01:29:42,170
V the default high speed link and
things like flex Ray and

1235
01:29:42,170 --> 01:29:47,790
most will probably be
eclipsed by it fairly quickly

1236
01:29:47,790 --> 01:29:51,610
that some automakers had used for
high speed links.

1237
01:29:51,610 --> 01:29:57,210
That doesn't mean that is necessarily
going away anytime soon for real time and

1238
01:29:57,210 --> 01:30:02,540
other uses I had, our sort

1239
01:30:02,540 --> 01:30:08,310
of lead network expert kinda
described it this way.

1240
01:30:08,310 --> 01:30:14,060
Unlike a somebody who's setting up sort
of an IT network on an enterprise,

1241
01:30:14,060 --> 01:30:17,790
where they have to, basically make
sure that the network is set up.

1242
01:30:17,790 --> 01:30:22,660
You've got dozens, in hundreds,
or thousands of clients.

1243
01:30:22,660 --> 01:30:26,710
It's kind of the opposite in a vehicle.

1244
01:30:26,710 --> 01:30:28,510
You need determinism, reliability,

1245
01:30:28,510 --> 01:30:32,900
and you're building the same
relatively small network with maybe.

1246
01:30:34,450 --> 01:30:38,060
Anywhere from four to a couple
of dozen nodes on it, but

1247
01:30:38,060 --> 01:30:41,890
you're building that same network
a million different times.

1248
01:30:41,890 --> 01:30:47,010
And it's in your basically
replicating it nearly identically,

1249
01:30:47,010 --> 01:30:51,410
sort of a million times as
you're building vehicles, and

1250
01:30:51,410 --> 01:30:56,340
you need to make sure that that
network behaves reliably and

1251
01:30:56,340 --> 01:31:00,390
sort of operates consistently.

1252
01:31:00,390 --> 01:31:04,090
And then just from a sort
of a technology standpoint,

1253
01:31:04,090 --> 01:31:08,500
I think on the wire,
you're gonna see a number of similarities.

1254
01:31:08,500 --> 01:31:12,949
So you'll still have TCP/IP and UDP.

1255
01:31:12,949 --> 01:31:18,887
On the wire, the physical wiring will be
different just because of some of the,

1256
01:31:18,887 --> 01:31:19,419
>> [COUGH]

1257
01:31:19,419 --> 01:31:22,340
>> Unique physical properties in

1258
01:31:22,340 --> 01:31:27,056
the vehicle, and
some of the cost constraints and

1259
01:31:27,056 --> 01:31:31,885
you may see a few additional
things on the network,

1260
01:31:31,885 --> 01:31:39,314
such as sort of time synchronization for
media and some other types of things.

1261
01:31:39,314 --> 01:31:43,909
And you may see statically
defined networks that go back

1262
01:31:43,909 --> 01:31:48,808
to making sure that everything
is consistent and whatnot.

1263
01:31:48,808 --> 01:31:53,340
But at the same time,
from a security standpoint.

1264
01:31:53,340 --> 01:31:56,530
There's a lot of excitement,
hey, can I use VLANs?

1265
01:31:56,530 --> 01:32:02,080
Can I start to do things that add
various sort of switching and

1266
01:32:02,080 --> 01:32:06,060
firewall layers to just sort of
isolate and shape traffic for

1267
01:32:06,060 --> 01:32:11,880
that things are isolated and segregated
appropriately to keep domains separate.

1268
01:32:11,880 --> 01:32:15,510
So, I think it's similar.

1269
01:32:15,510 --> 01:32:18,070
You'll see a lot of echoes and rhymes.

1270
01:32:18,070 --> 01:32:20,920
But there'll be slight oddities and

1271
01:32:20,920 --> 01:32:24,490
differences in a real time system
like that, if that makes sense.

1272
01:32:26,840 --> 01:32:28,655
>> Yeah, great.
Thank you, Mike.

1273
01:32:28,655 --> 01:32:32,830
Tao, how do you feel about

1274
01:32:32,830 --> 01:32:37,670
this merging of internet with
the automotive environment.

1275
01:32:37,670 --> 01:32:41,140
One of the questions
that we've been asking

1276
01:32:41,140 --> 01:32:45,020
is the clearly automotive
in the automotive space.

1277
01:32:45,020 --> 01:32:50,330
There's a really important security of
indication, encryption requirements.

1278
01:32:50,330 --> 01:32:54,630
And now the automotive industry is
looking at internet technologies.

1279
01:32:54,630 --> 01:32:57,802
To leverage what we have is,

1280
01:32:57,802 --> 01:33:02,435
is do you think that would be sufficient?

1281
01:33:02,435 --> 01:33:06,710
Or do we need to work on
different approaches that suit

1282
01:33:06,710 --> 01:33:09,184
the automotive space better?

1283
01:33:09,184 --> 01:33:13,135
>> Yeah, I think that's a very,
very important question.

1284
01:33:13,135 --> 01:33:19,270
[COUGH] So
I think what we do need a lot of help

1285
01:33:19,270 --> 01:33:25,200
from the internet community in this
area insecurity and trustworthiness.

1286
01:33:25,200 --> 01:33:30,180
But I think automotive do
bring in a very unique

1287
01:33:30,180 --> 01:33:35,740
set of challenges that even today's,
state of the art security

1288
01:33:35,740 --> 01:33:41,598
paradigm that we use for the internet
[COUGH] may not be adequate enough.

1289
01:33:41,598 --> 01:33:45,977
So [COUGH] several examples and

1290
01:33:45,977 --> 01:33:50,000
incidence response.

1291
01:33:50,000 --> 01:33:54,141
And think about sort of the hallway
respond to incidences and

1292
01:33:54,141 --> 01:33:55,449
to our computers.

1293
01:33:56,570 --> 01:33:58,450
You got a virus on the computer.

1294
01:33:58,450 --> 01:34:00,070
So what do you do, right?

1295
01:34:00,070 --> 01:34:03,390
You typically send it to some expert and
the expert shutting down and

1296
01:34:03,390 --> 01:34:08,110
trying to diagnose them to replace
software, hardware, whenever necessary and

1297
01:34:08,110 --> 01:34:11,210
reboot it, and
you just simply cannot do that to a car.

1298
01:34:12,270 --> 01:34:17,330
And so [COUGH] then
the question is what do you do?

1299
01:34:18,620 --> 01:34:21,380
And I don't think we
have a good answer yet.

1300
01:34:21,380 --> 01:34:27,070
So that is and that is an area
I think people can build upon

1301
01:34:27,070 --> 01:34:32,280
what we have and to really sort of
come up with solutions for automotive.

1302
01:34:32,280 --> 01:34:35,552
I'll give you another example that
actually there are a quite I have quite

1303
01:34:35,552 --> 01:34:36,840
a long list of this.

1304
01:34:36,840 --> 01:34:43,000
Another example of sort of the uniqueness
abroad to bide automotives,

1305
01:34:43,000 --> 01:34:49,280
well, no sort of automotives are very
sensitive to cost, and the processing

1306
01:34:49,280 --> 01:34:56,260
powers as a result on the automotive side
are usually relatively more restricted.

1307
01:34:56,260 --> 01:35:01,100
And then for example our computers and
cellphones and however at

1308
01:35:01,100 --> 01:35:06,210
the same time our car needs to run on
the road for an average of 14 years.

1309
01:35:07,360 --> 01:35:09,280
So that's a long lifespan.

1310
01:35:09,280 --> 01:35:14,150
And security has this thing about,
it goes out of date very quickly so

1311
01:35:14,150 --> 01:35:17,850
you need to catch up this
security software all the time.

1312
01:35:17,850 --> 01:35:25,610
Right, you need to update it to counter
the more sort of advanced threats.

1313
01:35:25,610 --> 01:35:29,960
And over that long span of lifespan,

1314
01:35:29,960 --> 01:35:35,340
there is real sort of a high probabilities
that sometime down the road.

1315
01:35:35,340 --> 01:35:39,810
Your new security software may not be such
that your hardware on the corner may be

1316
01:35:39,810 --> 01:35:43,980
too outdated to support your
security software updates.

1317
01:35:45,670 --> 01:35:47,450
And then what do you do?

1318
01:35:47,450 --> 01:35:51,000
Right in theory, you could make
the hardware sort of plug and play.

1319
01:35:51,000 --> 01:35:53,680
You could swap them but
nobody wants to do that, right.

1320
01:35:53,680 --> 01:35:54,770
That's a hustle.

1321
01:35:54,770 --> 01:35:56,450
That's a reputation hedge.

1322
01:35:56,450 --> 01:36:01,350
That creates inconvenience,
that creates fear in the driver's minds,

1323
01:36:01,350 --> 01:36:04,690
like what's going on
with my sort of device.

1324
01:36:04,690 --> 01:36:09,670
And so
unless in a fleet environment where sort

1325
01:36:09,670 --> 01:36:14,700
of a company have an army of
experts handling their updates, and

1326
01:36:14,700 --> 01:36:20,330
even individual carmakers may sort of this
may be difficult, sort of another area for

1327
01:36:20,330 --> 01:36:25,250
example, AI is becoming more and
more embedded into.

1328
01:36:25,250 --> 01:36:30,550
Cars especially self driving cars,
and AI come with a slew of unique

1329
01:36:31,640 --> 01:36:36,250
security issues,
especially when applied to automotive and

1330
01:36:36,250 --> 01:36:40,110
people started to discover many of those.

1331
01:36:40,110 --> 01:36:46,310
And but overall, I think our understanding
of that is still very, very weak.

1332
01:36:46,310 --> 01:36:51,390
And I think sort of a better understanding
of how those AI based modules used

1333
01:36:51,390 --> 01:36:58,990
in the car will sort of impose even
more security vulnerabilities to cars.

1334
01:36:58,990 --> 01:37:01,120
I think will be a must.

1335
01:37:01,120 --> 01:37:04,879
So, yeah,
those are just some a few examples.

1336
01:37:06,540 --> 01:37:07,729
>> Thank you Tao.

1337
01:37:07,729 --> 01:37:10,887
I have relevant question
from the audience.

1338
01:37:10,887 --> 01:37:17,720
He is asking about data availability for
research in machine learning.

1339
01:37:17,720 --> 01:37:22,509
It is obviously expensive, and
also challenging to collect data

1340
01:37:22,509 --> 01:37:27,046
from multiple vehicles to do
distributed machine learning.

1341
01:37:27,046 --> 01:37:32,131
Any thoughts on how we can
help the researchers either

1342
01:37:32,131 --> 01:37:39,598
get access to high quality data or perhaps
keep the cost down of such research?

1343
01:37:39,598 --> 01:37:46,110
>> It's possible to do, is easier to
do a present with aftermarket devices.

1344
01:37:46,110 --> 01:37:50,990
As the vehicle provide their own network
connection, get reverse engineering canvas

1345
01:37:50,990 --> 01:37:55,280
that was mentioned in order to be able to
sort of leverage to make use of that data,

1346
01:37:55,280 --> 01:38:00,280
but there's enough out there for

1347
01:38:00,280 --> 01:38:04,070
number of vehicles where you can do that,
that would be my suggestion.

1348
01:38:05,485 --> 01:38:06,770
Trying to get Yen's to.

1349
01:38:10,230 --> 01:38:12,560
And their legal departments
to part with data for

1350
01:38:12,560 --> 01:38:16,530
researchers given the sensitivity of it,
maybe more of a challenge, but

1351
01:38:16,530 --> 01:38:18,430
by committee maybe respond
to that better than I.

1352
01:38:20,000 --> 01:38:21,420
>> Well, yeah.

1353
01:38:21,420 --> 01:38:24,780
And as soon as it's somehow, I mean,

1354
01:38:24,780 --> 01:38:30,060
that's, I think Venice folks know
this quite well, as soon as you.

1355
01:38:30,060 --> 01:38:34,150
Are taking data from real
customers in the field.

1356
01:38:34,150 --> 01:38:38,850
There's always that chance that you can
D anonymize it if you're clever and

1357
01:38:38,850 --> 01:38:43,850
then you're gonna do sort of legal and
privacy sort of landmines.

1358
01:38:43,850 --> 01:38:50,901
One thing I would highlight, I don't just
use University of Michigan as an example.

1359
01:38:50,901 --> 01:38:54,559
With M city and they're not the only ones,
I think Virginia Tech and

1360
01:38:54,559 --> 01:38:56,990
some others have done this.

1361
01:38:56,990 --> 01:39:04,050
They've actually done research projects
in the US case around like V2X,

1362
01:39:04,050 --> 01:39:09,080
where the research project itself
is just to get the beginning of

1363
01:39:09,080 --> 01:39:14,260
a good based data set that they
can use to build additional

1364
01:39:16,050 --> 01:39:19,630
use for additional research,
sort of after the fact.

1365
01:39:19,630 --> 01:39:25,020
And so I have seen some academics,
where they've sort of funded and

1366
01:39:25,020 --> 01:39:28,970
done actual projects to just get,
get that data and

1367
01:39:28,970 --> 01:39:34,890
what's nice in that is they'll often
pick a cart handful of mix and

1368
01:39:34,890 --> 01:39:39,170
models so that they can normalize
that data a little bit as well.

1369
01:39:39,170 --> 01:39:46,070
And that's what you'll often find if
you just pick a Ford or gym, or Toyota.

1370
01:39:46,070 --> 01:39:51,660
The data is gonna be similar but
a lot if its going to be.

1371
01:39:51,660 --> 01:39:56,480
Sort of a bit wonky to
the specific sensors or

1372
01:39:56,480 --> 01:39:59,690
how the network is put together.

1373
01:39:59,690 --> 01:40:04,770
And so that normalization is always
a tricky thing to accomplish.

1374
01:40:09,050 --> 01:40:09,790
>> Right, thanks Mike.

1375
01:40:12,400 --> 01:40:14,570
So another question I have to, I'm sorry.

1376
01:40:14,570 --> 01:40:17,026
Did you have a,
did you want to respond to them?

1377
01:40:17,026 --> 01:40:21,611
>> No, I think we should probably go
to the next one since there's a low on

1378
01:40:21,611 --> 01:40:23,264
time and probably more.

1379
01:40:23,264 --> 01:40:27,966
>> Great because the next one,
the next question Ted is for you and Mike,

1380
01:40:27,966 --> 01:40:29,010
in some sense.

1381
01:40:30,090 --> 01:40:34,370
So one, so the question I have is,

1382
01:40:34,370 --> 01:40:39,230
so both you and Mike have talked
about data coming out of cars.

1383
01:40:39,230 --> 01:40:43,440
And Ted,
you're a supporter of open data standards.

1384
01:40:43,440 --> 01:40:48,439
And making all these valuable
data available to researchers,

1385
01:40:48,439 --> 01:40:52,570
to users, to anybody who needs the data.

1386
01:40:52,570 --> 01:40:58,220
And Mike has pointed out to
the cost of collecting the data.

1387
01:40:58,220 --> 01:41:02,940
And sometimes the fact that,
those who want the data seem to

1388
01:41:02,940 --> 01:41:07,390
ignore that there's a cost
associated with collecting the data.

1389
01:41:07,390 --> 01:41:12,490
For example, the aftermarket, the old ways
claimed the right to repair and they say,

1390
01:41:12,490 --> 01:41:16,230
well, you need to give us all the data
from the car because that's our job,

1391
01:41:16,230 --> 01:41:19,160
we need the data to do the tuning and
so forth.

1392
01:41:19,160 --> 01:41:26,580
So, our open data standards,
a good idea and how do we implement them?

1393
01:41:26,580 --> 01:41:30,890
How do we go about
creating these standards?

1394
01:41:30,890 --> 01:41:36,530
So we don't disadvantage or

1395
01:41:36,530 --> 01:41:39,780
make it unfair for somebody, for

1396
01:41:39,780 --> 01:41:45,450
all the players to play in this space.

1397
01:41:45,450 --> 01:41:49,630
So Ted I know you're doing a lot of work
and you're applicating open standards,

1398
01:41:49,630 --> 01:41:53,110
I wanted to give you
opportunity a little more about

1399
01:41:53,110 --> 01:41:54,450
what your thoughts are in that space.

1400
01:41:55,910 --> 01:42:01,480
>> I am an advocate of open standards
allow for more interoperability allow for

1401
01:42:01,480 --> 01:42:07,030
easier dissemination of data, as Mike was
alluding to, it's not just the different

1402
01:42:07,030 --> 01:42:11,410
signals but it's also the variations
what's needs some meditated.

1403
01:42:11,410 --> 01:42:17,670
The company said what's the degree
of error with the given sensor.

1404
01:42:17,670 --> 01:42:21,246
What was the sampling
method it was collected on.

1405
01:42:21,246 --> 01:42:24,370
And so

1406
01:42:24,370 --> 01:42:28,900
like a lot of them a number of OEMs
are doing some fixed time intervals and

1407
01:42:28,900 --> 01:42:34,450
clicking 100 or whatever sensor data
points and that's great and useful.

1408
01:42:34,450 --> 01:42:37,600
We answered a lot of questions, but it
may not be able to answer a researcher's

1409
01:42:37,600 --> 01:42:40,820
question which may be very specific.

1410
01:42:40,820 --> 01:42:46,200
And that's why we need sort
of when we have something

1411
01:42:46,200 --> 01:42:50,210
that people are comfortable for safety and
security reasons, allowing something to

1412
01:42:50,210 --> 01:42:53,590
run the vehicle, they should be
permitted to do their own data sampling.

1413
01:42:54,710 --> 01:42:59,250
They should be covering the cost
plus a reasonable profit margin for

1414
01:42:59,250 --> 01:43:03,630
the auto manufacturers to do that,
because there's fixed cost and

1415
01:43:03,630 --> 01:43:06,000
we make the investment capital investment

1416
01:43:06,000 --> 01:43:11,430
on the computer resources from the vehicle
and the ongoing costs of bandwidth.

1417
01:43:11,430 --> 01:43:12,040
Those are real.

1418
01:43:13,470 --> 01:43:18,650
And they need to be smart about not
just what data points they collect,

1419
01:43:18,650 --> 01:43:21,460
but how they do that collection.

1420
01:43:21,460 --> 01:43:24,288
As I said, a lot of you
are doing fixed intervals, and

1421
01:43:24,288 --> 01:43:29,120
that's flawed, or it misses a lot.

1422
01:43:29,120 --> 01:43:33,960
A lot can happen within those
group that were doing with

1423
01:43:33,960 --> 01:43:36,450
one service provider every 23 seconds.

1424
01:43:36,450 --> 01:43:38,390
That's why because you
miss a lot in 23 seconds.

1425
01:43:39,850 --> 01:43:44,290
There's a dispute future
curve algorithm which

1426
01:43:44,290 --> 01:43:47,020
helps sort of measure like the peaks and
valleys and

1427
01:43:48,240 --> 01:43:52,480
find pertinent data that will most likely
been more useful once off boarded.

1428
01:43:52,480 --> 01:43:57,730
You need to be able to have new logic,
they can also respond to events and

1429
01:43:57,730 --> 01:44:01,750
under certain situations,
like a whole another set of data points.

1430
01:44:01,750 --> 01:44:04,680
So there's, you.

1431
01:44:06,130 --> 01:44:09,310
There's absolutely no way that automated
faster can collect data that will solve

1432
01:44:09,310 --> 01:44:10,030
everyone's question.

1433
01:44:11,880 --> 01:44:16,445
Regulators, insurance carriers, everyone
can answer quite a few of them and

1434
01:44:16,445 --> 01:44:19,984
generate revenue from it by put
their software in the cloud.

1435
01:44:19,984 --> 01:44:25,273
But they at some point,
there needs to be safe, secure ways to

1436
01:44:25,273 --> 01:44:31,600
let others in my opinion, but,
as I said, I try to avoid the politics.

1437
01:44:31,600 --> 01:44:35,610
I'm not trying to scare
away auto manufacturers and

1438
01:44:35,610 --> 01:44:38,110
that's going to eventually come
from the regulators, I believe.

1439
01:44:39,940 --> 01:44:43,380
>> Yeah,
it as someone who's technical myself,

1440
01:44:43,380 --> 01:44:47,940
I'm gonna stay agnostic as to
what the right policies are and

1441
01:44:47,940 --> 01:44:52,240
even if you talk to
different OEMs they have.

1442
01:44:53,470 --> 01:44:59,047
I'll admit they have radically
different points of view as

1443
01:44:59,047 --> 01:45:04,074
to how much they want to sort
of control when and have.

1444
01:45:04,074 --> 01:45:07,230
Sort of essentially
ownership of that data.

1445
01:45:07,230 --> 01:45:12,692
I mean I can speak for before that
our view is generally, it's for

1446
01:45:12,692 --> 01:45:19,470
fleet donors it belongs that the the data
is kind of theirs to control and.

1447
01:45:20,590 --> 01:45:27,040
We're fairly actively looking at ways
that the data can be shared within

1448
01:45:27,040 --> 01:45:33,180
the context of the privacy principles
that we as an industry have adopted.

1449
01:45:33,180 --> 01:45:37,880
Which really it's about
respecting customer's ability to

1450
01:45:37,880 --> 01:45:42,690
kind of decide that data
needs to be used for.

1451
01:45:42,690 --> 01:45:45,960
But back to Ted's previous point.

1452
01:45:45,960 --> 01:45:51,257
A lot of it's a it's a heavy
optimization in terms of how

1453
01:45:51,257 --> 01:45:56,330
much data is collected by what and
for what purpose and

1454
01:45:56,330 --> 01:46:00,182
there's a lot of effort, especially.

1455
01:46:00,182 --> 01:46:04,236
When you get beyond prototype
vehicles into sort of the,

1456
01:46:04,236 --> 01:46:09,650
the mass large fleet to collect only
the minimal that's that's needed to.

1457
01:46:09,650 --> 01:46:11,590
To sort of get the job done.

1458
01:46:11,590 --> 01:46:16,860
And even retaining that I think one
of our data scientists at one point

1459
01:46:16,860 --> 01:46:21,550
had argued I want to collect the entire
canvas in real time for every vehicle.

1460
01:46:21,550 --> 01:46:25,360
And they then came and
said we need, we need,

1461
01:46:25,360 --> 01:46:30,460
four petabytes per year of have to be
able to sort of store all of that and

1462
01:46:30,460 --> 01:46:34,790
that's just the canvas
to point that that's.

1463
01:46:34,790 --> 01:46:41,800
Typically sliced up in either one second
or multi slices per second intervals and

1464
01:46:41,800 --> 01:46:46,050
a lot of that data isn't really that
interesting for day to day use.

1465
01:46:46,050 --> 01:46:50,520
But to researchers,
It can be of much more interest and

1466
01:46:50,520 --> 01:46:53,030
then when you compute
the data costs to try

1467
01:46:53,030 --> 01:46:57,390
to do anything with that data
collecting it at that kind of scale.

1468
01:46:57,390 --> 01:47:01,670
It's just astronomical and not practical.

1469
01:47:06,639 --> 01:47:07,600
>> Great.

1470
01:47:07,600 --> 01:47:08,130
Thank you, Mike.

1471
01:47:09,170 --> 01:47:14,390
There's a side conversation
going on in the chatroom about

1472
01:47:17,260 --> 01:47:23,860
the NBN security model, which I know our
panelists are not entirely familiar with.

1473
01:47:23,860 --> 01:47:28,950
But in the NBN security model,
the data itself is secured so

1474
01:47:28,950 --> 01:47:33,990
the name is attached to the data and
then there's a cryptographic signature.

1475
01:47:33,990 --> 01:47:35,910
That is attached to it.

1476
01:47:35,910 --> 01:47:41,760
And of the people on the chat room
are wondering whether we could,

1477
01:47:41,760 --> 01:47:43,310
given that security model.

1478
01:47:43,310 --> 01:47:49,900
We can bypass the cloud and
then not rely on security

1479
01:47:49,900 --> 01:47:54,880
mechanisms provided, by the cloud and
then simply have the data.

1480
01:47:54,880 --> 01:48:01,143
I'll go to researchers directly.

1481
01:48:01,143 --> 01:48:06,170
But I'll let the conversation go on for
a little more.

1482
01:48:08,640 --> 01:48:13,280
So I'm thinking this was
this was really nice and.

1483
01:48:14,450 --> 01:48:19,535
The other NDN related point here is to

1484
01:48:19,535 --> 01:48:25,776
Ted's point about standardizing the data.

1485
01:48:25,776 --> 01:48:31,731
It comes to standardizing the data
names and this is very much an NDN.

1486
01:48:31,731 --> 01:48:39,334
Topic where in NDN, the focus of
networking is around naming the data and

1487
01:48:39,334 --> 01:48:45,430
not naming the endpoint
where you can retrieve it.

1488
01:48:45,430 --> 01:48:50,220
And it seems to me that there's
a nice collaboration opportunity here

1489
01:48:50,220 --> 01:48:53,870
to look at how the Indian naming works.

1490
01:48:53,870 --> 01:48:59,050
And create name spaces
that could be derived

1491
01:48:59,050 --> 01:49:04,450
from standardizing the data,
that could be obtained from vehicles.

1492
01:49:06,640 --> 01:49:07,408
Okay.

1493
01:49:07,408 --> 01:49:08,010
All right.

1494
01:49:08,010 --> 01:49:11,220
So we're coming closer to the end, and

1495
01:49:11,220 --> 01:49:15,794
I wanted to first give
an opportunity to the panelists,

1496
01:49:15,794 --> 01:49:23,916
to see if there's any questions that
you guys wanted to ask each other.

1497
01:49:23,916 --> 01:49:26,120
Before I throw in one final question.

1498
01:49:28,310 --> 01:49:32,680
Given what you've heard from everybody,
go ahead Teddy.

1499
01:49:32,680 --> 01:49:37,540
>> Well sort of ties into the NDN
thing you're talking about.

1500
01:49:37,540 --> 01:49:42,535
So, and
sort of an earlier question as far as

1501
01:49:42,535 --> 01:49:46,724
automotive Ethernet, and sort of.

1502
01:49:46,724 --> 01:49:52,482
And you're also asking how the, this
community can potentially help automotive

1503
01:49:52,482 --> 01:49:57,741
manufacturers there is cost associated
with all this that they're trying

1504
01:49:57,741 --> 01:50:03,400
to balance against, sort of capabilities,
security, all these things.

1505
01:50:03,400 --> 01:50:08,690
I want to see these patches
take place in the vehicle.

1506
01:50:08,690 --> 01:50:14,220
I realize this may take some time and
some evolution because I've like to see

1507
01:50:14,220 --> 01:50:19,820
currently the most vehicles operate
on can and other other bus networks.

1508
01:50:19,820 --> 01:50:21,860
That is very limited bandwidth.

1509
01:50:21,860 --> 01:50:23,940
Its broadcast is a trusted network.

1510
01:50:25,310 --> 01:50:27,710
Anything can impersonate anything else,

1511
01:50:27,710 --> 01:50:30,300
which is not a good thing if you
can break into that network.

1512
01:50:31,650 --> 01:50:35,418
So I like to us to see move closer to

1513
01:50:35,418 --> 01:50:40,410
Ethernet sign messages not encrypted and

1514
01:50:40,410 --> 01:50:45,980
then so that you know you can't have
people sort of other devices that can.

1515
01:50:45,980 --> 01:50:49,980
Be compromised find their way or apps or
whatever find their way in there and

1516
01:50:49,980 --> 01:50:55,700
be able to sort of eavesdrop in and send.

1517
01:50:55,700 --> 01:51:01,097
Bogus instructions cuz that's futurist so
I think that anyway,

1518
01:51:01,097 --> 01:51:05,423
I'd like to sort of encourage
further dialogue with

1519
01:51:06,535 --> 01:51:11,100
NSD community and
an auto manufacturers and

1520
01:51:11,100 --> 01:51:15,555
to sort of Lend them your expertise.

1521
01:51:18,392 --> 01:51:22,600
Looking at town now,
hopefully sort of jumped in on that.

1522
01:51:25,580 --> 01:51:26,580
>> Did you want to jump in?

1523
01:51:27,710 --> 01:51:31,330
>> I thought that was a very good thought.

1524
01:51:31,330 --> 01:51:35,270
And so I don't have anything
further to add there.

1525
01:51:35,270 --> 01:51:39,320
I was just wondering I have sort of
a related question I was just wondering.

1526
01:51:39,320 --> 01:51:43,280
I do agree that
standardisation is important.

1527
01:51:43,280 --> 01:51:46,970
And for data and
the sharing of the data will be helpful.

1528
01:51:46,970 --> 01:51:51,090
I do recognize sort of the challenges
that you're doing that and

1529
01:51:51,090 --> 01:51:54,220
the privacy and the cost and everything.

1530
01:51:54,220 --> 01:51:57,100
And so
I'm wondering whether it makes sense,

1531
01:51:57,100 --> 01:52:01,690
for example, for a fund, a neutral entity.

1532
01:52:01,690 --> 01:52:07,850
To host the data so
you can sort of anonymize the data,

1533
01:52:07,850 --> 01:52:12,866
trying to get rid of
the identifying information that

1534
01:52:12,866 --> 01:52:20,800
will sort of implicate any car maker,
particular car models or so on.

1535
01:52:20,800 --> 01:52:26,180
And so that neutral entity can
host the data and then provide

1536
01:52:26,180 --> 01:52:31,208
the aggregation of the data to users.

1537
01:52:31,208 --> 01:52:37,919
So that data may not only be useful for
researchers, but also be very useful for

1538
01:52:37,919 --> 01:52:43,928
validating the vehicle performance,
especially autonomous cars.

1539
01:52:43,928 --> 01:52:46,878
As we all know,
validating autonomous car performance and

1540
01:52:46,878 --> 01:52:48,555
safety is still a big challenge.

1541
01:52:48,555 --> 01:52:53,679
And [COUGH] so we don't have
enough data [LAUGH] to do for

1542
01:52:53,679 --> 01:53:01,200
anybody sort of beyond the carmakers
themselves to test their cars.

1543
01:53:01,200 --> 01:53:06,790
And there is like of standardization or
even what do you mean?

1544
01:53:06,790 --> 01:53:10,270
How do we even measure safety?

1545
01:53:11,390 --> 01:53:18,219
So, I think standardization and along
those lines will be tremendously helpful.

1546
01:53:22,525 --> 01:53:23,668
>> Okay great.

1547
01:53:23,668 --> 01:53:26,740
Any comments from the other
panelists on this one?

1548
01:53:26,740 --> 01:53:31,510
Cuz I think we're coming up to the end.

1549
01:53:31,510 --> 01:53:32,838
>> [COUGH] standards, I agree.

1550
01:53:32,838 --> 01:53:40,904
[LAUGH] I think data standardization is
always important and talking with folks.

1551
01:53:40,904 --> 01:53:45,980
It took SAE and
some of the other organizations probably

1552
01:53:45,980 --> 01:53:50,408
numerous years to standardize
on sort of data and

1553
01:53:50,408 --> 01:53:55,275
all of the things around
right to repair and all that.

1554
01:53:55,275 --> 01:53:59,956
And over over time,
I suspect a lot of the other sort of

1555
01:53:59,956 --> 01:54:03,504
data elements need to be standardized.

1556
01:54:03,504 --> 01:54:08,397
It's just a question of what,
when and where.

1557
01:54:08,397 --> 01:54:12,575
And then getting things into
the standardized format.

1558
01:54:17,672 --> 01:54:18,560
>> Okay, great.

1559
01:54:18,560 --> 01:54:19,810
Thank you, Mike.

1560
01:54:19,810 --> 01:54:23,850
So I think at this point,
we can wrap up the panel.

1561
01:54:23,850 --> 01:54:25,610
So thank you, Mike.

1562
01:54:25,610 --> 01:54:26,240
Thank you, Ted.

1563
01:54:26,240 --> 01:54:28,350
Thank you, Tao.

1564
01:54:28,350 --> 01:54:29,390
Wonderful conversation.

1565
01:54:29,390 --> 01:54:31,880
Really appreciate you taking the time and

1566
01:54:31,880 --> 01:54:34,970
educating us a little bit
about the automotive world.

1567
01:54:34,970 --> 01:54:37,310
It's a fascinating space, I think.

1568
01:54:37,310 --> 01:54:42,770
I hope that more networking researchers
will look at the automotive world and

1569
01:54:42,770 --> 01:54:44,900
all the very interesting
problems that are coming up.

1570
01:54:46,190 --> 01:54:47,460
So thank you again.

1571
01:54:47,460 --> 01:54:51,430
And at this point, I think I wanna pass
this back to the [INAUDIBLE] folks and

1572
01:54:51,430 --> 01:54:55,540
see if IIya is back on line.

1573
01:54:55,540 --> 01:54:58,780
And if you wanted to talk about fabric.

1574
01:55:00,296 --> 01:55:02,480
>> Thank you everyone.
