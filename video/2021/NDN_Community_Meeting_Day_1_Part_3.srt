1
00:00:00,410 --> 00:00:02,670
>> Welcome everyone to

2
00:00:02,670 --> 00:00:05,175
the second session
in today's program

3
00:00:05,175 --> 00:00:06,930
focused on NDN

4
00:00:06,930 --> 00:00:09,305
for data-intensive
applications,

5
00:00:09,305 --> 00:00:11,050
with five
presentations that

6
00:00:11,050 --> 00:00:13,420
are interrelated as
you will discover

7
00:00:13,420 --> 00:00:16,720
from the first
presentation by Edmund Yeh

8
00:00:16,720 --> 00:00:18,430
on NDN for

9
00:00:18,430 --> 00:00:20,975
data-intensive
science experiments.

10
00:00:20,975 --> 00:00:23,020
Edmund is a Professor

11
00:00:23,020 --> 00:00:24,160
of Electrical and Computer

12
00:00:24,160 --> 00:00:27,530
Engineering at
North-Eastern University

13
00:00:27,600 --> 00:00:30,460
with the research
focus on a number

14
00:00:30,460 --> 00:00:32,410
of communications and
networking problems,

15
00:00:32,410 --> 00:00:36,615
including networking for
data-intensive applications.

16
00:00:36,615 --> 00:00:39,010
Edmund go-ahead
and we need

17
00:00:39,010 --> 00:00:40,990
to watch the
time because we

18
00:00:40,990 --> 00:00:42,490
have one hour for

19
00:00:42,490 --> 00:00:46,460
five presentations.
Go ahead, please.

20
00:00:47,030 --> 00:00:49,965
>> Thank you Lotfi,
can you hear me?

21
00:00:49,965 --> 00:00:51,450
>> Yes.

22
00:00:51,450 --> 00:00:54,120
>> Great. Thank you.

23
00:00:54,120 --> 00:00:55,890
Let me make sure that

24
00:00:55,890 --> 00:01:00,750
my slides are
being shared or?

25
00:01:00,750 --> 00:01:02,205
>> Not yet.

26
00:01:02,205 --> 00:01:04,360
You have to share
[OVERLAPPING] them again.

27
00:01:07,250 --> 00:01:14,675
>> Can you see it now?

28
00:01:14,675 --> 00:01:17,000
>> Yes. Just go
full screen.

29
00:01:17,000 --> 00:01:18,780
>> Okay?

30
00:01:18,950 --> 00:01:20,700
>> Yeah

31
00:01:20,700 --> 00:01:23,200
>> Thank you very much
for the introduction

32
00:01:23,200 --> 00:01:27,050
and great to be here
at NDN and calm.

33
00:01:28,860 --> 00:01:31,600
Last year I was here,

34
00:01:31,600 --> 00:01:34,400
in fact talking about

35
00:01:35,370 --> 00:01:38,745
NDN for data-intensive
science.

36
00:01:38,745 --> 00:01:40,460
In fact, I was
talking about

37
00:01:40,460 --> 00:01:41,720
a predecessor project

38
00:01:41,720 --> 00:01:44,680
to N-DISE called SANDIE.

39
00:01:44,680 --> 00:01:46,700
This is the
follow on project

40
00:01:46,700 --> 00:01:50,034
which has also been
funded by NSF for

41
00:01:50,034 --> 00:01:51,410
data-intensive science

42
00:01:51,410 --> 00:01:54,840
experiments called N-DISE.

43
00:01:54,860 --> 00:01:57,290
I'm going to give
an overview of what

44
00:01:57,290 --> 00:01:58,640
we're trying to do

45
00:01:58,640 --> 00:02:00,185
and some recent
developments.

46
00:02:00,185 --> 00:02:02,570
As Lokhi mentioned,

47
00:02:02,570 --> 00:02:03,920
my talk will be followed

48
00:02:03,920 --> 00:02:05,330
on by a number of tasks

49
00:02:05,330 --> 00:02:09,790
which expand on the
themes mentioned here.

50
00:02:10,820 --> 00:02:14,750
My slides are moving
properly, I assume.

51
00:02:15,420 --> 00:02:17,530
Data-intensive science

52
00:02:17,530 --> 00:02:20,785
encompasses many
different fields,

53
00:02:20,785 --> 00:02:23,705
such as Large
Hadron Collider.

54
00:02:23,705 --> 00:02:25,755
This is high-energy
physics,

55
00:02:25,755 --> 00:02:27,190
and this is the
main example we're

56
00:02:27,190 --> 00:02:29,110
dealing in this
particular project.

57
00:02:29,110 --> 00:02:32,495
LSST, Large Synoptic
Survey Telescope.

58
00:02:32,495 --> 00:02:36,765
The SKA Square
Kilometer Array is

59
00:02:36,765 --> 00:02:39,310
astronomy and
astrophysics fields which

60
00:02:39,310 --> 00:02:42,360
take enormous amounts
of data every night.

61
00:02:42,360 --> 00:02:45,735
Genomics is a
new field which

62
00:02:45,735 --> 00:02:47,740
has also been looked

63
00:02:47,740 --> 00:02:49,690
at in this
particular project.

64
00:02:49,690 --> 00:02:52,434
All of these
different fields,

65
00:02:52,434 --> 00:02:56,730
share similar
challenges which

66
00:02:56,730 --> 00:03:00,895
include how to index,

67
00:03:00,895 --> 00:03:03,670
secure, store,
distribute, analyze,

68
00:03:03,670 --> 00:03:05,125
and learn from the data,

69
00:03:05,125 --> 00:03:07,510
and in the
coordinated use of

70
00:03:07,510 --> 00:03:09,660
computing storage and
network resources.

71
00:03:09,660 --> 00:03:12,550
Even though these
resources are substantial,

72
00:03:12,550 --> 00:03:16,180
when you have to deal
with data sets and

73
00:03:16,180 --> 00:03:18,355
data volumes of the size

74
00:03:18,355 --> 00:03:20,065
that we're
encountering here,

75
00:03:20,065 --> 00:03:22,520
you still have a
lot of challenges.

76
00:03:22,520 --> 00:03:24,820
Right now, the domain
experts are dealing with

77
00:03:24,820 --> 00:03:27,550
these systems problems in

78
00:03:27,550 --> 00:03:30,430
separate domains using
incremental solutions

79
00:03:30,430 --> 00:03:32,560
developed often
in isolation.

80
00:03:32,560 --> 00:03:34,915
There are many
replicated efforts,

81
00:03:34,915 --> 00:03:38,080
primarily due to
the fact that

82
00:03:38,080 --> 00:03:39,940
the architecture we're
using today is now

83
00:03:39,940 --> 00:03:42,130
quite suited to
these applications.

84
00:03:42,130 --> 00:03:45,480
What we're espousing
here is a new approach.

85
00:03:45,480 --> 00:03:46,885
A data-centric approach to

86
00:03:46,885 --> 00:03:48,590
system and network design,

87
00:03:48,590 --> 00:03:51,880
and to provide system
support through

88
00:03:51,880 --> 00:03:53,410
the whole data life cycles

89
00:03:53,410 --> 00:03:55,360
from data production,

90
00:03:55,360 --> 00:03:58,134
naming the data, securing
the data directly,

91
00:03:58,134 --> 00:04:00,595
delivering the
data using names,

92
00:04:00,595 --> 00:04:04,345
enabling scalable
data retrieval,

93
00:04:04,345 --> 00:04:07,915
with native support for
in-network caching,

94
00:04:07,915 --> 00:04:10,759
automated joint caching
and forwarding,

95
00:04:10,759 --> 00:04:13,314
multicast delivery.

96
00:04:13,314 --> 00:04:15,235
What we're trying
to do is to

97
00:04:15,235 --> 00:04:17,575
develop a common
framework for

98
00:04:17,575 --> 00:04:20,440
a data-intensive
science to support

99
00:04:20,440 --> 00:04:22,300
different kinds of
application domains

100
00:04:22,300 --> 00:04:24,025
using the same approach.

101
00:04:24,025 --> 00:04:28,120
This is all based on
the NDN approach.

102
00:04:28,120 --> 00:04:32,050
Now, this particular
project was funded in

103
00:04:32,050 --> 00:04:35,965
2020 by the NSF
CC* Start program.

104
00:04:35,965 --> 00:04:39,190
It builds on the
previous project

105
00:04:39,190 --> 00:04:41,190
which I mentioned
called SANDIE,

106
00:04:41,190 --> 00:04:45,670
which ran from
2017 to 2001.

107
00:04:46,130 --> 00:04:49,750
The team consists
of Northeastern,

108
00:04:49,750 --> 00:04:51,250
where I'm leading
the team,

109
00:04:51,250 --> 00:04:53,350
Caltech where Professor
Harvey Newman

110
00:04:53,350 --> 00:04:56,775
from Caltech physics
is leading the team.

111
00:04:56,775 --> 00:05:00,120
UCLA, where the
Co-PIs are,

112
00:05:00,120 --> 00:05:01,770
Professor Lisa Zhang and

113
00:05:01,770 --> 00:05:04,320
professor Jason Cong,

114
00:05:04,320 --> 00:05:06,490
they're leading
the efforts on

115
00:05:06,490 --> 00:05:11,040
congestion control and
FPGA acceleration,

116
00:05:11,040 --> 00:05:13,350
and Tennessee Tech
where the Co-PI is

117
00:05:13,350 --> 00:05:16,060
Susmit Shannigrahi who is

118
00:05:16,060 --> 00:05:19,525
looking at the
application of genomics.

119
00:05:19,525 --> 00:05:21,280
We of course do
this in partnership

120
00:05:21,280 --> 00:05:23,005
with the LHC teams,

121
00:05:23,005 --> 00:05:24,370
the genomics
collaborators in

122
00:05:24,370 --> 00:05:26,120
the NDN project team.

123
00:05:26,120 --> 00:05:27,965
But the challenges here,

124
00:05:27,965 --> 00:05:29,750
in particular the
trouble trying to

125
00:05:29,750 --> 00:05:32,465
address is that
LHC data volume is

126
00:05:32,465 --> 00:05:35,230
such grow about
10 times due to

127
00:05:35,230 --> 00:05:36,930
the higher luminosity LHC

128
00:05:36,930 --> 00:05:39,585
which is set to
start in 2027.

129
00:05:39,585 --> 00:05:41,350
Therefore, we're
looking at

130
00:05:41,350 --> 00:05:45,976
another 10 times increase
over and already

131
00:05:45,976 --> 00:05:48,395
there extremely high
data volume-based.

132
00:05:48,395 --> 00:05:49,340
We're also going to

133
00:05:49,340 --> 00:05:51,785
get increased
data complexity.

134
00:05:51,785 --> 00:05:53,915
We're also looking at

135
00:05:53,915 --> 00:05:56,975
human genome data and
earth bio genome data,

136
00:05:56,975 --> 00:05:59,975
which is approaching
the exabyte range.

137
00:05:59,975 --> 00:06:01,940
All of these
applications need to use

138
00:06:01,940 --> 00:06:03,800
diverse computation
storage,

139
00:06:03,800 --> 00:06:05,135
networking resources.

140
00:06:05,135 --> 00:06:07,280
There is an increasing
need to have

141
00:06:07,280 --> 00:06:10,165
the ability to use these
diverse resources.

142
00:06:10,165 --> 00:06:12,435
Our approach is to build

143
00:06:12,435 --> 00:06:14,430
a data-centric ecosystem,

144
00:06:14,430 --> 00:06:16,415
provide agile integrated,

145
00:06:16,415 --> 00:06:18,170
interoperable,
scalable, robust,

146
00:06:18,170 --> 00:06:20,120
and trustworthy
solutions for

147
00:06:20,120 --> 00:06:22,385
heterogeneous data
intensive domains.

148
00:06:22,385 --> 00:06:24,840
That is our larger goal.

149
00:06:24,980 --> 00:06:28,160
Now the near-term goal
for the N-DISE project

150
00:06:28,160 --> 00:06:31,040
is to deploy commission
and commission

151
00:06:31,040 --> 00:06:32,915
the first prototype
production ready

152
00:06:32,915 --> 00:06:37,160
NDN based petascale data
distribution caching,

153
00:06:37,160 --> 00:06:39,290
access computation system,

154
00:06:39,290 --> 00:06:42,730
serve a major
science programs.

155
00:06:42,730 --> 00:06:44,270
We're going to take

156
00:06:44,270 --> 00:06:45,770
LHC high-energy physics as

157
00:06:45,770 --> 00:06:47,150
the leading
target use case

158
00:06:47,150 --> 00:06:48,600
, with bio genome,

159
00:06:48,600 --> 00:06:51,390
human genome projects as

160
00:06:51,390 --> 00:06:52,920
the secondary use case,

161
00:06:52,920 --> 00:06:54,869
and with ATLAS, LSST,

162
00:06:54,869 --> 00:06:57,420
SKA as future use cases.

163
00:06:57,420 --> 00:06:59,810
We're going to
leverage the

164
00:06:59,810 --> 00:07:01,145
NDN protocols which have

165
00:07:01,145 --> 00:07:02,810
already been developed
and have been

166
00:07:02,810 --> 00:07:05,180
discussed in
previous sessions.

167
00:07:05,180 --> 00:07:06,590
High-throughput forwarding

168
00:07:06,590 --> 00:07:07,970
caching methods
which have been

169
00:07:07,970 --> 00:07:09,270
developed by the

170
00:07:09,270 --> 00:07:11,280
Northeastern and
other institutions.

171
00:07:11,280 --> 00:07:13,234
Containerization
techniques,

172
00:07:13,234 --> 00:07:16,685
which are being
developed at Caltech,

173
00:07:16,685 --> 00:07:20,060
integrated with FPGA
acceleration subsystems

174
00:07:20,060 --> 00:07:23,470
which UCLA is looking at.

175
00:07:23,470 --> 00:07:25,970
Our goal is to
deliver LHC data over

176
00:07:25,970 --> 00:07:27,470
a wide area networks
or throughputs

177
00:07:27,470 --> 00:07:29,960
approaching 100
gigabits per second,

178
00:07:29,960 --> 00:07:32,690
and dramatically
decrease download times

179
00:07:32,690 --> 00:07:35,135
by using optimized
caching.

180
00:07:35,135 --> 00:07:39,215
We're very much going
after performance here.

181
00:07:39,215 --> 00:07:42,400
For very large
data volumes

182
00:07:42,400 --> 00:07:45,125
using NDN approach.

183
00:07:45,125 --> 00:07:48,594
We are establishing
a persistent testbed

184
00:07:48,594 --> 00:07:51,340
with high-performance
NDN data cache servers.

185
00:07:51,340 --> 00:07:55,445
We're going to demo
that testbed at SC21,

186
00:07:55,445 --> 00:07:58,150
which is coming up in
less than two weeks.

187
00:07:58,150 --> 00:08:01,270
Even after SC21 will keep

188
00:08:01,270 --> 00:08:04,465
a persistent testbed
for this project.

189
00:08:04,465 --> 00:08:06,115
Let me now just talk about

190
00:08:06,115 --> 00:08:11,570
some recent
developments with NDNs.

191
00:08:13,020 --> 00:08:16,150
Let me know how much
time I have left,

192
00:08:16,150 --> 00:08:17,890
but I'll just try to go

193
00:08:17,890 --> 00:08:19,700
through it
relatively quickly.

194
00:08:19,700 --> 00:08:22,325
We've been looking
at developing

195
00:08:22,325 --> 00:08:25,675
the consumer and
producer for NDN-DPDK.

196
00:08:25,675 --> 00:08:29,450
A new consumer-producer
application

197
00:08:29,450 --> 00:08:30,890
based on the
NDNgo library,

198
00:08:30,890 --> 00:08:32,270
which is developed by NIST

199
00:08:32,270 --> 00:08:34,375
, has been developed.

200
00:08:34,375 --> 00:08:37,730
Which replaces the extra
NDN and OSS plugin,

201
00:08:37,730 --> 00:08:39,785
which I described
last year,

202
00:08:39,785 --> 00:08:41,395
by the SANDIE project.

203
00:08:41,395 --> 00:08:43,259
For even better
throughput,

204
00:08:43,259 --> 00:08:47,410
we've developed new
C++ NDNc library,

205
00:08:47,410 --> 00:08:49,790
with APIs for applications
to communicate

206
00:08:49,790 --> 00:08:50,840
with the NDN-DPDK

207
00:08:50,840 --> 00:08:52,330
forward to using
the memif,

208
00:08:52,330 --> 00:08:54,605
which is a shared memory
package interface

209
00:08:54,605 --> 00:08:55,760
providing high-performance

210
00:08:55,760 --> 00:08:58,220
packet transmission. This
is all being done by

211
00:08:58,220 --> 00:08:59,960
the group at Caltech.

212
00:08:59,960 --> 00:09:02,150
We'll also be looking
at containers

213
00:09:02,150 --> 00:09:03,290
for NDN-DPDK and

214
00:09:03,290 --> 00:09:04,460
applications for

215
00:09:04,460 --> 00:09:06,845
diverse server equipment
and interfaces.

216
00:09:06,845 --> 00:09:09,290
Specifically, using
docker containers,

217
00:09:09,290 --> 00:09:11,825
which allows you
to host guest OS,

218
00:09:11,825 --> 00:09:14,405
state restoration,
easy upgrading.

219
00:09:14,405 --> 00:09:16,770
We're completely docker
containerization

220
00:09:16,770 --> 00:09:18,450
of the NDN-DPDK forwarder,

221
00:09:18,450 --> 00:09:19,835
consumer, and producer.

222
00:09:19,835 --> 00:09:21,575
This is a joint
effort between

223
00:09:21,575 --> 00:09:24,555
Caltech and NIST in fact.

224
00:09:24,555 --> 00:09:26,700
We just also been looking

225
00:09:26,700 --> 00:09:29,730
at rate-based congestion
control for NDN.

226
00:09:29,730 --> 00:09:34,110
This is headed by Professor
[inaudible] UCLA.

227
00:09:34,110 --> 00:09:37,700
The NDNs dynamic multipath
forwarding and in

228
00:09:37,700 --> 00:09:39,080
network caching renders

229
00:09:39,080 --> 00:09:41,140
the traditional congestion

230
00:09:41,140 --> 00:09:42,905
control approach
inapplicable.

231
00:09:42,905 --> 00:09:44,250
Therefore, we're
developing

232
00:09:44,250 --> 00:09:45,480
rate-based
congestion control

233
00:09:45,480 --> 00:09:47,070
where we're comparing

234
00:09:47,070 --> 00:09:48,530
the idea is to compare

235
00:09:48,530 --> 00:09:50,000
the consumer interest
sending rate

236
00:09:50,000 --> 00:09:52,970
with the corresponding
data arrival rate

237
00:09:52,970 --> 00:09:54,305
to detect congestion,

238
00:09:54,305 --> 00:09:56,120
and then set the interest

239
00:09:56,120 --> 00:09:58,285
sending rate accordingly.

240
00:09:58,285 --> 00:10:00,650
Professor Congs'
group is looking at

241
00:10:00,650 --> 00:10:02,405
FPGA acceleration

242
00:10:02,405 --> 00:10:04,550
to accelerate the
NDN forwarder.

243
00:10:04,550 --> 00:10:06,230
The initial focus
of this effort

244
00:10:06,230 --> 00:10:08,300
is on the input stage
of the forwarder,

245
00:10:08,300 --> 00:10:11,920
where we're detecting
a bottleneck.

246
00:10:11,920 --> 00:10:12,770
The idea is to

247
00:10:12,770 --> 00:10:14,270
accelerate the
hashing function and

248
00:10:14,270 --> 00:10:16,670
lookup table used for
thread dispatching.

249
00:10:16,670 --> 00:10:18,080
For both of these areas,

250
00:10:18,080 --> 00:10:20,300
the congestion control
and FPGA acceleration.

251
00:10:20,300 --> 00:10:21,890
There'll be talks
coming up later in

252
00:10:21,890 --> 00:10:24,605
the session that expand
on these themes.

253
00:10:24,605 --> 00:10:26,840
We're also looking at
preliminary integration

254
00:10:26,840 --> 00:10:28,759
with genomics workflow.

255
00:10:28,759 --> 00:10:30,830
This is headed
by Professor

256
00:10:30,830 --> 00:10:33,035
Shannigrahi at
Tennessee Tech.

257
00:10:33,035 --> 00:10:35,605
We've tested
docker containers

258
00:10:35,605 --> 00:10:37,770
on the Pacific
Research Platform,

259
00:10:37,770 --> 00:10:39,410
PRP, and Google Cloud

260
00:10:39,410 --> 00:10:41,615
by use with
genomics workflows.

261
00:10:41,615 --> 00:10:42,350
There's also

262
00:10:42,350 --> 00:10:44,180
ongoing integration
of containers with

263
00:10:44,180 --> 00:10:46,460
Kubernetes-based
systems or deployment

264
00:10:46,460 --> 00:10:49,710
and usage in
genomics workflows.

265
00:10:50,000 --> 00:10:53,450
At Northeastern we've
been focusing on

266
00:10:53,450 --> 00:10:57,205
the NDN [OVERLAPPING]
How many minutes, sorry?

267
00:10:57,205 --> 00:10:58,740
>> One minute please.

268
00:10:58,740 --> 00:11:00,810
>> One minute okay.
There I'll be fast.

269
00:11:00,810 --> 00:11:02,765
At Northeast we've been

270
00:11:02,765 --> 00:11:04,850
upgrading the
local testbed.

271
00:11:04,850 --> 00:11:06,860
We've implemented

272
00:11:06,860 --> 00:11:09,350
a containerized
NDN-DPDK forwarder,

273
00:11:09,350 --> 00:11:10,580
the C-based consumer,

274
00:11:10,580 --> 00:11:13,340
and file server
developed by NIST.

275
00:11:13,340 --> 00:11:14,810
We've upgraded the

276
00:11:14,810 --> 00:11:16,370
forwarding caching
algorithm to

277
00:11:16,370 --> 00:11:18,350
the latest NDN-DPDK
forwarder with

278
00:11:18,350 --> 00:11:19,684
performed extensive

279
00:11:19,684 --> 00:11:22,025
throughput and cache
latency tests.

280
00:11:22,025 --> 00:11:23,600
Now, I'm going
to talk about

281
00:11:23,600 --> 00:11:25,310
the WAN testbed,

282
00:11:25,310 --> 00:11:27,560
which we have
put together.

283
00:11:27,560 --> 00:11:30,260
We've upgraded the
Northeastern server

284
00:11:30,260 --> 00:11:30,920
and moved it to

285
00:11:30,920 --> 00:11:32,480
MGHPCC in order to

286
00:11:32,480 --> 00:11:33,680
access 100 gigabits

287
00:11:33,680 --> 00:11:35,280
per second network
bandwidth.

288
00:11:35,280 --> 00:11:36,745
Caltech has upgraded

289
00:11:36,745 --> 00:11:38,740
its connectivity
working with StarLight.

290
00:11:38,740 --> 00:11:39,700
Now they have a 2

291
00:11:39,700 --> 00:11:41,350
by 100-gigabit
connection to

292
00:11:41,350 --> 00:11:42,460
StarLight
exchange point in

293
00:11:42,460 --> 00:11:45,525
Chicago and the
StarLight SC21 booth.

294
00:11:45,525 --> 00:11:47,600
We purchased two
new servers to be

295
00:11:47,600 --> 00:11:50,720
placed in Chicago
and the SC21 booth.

296
00:11:50,720 --> 00:11:52,250
We've added UCLA in

297
00:11:52,250 --> 00:11:53,810
Tennessee Tech sites

298
00:11:53,810 --> 00:11:56,135
supporting 10-gigabit
connections.

299
00:11:56,135 --> 00:11:57,560
In order to send the NDN

300
00:11:57,560 --> 00:11:58,760
package directly
in the network,

301
00:11:58,760 --> 00:11:59,810
we've established VLAN

302
00:11:59,810 --> 00:12:01,160
connections
among the sites

303
00:12:01,160 --> 00:12:03,710
in the testbed with
support from Internet2,

304
00:12:03,710 --> 00:12:06,020
CENIC, ESnet, and UCSD.

305
00:12:06,020 --> 00:12:08,240
This is the picture
of our testbed here

306
00:12:08,240 --> 00:12:10,130
which we're going
to use for SC21,

307
00:12:10,130 --> 00:12:12,890
also for the persistent
testbed afterwards.

308
00:12:12,890 --> 00:12:15,410
You can see we have
Northeastern here,

309
00:12:15,410 --> 00:12:16,880
StarLight in Chicago,

310
00:12:16,880 --> 00:12:19,685
the SC21 StarLight
booth here,

311
00:12:19,685 --> 00:12:21,410
Tennessee Tech,
Caltech we have

312
00:12:21,410 --> 00:12:23,705
two machines, and UCLA.

313
00:12:23,705 --> 00:12:28,700
The idea is just

314
00:12:28,700 --> 00:12:30,290
to looking forward
to the SC21,

315
00:12:30,290 --> 00:12:31,880
which is coming up in
less than two weeks.

316
00:12:31,880 --> 00:12:34,070
We're going to demo
N-DISE's data access

317
00:12:34,070 --> 00:12:35,120
distribution caching

318
00:12:35,120 --> 00:12:36,770
system over this testbed,

319
00:12:36,770 --> 00:12:38,270
focusing on throughput and

320
00:12:38,270 --> 00:12:39,650
download latency
experiments

321
00:12:39,650 --> 00:12:42,870
with CMS datasets.

322
00:12:43,120 --> 00:12:46,550
We hope to get a very
substantial increase in

323
00:12:46,550 --> 00:12:49,595
performance for
SC21 over SC19,

324
00:12:49,595 --> 00:12:50,750
which is two years ago.

325
00:12:50,750 --> 00:12:53,825
We couldn't do it for
2020 because of COVID.

326
00:12:53,825 --> 00:12:56,690
Beyond SC21 we'll look

327
00:12:56,690 --> 00:12:58,640
at the following topics.

328
00:12:58,640 --> 00:13:00,335
Let me just put
it up there

329
00:13:00,335 --> 00:13:02,345
because of the
limitation on time.

330
00:13:02,345 --> 00:13:03,590
There are a number
of things we want to

331
00:13:03,590 --> 00:13:06,065
do after the SC21.

332
00:13:06,065 --> 00:13:07,955
This project's going to

333
00:13:07,955 --> 00:13:09,545
run for at least
another year,

334
00:13:09,545 --> 00:13:11,030
if not two years, so

335
00:13:11,030 --> 00:13:12,815
there's a lot of
work coming up.

336
00:13:12,815 --> 00:13:15,005
We're very excited
and we hope

337
00:13:15,005 --> 00:13:18,530
to get a significant
performance boost,

338
00:13:18,530 --> 00:13:20,510
that SC21 which
is going to

339
00:13:20,510 --> 00:13:22,985
propel us forward,
and we're, of course,

340
00:13:22,985 --> 00:13:24,590
seeking long-term
collaboration with

341
00:13:24,590 --> 00:13:26,120
domain science,
networking,

342
00:13:26,120 --> 00:13:28,325
and computer
systems communities

343
00:13:28,325 --> 00:13:31,050
in this effort.
Thank you very much.

344
00:13:31,060 --> 00:13:34,010
>> Thank you very
much, Edmund.

345
00:13:34,010 --> 00:13:37,535
For the sake of time,
one quick question.

346
00:13:37,535 --> 00:13:39,140
By now, do you

347
00:13:39,140 --> 00:13:41,120
know what throughput
performance

348
00:13:41,120 --> 00:13:43,685
you'll be able
to show at SC21?

349
00:13:43,685 --> 00:13:45,590
>> Yeah, so a very
good question.

350
00:13:45,590 --> 00:13:46,670
We're still working on it.

351
00:13:46,670 --> 00:13:50,630
[LAUGHTER] I mean, you

352
00:13:50,630 --> 00:13:52,580
may encounter a lot
of things while

353
00:13:52,580 --> 00:13:54,410
you try to do live demos,

354
00:13:54,410 --> 00:13:55,670
though we're pretty

355
00:13:55,670 --> 00:13:56,930
confident we're
going to get

356
00:13:56,930 --> 00:14:00,440
beyond 10 gigabits
per second,

357
00:14:00,440 --> 00:14:01,820
I think, but

358
00:14:01,820 --> 00:14:04,370
we are trying to
push beyond that,

359
00:14:04,370 --> 00:14:06,380
toward ultimate goal being

360
00:14:06,380 --> 00:14:07,490
100 gigabits per second.

361
00:14:07,490 --> 00:14:08,990
But also we're focusing

362
00:14:08,990 --> 00:14:11,390
on decreasing the
download latency,

363
00:14:11,390 --> 00:14:12,470
so there are two

364
00:14:12,470 --> 00:14:14,675
different things
going on here.

365
00:14:14,675 --> 00:14:17,030
>> Thank you very much.

366
00:14:17,030 --> 00:14:17,855
>> Thank you.

367
00:14:17,855 --> 00:14:22,085
>> Our next speaker
is Catalin Iordache.

368
00:14:22,085 --> 00:14:24,440
Catalin, you can

369
00:14:24,440 --> 00:14:26,525
go ahead and start
sharing your screen.

370
00:14:26,525 --> 00:14:28,025
Catalin graduated from

371
00:14:28,025 --> 00:14:30,755
the Polytechnic
University of Bucharest

372
00:14:30,755 --> 00:14:31,820
with a master's degree in

373
00:14:31,820 --> 00:14:33,695
advanced computer
architecture.

374
00:14:33,695 --> 00:14:35,300
Over the past few years,

375
00:14:35,300 --> 00:14:37,505
he's been a contractor
for Caltech,

376
00:14:37,505 --> 00:14:39,275
working on the
SANDIE project,

377
00:14:39,275 --> 00:14:41,450
and currently on
the N-DISE project

378
00:14:41,450 --> 00:14:44,540
that he's going to
tell us about it.

379
00:14:44,540 --> 00:14:46,715
Catalin, go ahead, please.

380
00:14:46,715 --> 00:14:50,940
>> Thank you, Lofti.
Can you hear me?

381
00:14:53,350 --> 00:14:58,160
>> Yes. Just
[OVERLAPPING] good.

382
00:14:58,160 --> 00:14:59,660
>> Perfect. Thank
you very much,

383
00:14:59,660 --> 00:15:01,175
and thank you
for having me to

384
00:15:01,175 --> 00:15:02,810
this community meeting.

385
00:15:02,810 --> 00:15:04,655
It's my first time say,

386
00:15:04,655 --> 00:15:06,110
the past three years
that I'm going

387
00:15:06,110 --> 00:15:07,850
to talk about what I'm

388
00:15:07,850 --> 00:15:11,585
doing by using NDN
to these projects.

389
00:15:11,585 --> 00:15:14,960
The topic today
will be this NDNc,

390
00:15:14,960 --> 00:15:18,425
what it is, and why
we are doing it?

391
00:15:18,425 --> 00:15:21,650
In order to explain it,

392
00:15:21,650 --> 00:15:23,645
I would first
like to say that

393
00:15:23,645 --> 00:15:25,820
they're both working
for the SANDIE project,

394
00:15:25,820 --> 00:15:27,110
and also for the N-DISE

395
00:15:27,110 --> 00:15:28,790
project at this moment.

396
00:15:28,790 --> 00:15:30,875
The main goal of

397
00:15:30,875 --> 00:15:32,450
both projects on

398
00:15:32,450 --> 00:15:34,460
the application
side was always to

399
00:15:34,460 --> 00:15:36,095
deploy NDN in

400
00:15:36,095 --> 00:15:36,650
large-scale

401
00:15:36,650 --> 00:15:38,090
data-intensive
science experiments

402
00:15:38,090 --> 00:15:41,340
such as LHC,
high-energy physics.

403
00:15:41,770 --> 00:15:46,130
This has always
been our goal,

404
00:15:46,130 --> 00:15:49,250
and today I'm going
to first show you

405
00:15:49,250 --> 00:15:50,780
how currently the data is

406
00:15:50,780 --> 00:15:52,490
being accessed
and delivered,

407
00:15:52,490 --> 00:15:53,840
that CMS, one of

408
00:15:53,840 --> 00:15:56,240
the two large
experiments that I see.

409
00:15:56,240 --> 00:15:58,610
Then how NDN application

410
00:15:58,610 --> 00:16:00,650
would look like in
such an environment,

411
00:16:00,650 --> 00:16:02,480
at least the way
we envision it.

412
00:16:02,480 --> 00:16:05,240
Then I will talk about
the triple performance

413
00:16:05,240 --> 00:16:07,895
of such an application,
and finally,

414
00:16:07,895 --> 00:16:10,640
this will lead up
to what is NDNc,

415
00:16:10,640 --> 00:16:14,280
and the future
plans for this.

416
00:16:14,530 --> 00:16:19,115
First, how is data
access today at CMS?

417
00:16:19,115 --> 00:16:21,380
we have this diagram

418
00:16:21,380 --> 00:16:22,925
where at the
bottom you have

419
00:16:22,925 --> 00:16:25,880
the side B and site C.

420
00:16:25,880 --> 00:16:28,190
As you can see
both sides have

421
00:16:28,190 --> 00:16:30,065
access to some storage,

422
00:16:30,065 --> 00:16:31,880
and the storage contains

423
00:16:31,880 --> 00:16:34,560
data from the
CMS experiment.

424
00:16:35,620 --> 00:16:38,420
I mean, alongside
site B you

425
00:16:38,420 --> 00:16:40,760
also have a number of
sites and the same

426
00:16:40,760 --> 00:16:42,500
for site C. Although

427
00:16:42,500 --> 00:16:43,520
these sites are connected

428
00:16:43,520 --> 00:16:46,775
to or so-called Regional
XRootD Redirector,

429
00:16:46,775 --> 00:16:49,610
which knows about all
of the sites below it,

430
00:16:49,610 --> 00:16:52,055
and also about the
Global Redirector.

431
00:16:52,055 --> 00:16:54,050
In this diagram,

432
00:16:54,050 --> 00:16:58,115
you have a redirector
in US and one in EU.

433
00:16:58,115 --> 00:17:01,085
In this case
for us site A,

434
00:17:01,085 --> 00:17:04,205
or here in the
left-hand corner

435
00:17:04,205 --> 00:17:06,755
is where the user
applications runs,

436
00:17:06,755 --> 00:17:08,750
where the scientists
are actually running

437
00:17:08,750 --> 00:17:11,900
their scientific
application,

438
00:17:11,900 --> 00:17:13,535
scientific data at CMS.

439
00:17:13,535 --> 00:17:15,665
In this case, we have
two applications.

440
00:17:15,665 --> 00:17:16,730
In the first case,

441
00:17:16,730 --> 00:17:18,995
the application actually
requests the data.

442
00:17:18,995 --> 00:17:21,245
The first thing
it will do,

443
00:17:21,245 --> 00:17:22,520
this application would

444
00:17:22,520 --> 00:17:23,510
actually look locally,

445
00:17:23,510 --> 00:17:24,785
and it resides there,

446
00:17:24,785 --> 00:17:26,195
then there's no need

447
00:17:26,195 --> 00:17:27,620
to search for it further.

448
00:17:27,620 --> 00:17:29,045
In the first case,

449
00:17:29,045 --> 00:17:30,080
you will see that the data

450
00:17:30,080 --> 00:17:31,460
it's actually at site A.

451
00:17:31,460 --> 00:17:33,365
But then in the
second case,

452
00:17:33,365 --> 00:17:37,175
these are the application,

453
00:17:37,175 --> 00:17:38,660
actually looks for
the data again

454
00:17:38,660 --> 00:17:40,880
local at site A, but
it doesn't find it.

455
00:17:40,880 --> 00:17:43,715
What it does after
that is go to step 2,

456
00:17:43,715 --> 00:17:45,455
and that is to ask

457
00:17:45,455 --> 00:17:48,110
its Regional Redirector
about a site,

458
00:17:48,110 --> 00:17:49,805
what the data can be.

459
00:17:49,805 --> 00:17:51,710
This redirector
would look at

460
00:17:51,710 --> 00:17:54,545
site B to see if the
file is in there,

461
00:17:54,545 --> 00:17:58,340
if not, then it will go
to Global Redirector.

462
00:17:58,340 --> 00:17:59,780
This redirector
would look at

463
00:17:59,780 --> 00:18:01,880
the director at EU,

464
00:18:01,880 --> 00:18:04,625
or maybe other
regions as well.

465
00:18:04,625 --> 00:18:06,410
When the data is found,

466
00:18:06,410 --> 00:18:07,520
finally, in this case,

467
00:18:07,520 --> 00:18:11,300
it's site C, then the
application site,

468
00:18:11,300 --> 00:18:12,845
they will be notified that

469
00:18:12,845 --> 00:18:14,360
here is the IP where

470
00:18:14,360 --> 00:18:15,530
the data is, in this case,

471
00:18:15,530 --> 00:18:17,720
it's site C, and then
the application would

472
00:18:17,720 --> 00:18:18,980
connect to that IP and

473
00:18:18,980 --> 00:18:20,390
actually read the data.

474
00:18:20,390 --> 00:18:22,324
Like I said, these
applications

475
00:18:22,324 --> 00:18:24,635
are called XRootD.

476
00:18:24,635 --> 00:18:26,855
What is actually XRootD?

477
00:18:26,855 --> 00:18:28,910
It's a framework, and it's

478
00:18:28,910 --> 00:18:31,280
basically the defined
management tool

479
00:18:31,280 --> 00:18:32,645
that's used at server

480
00:18:32,645 --> 00:18:35,750
for distributing and
reading data and so on.

481
00:18:35,750 --> 00:18:38,630
[NOISE] Among
other things,

482
00:18:38,630 --> 00:18:39,815
because it's a framework

483
00:18:39,815 --> 00:18:41,030
which they also enables

484
00:18:41,030 --> 00:18:42,560
developers to implement
various types

485
00:18:42,560 --> 00:18:44,525
of plug-ins for it.

486
00:18:44,525 --> 00:18:46,220
For example,
you can develop

487
00:18:46,220 --> 00:18:47,975
your own file system
plug-in for this,

488
00:18:47,975 --> 00:18:49,430
or caching plug-in or a

489
00:18:49,430 --> 00:18:51,155
security plug-in,
and so on.

490
00:18:51,155 --> 00:18:52,880
I mean the list is big.

491
00:18:52,880 --> 00:18:57,575
But it's a C++ framework,

492
00:18:57,575 --> 00:19:00,185
and the source code
it's open source.

493
00:19:00,185 --> 00:19:02,630
But they also develop
something in Golang,

494
00:19:02,630 --> 00:19:04,595
but it's just at
the beginning.

495
00:19:04,595 --> 00:19:07,130
In our case, we

496
00:19:07,130 --> 00:19:08,840
wanted to develop
this plug-in,

497
00:19:08,840 --> 00:19:09,740
which is called an Open

498
00:19:09,740 --> 00:19:11,045
Storage System plug-in,

499
00:19:11,045 --> 00:19:12,920
and it's actually
implementation

500
00:19:12,920 --> 00:19:14,225
of the file system.

501
00:19:14,225 --> 00:19:15,770
Its core is just

502
00:19:15,770 --> 00:19:18,035
the C++ dynamic
library that exports

503
00:19:18,035 --> 00:19:21,740
just one single symbol

504
00:19:21,740 --> 00:19:23,270
in order for
these to get to

505
00:19:23,270 --> 00:19:25,415
know how to load
this library.

506
00:19:25,415 --> 00:19:27,650
In the implementation of

507
00:19:27,650 --> 00:19:30,530
the plug-ins
actually needs to

508
00:19:30,530 --> 00:19:31,865
offer implementation for

509
00:19:31,865 --> 00:19:35,410
each posting slices
system then co-created.

510
00:19:35,410 --> 00:19:37,420
For example, you have
probably implementation

511
00:19:37,420 --> 00:19:38,830
for open, for
close, for read,

512
00:19:38,830 --> 00:19:40,700
for opendir, readdir,

513
00:19:40,700 --> 00:19:44,345
and all the other posting
plugins and calls.

514
00:19:44,345 --> 00:19:46,025
This is basically
the plug-in,

515
00:19:46,025 --> 00:19:48,020
and what we envision
is actually to

516
00:19:48,020 --> 00:19:51,125
embed an NDN consumer,

517
00:19:51,125 --> 00:19:53,615
in this issue the plug-in.

518
00:19:53,615 --> 00:19:56,240
That consumer should
be able to translate

519
00:19:56,240 --> 00:19:59,735
between the file system
call to an NDN name,

520
00:19:59,735 --> 00:20:02,525
then compose on interest
with that name,

521
00:20:02,525 --> 00:20:04,350
send it over an
NDN network,

522
00:20:04,350 --> 00:20:05,920
and the other end
would have producer

523
00:20:05,920 --> 00:20:07,360
that have access
to the data.

524
00:20:07,360 --> 00:20:08,680
They will send
the data back,

525
00:20:08,680 --> 00:20:10,540
and then the consumer
will read the data.

526
00:20:10,540 --> 00:20:12,235
We'll verify that
data is valid,

527
00:20:12,235 --> 00:20:15,130
and then put it back to
the XRootD framework.

528
00:20:15,130 --> 00:20:17,770
[NOISE] In our case,

529
00:20:17,770 --> 00:20:20,630
we did this,

530
00:20:20,630 --> 00:20:22,880
and we also had to came

531
00:20:22,880 --> 00:20:24,425
up with a naming scheme.

532
00:20:24,425 --> 00:20:25,970
For example, for B

533
00:20:25,970 --> 00:20:28,340
open or fstat file
system calls,

534
00:20:28,340 --> 00:20:30,170
we have this name,

535
00:20:30,170 --> 00:20:32,525
which the prefix
is NDN XRootD.

536
00:20:32,525 --> 00:20:34,160
Then you have the meta,

537
00:20:34,160 --> 00:20:38,030
which basically requests
a meta-package,

538
00:20:38,030 --> 00:20:40,040
which is also
requested when

539
00:20:40,040 --> 00:20:43,235
the file system
is open or fstat.

540
00:20:43,235 --> 00:20:45,440
The data packet of

541
00:20:45,440 --> 00:20:47,090
interest contains a bunch

542
00:20:47,090 --> 00:20:48,995
of information
about the file.

543
00:20:48,995 --> 00:20:50,300
Then basically
in the green,

544
00:20:50,300 --> 00:20:51,830
you have the file path.

545
00:20:51,830 --> 00:20:52,790
Now for example, for

546
00:20:52,790 --> 00:20:54,170
the read file system call,

547
00:20:54,170 --> 00:20:55,310
there's a different name.

548
00:20:55,310 --> 00:20:57,995
We have the same
prefix and the XRootD,

549
00:20:57,995 --> 00:21:00,110
you have the hyper,
and then you have

550
00:21:00,110 --> 00:21:01,340
the segment number and

551
00:21:01,340 --> 00:21:02,895
the version of the file.

552
00:21:02,895 --> 00:21:04,660
Then the producer
on the other hand

553
00:21:04,660 --> 00:21:06,010
will not to translate

554
00:21:06,010 --> 00:21:07,570
the segment number
to an offset

555
00:21:07,570 --> 00:21:09,860
in the corresponding file.

556
00:21:09,970 --> 00:21:13,310
This is what we
did already.

557
00:21:13,310 --> 00:21:16,670
The first implementation
of this was using

558
00:21:16,670 --> 00:21:19,475
the NDNCX library with

559
00:21:19,475 --> 00:21:24,605
NFD and we run a bunch
of tests on that,

560
00:21:24,605 --> 00:21:26,825
and all this we're stuck

561
00:21:26,825 --> 00:21:29,375
below one gigabit per
second performance.

562
00:21:29,375 --> 00:21:31,730
As you can see in
these two diagrams,

563
00:21:31,730 --> 00:21:34,020
in the first one above,

564
00:21:34,200 --> 00:21:36,790
once we apply the
interface on the delay,

565
00:21:36,790 --> 00:21:40,370
the throughput
also went down.

566
00:21:40,390 --> 00:21:43,280
It was working. It was
a good experiment,

567
00:21:43,280 --> 00:21:45,665
but the trucker
performance wasn't there.

568
00:21:45,665 --> 00:21:49,340
We also compared our
consumer that was

569
00:21:49,340 --> 00:21:51,140
embedded in the library

570
00:21:51,140 --> 00:21:53,810
with the NDN
put in chunks,

571
00:21:53,810 --> 00:21:55,820
and they actually
performed

572
00:21:55,820 --> 00:21:58,055
better than those
applications.

573
00:21:58,055 --> 00:21:59,720
But either way,

574
00:21:59,720 --> 00:22:01,415
the performance
was not that good.

575
00:22:01,415 --> 00:22:03,860
But we continue to

576
00:22:03,860 --> 00:22:05,540
test this plug-in just to

577
00:22:05,540 --> 00:22:07,025
see that the NDN can work,

578
00:22:07,025 --> 00:22:10,815
and one of our
colleagues, Justice.

579
00:22:10,815 --> 00:22:14,230
he run a bunch of
tests and compared

580
00:22:14,230 --> 00:22:17,575
the NDN with multiple
storage solutions.

581
00:22:17,575 --> 00:22:18,970
In this diagram,
you will see

582
00:22:18,970 --> 00:22:21,400
the success rate
of CMS jobs,

583
00:22:21,400 --> 00:22:22,870
those user
application that I

584
00:22:22,870 --> 00:22:25,180
was talking about earlier.

585
00:22:25,180 --> 00:22:27,590
Here's the success
versus failed rate.

586
00:22:27,590 --> 00:22:29,275
He compared it against

587
00:22:29,275 --> 00:22:30,550
Ceph, against Hadoop,

588
00:22:30,550 --> 00:22:32,425
against using

589
00:22:32,425 --> 00:22:34,410
differentiated directors
one at Fermilab,

590
00:22:34,410 --> 00:22:35,965
one at Caltech,
one at CERN,

591
00:22:35,965 --> 00:22:39,685
and against all different
kinds of caches.

592
00:22:39,685 --> 00:22:42,235
Here in the
right, it's NDN.

593
00:22:42,235 --> 00:22:45,235
We can see that at
least for this test,

594
00:22:45,235 --> 00:22:49,775
it did perform good.

595
00:22:49,775 --> 00:22:51,640
Looking forward, you can

596
00:22:51,640 --> 00:22:53,480
also see that the
time to complete

597
00:22:53,480 --> 00:22:56,710
all these 269
jobs was fairly

598
00:22:56,710 --> 00:22:58,480
average using
the NDN library

599
00:22:58,480 --> 00:23:00,520
one compared to the
other solution.

600
00:23:00,520 --> 00:23:02,740
The idea is good,
but then we know

601
00:23:02,740 --> 00:23:04,660
that if you want to

602
00:23:04,660 --> 00:23:06,970
use thousands and
thousands of jobs,

603
00:23:06,970 --> 00:23:08,665
which happens
in production,

604
00:23:08,665 --> 00:23:11,455
then the triple would
have been better.

605
00:23:11,455 --> 00:23:14,055
We continue to search

606
00:23:14,055 --> 00:23:16,515
for performance per
our applications.

607
00:23:16,515 --> 00:23:18,210
We knew that the NFD

608
00:23:18,210 --> 00:23:20,545
was one of the
main bottlenecks.

609
00:23:20,545 --> 00:23:22,345
Luckily at the
same time, I think

610
00:23:22,345 --> 00:23:24,755
the NDN team at

611
00:23:24,755 --> 00:23:26,560
NIST was already working

612
00:23:26,560 --> 00:23:28,985
on the NDN-DPDK forwarder.

613
00:23:28,985 --> 00:23:30,970
As soon as they
find about that,

614
00:23:30,970 --> 00:23:32,110
we implemented

615
00:23:32,110 --> 00:23:33,340
our own DPDK consumer and

616
00:23:33,340 --> 00:23:34,689
producer applications

617
00:23:34,689 --> 00:23:37,675
which were generating
a file transfer.

618
00:23:37,675 --> 00:23:40,235
We demo that at
SuperComputing 2019.

619
00:23:40,235 --> 00:23:47,740
We got a performance

620
00:23:47,740 --> 00:23:49,985
of about 6.7 gigabits

621
00:23:49,985 --> 00:23:52,885
per second over a
wide area network.

622
00:23:52,885 --> 00:23:56,300
But then the drawback
for this was just

623
00:23:56,300 --> 00:23:57,610
the fact that there

624
00:23:57,610 --> 00:23:59,375
wasn't any NDN API for us,

625
00:23:59,375 --> 00:24:00,430
so we had to implement

626
00:24:00,430 --> 00:24:02,450
everything almost
from scratch.

627
00:24:02,450 --> 00:24:06,620
For us, this is
not the way to go.

628
00:24:06,620 --> 00:24:08,440
We want to focus
on other things,

629
00:24:08,440 --> 00:24:10,720
not rebuilding
NDN from scratch.

630
00:24:10,720 --> 00:24:13,175
But the worst thing

631
00:24:13,175 --> 00:24:14,830
for us was
actually to deploy

632
00:24:14,830 --> 00:24:19,120
these applications
on the machine

633
00:24:19,120 --> 00:24:20,260
at CMS because they

634
00:24:20,260 --> 00:24:23,395
all use old-center
machines.

635
00:24:23,395 --> 00:24:25,620
It's a big hustle
to actually start

636
00:24:25,620 --> 00:24:27,065
the DPDK applications
on this kind

637
00:24:27,065 --> 00:24:29,365
of operating system
and so and so.

638
00:24:29,365 --> 00:24:30,670
Although the
performance was

639
00:24:30,670 --> 00:24:31,990
super good and promising,

640
00:24:31,990 --> 00:24:33,970
the actual useability of

641
00:24:33,970 --> 00:24:35,200
it and also

642
00:24:35,200 --> 00:24:37,135
the development
was not that good.

643
00:24:37,135 --> 00:24:40,205
We continue to look
forward and further to

644
00:24:40,205 --> 00:24:42,335
this NDNgo library that

645
00:24:42,335 --> 00:24:44,065
was also developed
by NIST.

646
00:24:44,065 --> 00:24:46,055
Meeting goal, we developed

647
00:24:46,055 --> 00:24:47,215
the consumer and
producer for

648
00:24:47,215 --> 00:24:49,000
that as well
in [inaudible]

649
00:24:49,000 --> 00:24:50,605
just to simulate
file transfers.

650
00:24:50,605 --> 00:24:52,180
We got around 2.2

651
00:24:52,180 --> 00:24:54,890
gigabits per second
with just one consumer.

652
00:24:54,890 --> 00:24:58,975
We expecting maybe more
because it already

653
00:24:58,975 --> 00:25:00,850
used many which
is the interface

654
00:25:00,850 --> 00:25:03,445
that you can connect
to NDN-DPDK.

655
00:25:03,445 --> 00:25:05,075
But then we learned
that this library

656
00:25:05,075 --> 00:25:06,820
wasn't actually built
for this kind of stuff,

657
00:25:06,820 --> 00:25:11,000
but more for management
or the forwarder.

658
00:25:11,310 --> 00:25:13,360
This is the results

659
00:25:13,360 --> 00:25:15,805
for the
SuperComputing 2019.

660
00:25:15,805 --> 00:25:17,830
We have the performance of

661
00:25:17,830 --> 00:25:20,000
about 6.7 gigabits
per second.

662
00:25:20,000 --> 00:25:22,985
The experiment was
only for three hours,

663
00:25:22,985 --> 00:25:24,365
again with the DPDK

664
00:25:24,365 --> 00:25:26,395
consumer-producer
applications.

665
00:25:26,395 --> 00:25:29,135
Then we arrive at
[inaudible] where,

666
00:25:29,135 --> 00:25:31,555
as Professor Yen
mentioned earlier,

667
00:25:31,555 --> 00:25:33,275
our goal is to

668
00:25:33,275 --> 00:25:35,245
achieve 100 gigabits
per second.

669
00:25:35,245 --> 00:25:38,215
That can be given a
aggregate throughput.

670
00:25:38,215 --> 00:25:40,810
We came up with
this diagram here

671
00:25:40,810 --> 00:25:43,280
where you have
an NDN network,

672
00:25:43,280 --> 00:25:46,210
you're using
NDN-DPDK forwarders.

673
00:25:46,210 --> 00:25:47,365
Then at one end,

674
00:25:47,365 --> 00:25:49,210
you have Ceph that have

675
00:25:49,210 --> 00:25:52,135
access to the CMS data.

676
00:25:52,135 --> 00:25:54,370
There you have host with

677
00:25:54,370 --> 00:25:58,300
dedicated NICs where we

678
00:25:58,300 --> 00:26:01,070
also run docker
containers,

679
00:26:01,070 --> 00:26:02,170
where you have

680
00:26:02,170 --> 00:26:03,850
the NDN-DPDK
forwarder running in

681
00:26:03,850 --> 00:26:05,005
one docker container and

682
00:26:05,005 --> 00:26:07,585
uses that network card.

683
00:26:07,585 --> 00:26:10,240
Then you maybe have

684
00:26:10,240 --> 00:26:12,100
a producer that uses

685
00:26:12,100 --> 00:26:14,500
memif, it's written C++.

686
00:26:14,500 --> 00:26:17,695
It's fast and it can
access the storage,

687
00:26:17,695 --> 00:26:20,125
but then also can use
other solution of

688
00:26:20,125 --> 00:26:22,750
other file
transfer servers

689
00:26:22,750 --> 00:26:26,230
like one that will
be later presented.

690
00:26:26,230 --> 00:26:28,840
On the left side, you
have the consumers.

691
00:26:28,840 --> 00:26:31,060
Again, this is on
the left-hand side.

692
00:26:31,060 --> 00:26:33,865
You can have one or
more host machines.

693
00:26:33,865 --> 00:26:36,575
Then again you have
one dedicated NIC

694
00:26:36,575 --> 00:26:37,630
that's going to be used by

695
00:26:37,630 --> 00:26:40,210
the NDN-DPDK forwarder

696
00:26:40,210 --> 00:26:41,605
running the
docker container.

697
00:26:41,605 --> 00:26:43,745
Then another docker
containers will have

698
00:26:43,745 --> 00:26:46,050
actually XRootD
plugins which

699
00:26:46,050 --> 00:26:50,975
embed NDN
consumer in that.

700
00:26:50,975 --> 00:26:52,270
Then at that side,

701
00:26:52,270 --> 00:26:53,630
we have thousands
and thousands of

702
00:26:53,630 --> 00:26:55,600
CMS jobs that are

703
00:26:55,600 --> 00:26:57,520
accessing this
XRootD applications.

704
00:26:57,520 --> 00:26:58,975
Then they will send

705
00:26:58,975 --> 00:27:01,170
and request data
across the network.

706
00:27:01,170 --> 00:27:08,610
Then what is NDNc? Sorry.

707
00:27:08,610 --> 00:27:14,085
>> A minute, I'm
running that file.

708
00:27:14,085 --> 00:27:16,805
>> Sorry. Yeah, the NDNc

709
00:27:16,805 --> 00:27:18,820
is basically a
small library,

710
00:27:18,820 --> 00:27:20,215
a set of functions
that actually

711
00:27:20,215 --> 00:27:22,780
adds ndn-cxx
support back to

712
00:27:22,780 --> 00:27:24,455
NDN-DPDK and it uses

713
00:27:24,455 --> 00:27:27,130
memif shared memory
packet interface.

714
00:27:27,130 --> 00:27:29,615
At the moment, we have
already implemented

715
00:27:29,615 --> 00:27:31,360
the GraphQL client
that enables

716
00:27:31,360 --> 00:27:33,370
us to configure
the forwarder,

717
00:27:33,370 --> 00:27:35,555
like creating a face,
inserting a FibEntry,

718
00:27:35,555 --> 00:27:36,120
or deleting

719
00:27:36,120 --> 00:27:38,570
some information
from the forwarder.

720
00:27:38,570 --> 00:27:40,620
At the moment,
like I said,

721
00:27:40,620 --> 00:27:41,950
has a transport
layer which

722
00:27:41,950 --> 00:27:44,170
is memif but is
single-threaded,

723
00:27:44,170 --> 00:27:46,840
also has a face object
that enables us to

724
00:27:46,840 --> 00:27:48,295
send one or more packets

725
00:27:48,295 --> 00:27:49,795
at the time of
the network.

726
00:27:49,795 --> 00:27:53,095
It also offers PIT
token support,

727
00:27:53,095 --> 00:27:55,930
something that
ndn-cxx doesn't do.

728
00:27:55,930 --> 00:27:58,000
Yeah, we also have

729
00:27:58,000 --> 00:28:00,580
some abstract classes
that you can use

730
00:28:00,580 --> 00:28:02,320
to base your
customer-producer application

731
00:28:02,320 --> 00:28:04,495
upon and also have some
congestion window,

732
00:28:04,495 --> 00:28:06,300
retransmissions
in there already.

733
00:28:06,300 --> 00:28:08,845
We have a fixed
window and a AIMD.

734
00:28:08,845 --> 00:28:10,630
We plan to add more soon.

735
00:28:10,630 --> 00:28:13,090
We also have a logger
and we also have CMake

736
00:28:13,090 --> 00:28:16,460
and Dockerfile for
deploying all of this.

737
00:28:16,460 --> 00:28:18,320
Using the NDNc,

738
00:28:18,320 --> 00:28:19,690
we already build
two applications.

739
00:28:19,690 --> 00:28:21,820
We build the PING
consumer and also build

740
00:28:21,820 --> 00:28:23,350
a high transfer consumer

741
00:28:23,350 --> 00:28:24,920
and producer applications.

742
00:28:24,920 --> 00:28:26,480
So far so good.

743
00:28:26,480 --> 00:28:28,630
Just with one consumer,

744
00:28:28,630 --> 00:28:32,015
the maximum is
4.3 gigabits per

745
00:28:32,015 --> 00:28:35,525
second this in 6,600
bytes per payload size.

746
00:28:35,525 --> 00:28:38,315
We think that this is
the way to go moving

747
00:28:38,315 --> 00:28:42,130
forward and we like
to build upon this.

748
00:28:42,130 --> 00:28:43,990
Like I said, we would

749
00:28:43,990 --> 00:28:45,310
like to continue
to bring more

750
00:28:45,310 --> 00:28:46,750
benchmarking to

751
00:28:46,750 --> 00:28:49,745
identify possible
bottlenecks and maybe

752
00:28:49,745 --> 00:28:53,110
implement some of our
own method and not use

753
00:28:53,110 --> 00:28:54,465
everything from ndn-cxx,

754
00:28:54,465 --> 00:28:56,630
add multiple-threaded
support.

755
00:28:56,630 --> 00:29:00,530
Since we asked also
to make a wish list,

756
00:29:00,530 --> 00:29:01,820
I just made one,

757
00:29:01,820 --> 00:29:03,815
and that is to actually,

758
00:29:03,815 --> 00:29:05,290
maybe more would like

759
00:29:05,290 --> 00:29:06,910
to join our efforts,
I don't know.

760
00:29:06,910 --> 00:29:07,600
Maybe there are

761
00:29:07,600 --> 00:29:09,220
some other people
in this community

762
00:29:09,220 --> 00:29:10,570
that are also like us

763
00:29:10,570 --> 00:29:12,985
looking for throughput
performance.

764
00:29:12,985 --> 00:29:15,385
It would be nice to
get in touch and

765
00:29:15,385 --> 00:29:18,530
work on this
together. Thank you.

766
00:29:19,050 --> 00:29:22,750
>> Great, thanks. There's
some discussion on

767
00:29:22,750 --> 00:29:25,865
the Slack channel
asking about

768
00:29:25,865 --> 00:29:27,365
how were you able to

769
00:29:27,365 --> 00:29:29,770
achieve performance more
than five gigabits.

770
00:29:29,770 --> 00:29:31,945
You showed 6.7, right?

771
00:29:31,945 --> 00:29:32,770
>> Yes.

772
00:29:32,770 --> 00:29:34,780
>> One good question is,

773
00:29:34,780 --> 00:29:37,015
what's on top of

774
00:29:37,015 --> 00:29:38,380
your list to booth

775
00:29:38,380 --> 00:29:39,640
the throughput
performance?

776
00:29:39,640 --> 00:29:41,830
What's the next bottleneck

777
00:29:41,830 --> 00:29:45,040
you're going to address?

778
00:29:45,040 --> 00:29:47,710
>> Yes, this is
a good question.

779
00:29:47,710 --> 00:29:51,190
This is a network
that is new,

780
00:29:51,190 --> 00:29:55,300
we can't afford for
about 5-4 months.

781
00:29:55,300 --> 00:29:59,210
It's still young,
it's a young project.

782
00:30:00,030 --> 00:30:02,795
Like I said, we need
to do benchmarking

783
00:30:02,795 --> 00:30:04,870
a lot to understand what
the bottlenecks are.

784
00:30:04,870 --> 00:30:05,945
Of course, at the moment

785
00:30:05,945 --> 00:30:07,315
it's all single-threaded.

786
00:30:07,315 --> 00:30:09,785
The easiest thing to do
is go multi-threaded.

787
00:30:09,785 --> 00:30:11,910
But I think until
we do that,

788
00:30:11,910 --> 00:30:13,145
we would like to

789
00:30:13,145 --> 00:30:15,430
get the best performance

790
00:30:15,430 --> 00:30:16,975
out of the single-thread.

791
00:30:16,975 --> 00:30:19,085
Yes, we don't know

792
00:30:19,085 --> 00:30:20,620
exactly if we have

793
00:30:20,620 --> 00:30:22,075
bottlenecks and
where those are,

794
00:30:22,075 --> 00:30:24,740
but we need to
do more testing.

795
00:30:24,740 --> 00:30:28,355
>> Okay, good.
Thanks again.

796
00:30:28,355 --> 00:30:30,070
You can continue
the discussion

797
00:30:30,070 --> 00:30:32,095
on the Slack channel.

798
00:30:32,095 --> 00:30:35,005
There are a few things
you can address there.

799
00:30:35,005 --> 00:30:39,320
Our next speaker
is Sichen Song.

800
00:30:39,320 --> 00:30:42,570
Sichen is a
master's student at

801
00:30:42,570 --> 00:30:46,050
UCLA and is a
research assistant

802
00:30:46,050 --> 00:30:48,660
in the Internet Research
Lab working on NDN

803
00:30:48,660 --> 00:30:50,865
including
congestion control

804
00:30:50,865 --> 00:30:52,605
and he does mitigation.

805
00:30:52,605 --> 00:30:55,260
He's going to tell
us about his work on

806
00:30:55,260 --> 00:30:56,460
congestion control in

807
00:30:56,460 --> 00:30:58,865
support and this project.

808
00:30:58,865 --> 00:31:01,690
Go ahead, please, Sichen.

809
00:31:01,690 --> 00:31:05,995
>> Thanks. Can you
see my screen?

810
00:31:05,995 --> 00:31:07,300
Is it present?

811
00:31:07,300 --> 00:31:09,095
>> Yeah, good to go. Yes.

812
00:31:09,095 --> 00:31:12,235
>> Is it present?

813
00:31:12,235 --> 00:31:14,230
>> It's on screen, yes.

814
00:31:14,230 --> 00:31:21,020
>> Okay. Thanks. I'm
Sichen from UCLA,

815
00:31:21,020 --> 00:31:23,765
I'm going to talk
about our work,

816
00:31:23,765 --> 00:31:26,615
our rate based
congestion control.

817
00:31:26,615 --> 00:31:29,960
Lets start with a
problem description.

818
00:31:29,960 --> 00:31:31,880
Congestion control
algorithms in

819
00:31:31,880 --> 00:31:34,985
TCPIP are window-based
in general.

820
00:31:34,985 --> 00:31:37,385
Those algorithms are

821
00:31:37,385 --> 00:31:38,900
estimatings of pipe size,

822
00:31:38,900 --> 00:31:41,030
which is a maximum amount

823
00:31:41,030 --> 00:31:42,290
of bytes inside

824
00:31:42,290 --> 00:31:44,075
the network without
killing it.

825
00:31:44,075 --> 00:31:46,010
Adjust the
condenser window

826
00:31:46,010 --> 00:31:47,570
two p's a pipe size.

827
00:31:47,570 --> 00:31:48,980
In India, there's

828
00:31:48,980 --> 00:31:50,600
dynamic multi-pass
poverty and

829
00:31:50,600 --> 00:31:52,250
caching that destroys

830
00:31:52,250 --> 00:31:54,470
the concept of pipe size.

831
00:31:54,470 --> 00:31:57,005
So we hope to work on

832
00:31:57,005 --> 00:31:58,730
a congestion
control algorithm

833
00:31:58,730 --> 00:32:02,000
that battlefields
named data networking.

834
00:32:02,000 --> 00:32:04,580
The algorithm should
be adaptive to

835
00:32:04,580 --> 00:32:07,625
the available bandwidth
or our active paths,

836
00:32:07,625 --> 00:32:09,155
and also it should be

837
00:32:09,155 --> 00:32:12,510
insensitive to round
trip time variations.

838
00:32:12,880 --> 00:32:16,535
We hope to start this
effort by letting

839
00:32:16,535 --> 00:32:19,040
end-consumers do
measurements and

840
00:32:19,040 --> 00:32:21,515
adjust these
transmission rates.

841
00:32:21,515 --> 00:32:24,515
We have four goals
in importance order.

842
00:32:24,515 --> 00:32:26,840
The designs should be

843
00:32:26,840 --> 00:32:28,280
able to prevent long queue

844
00:32:28,280 --> 00:32:32,180
building up and to have
high bandwidth usage.

845
00:32:32,180 --> 00:32:34,130
Not to rely on packet loss

846
00:32:34,130 --> 00:32:35,810
as the congestion signal.

847
00:32:35,810 --> 00:32:40,550
Lastly, it should
give a good fairness.

848
00:32:40,550 --> 00:32:43,920
At least there should
not be starvation.

849
00:32:45,250 --> 00:32:47,450
For this talk, I hope

850
00:32:47,450 --> 00:32:50,990
to talk about our work in

851
00:32:50,990 --> 00:32:53,270
progress of this part

852
00:32:53,270 --> 00:32:56,900
and I'll talk about
our current design.

853
00:32:56,900 --> 00:32:59,960
So congestion control
and also about

854
00:32:59,960 --> 00:33:02,495
a interesting
observation of

855
00:33:02,495 --> 00:33:04,055
measurement interference

856
00:33:04,055 --> 00:33:06,875
between consumers
and their caching.

857
00:33:06,875 --> 00:33:11,450
Let's start with basic
idea of the design.

858
00:33:11,450 --> 00:33:14,330
So the basic idea

859
00:33:14,330 --> 00:33:17,090
is to control the
interests sending

860
00:33:17,090 --> 00:33:20,225
rates instead of the
congestion window

861
00:33:20,225 --> 00:33:22,730
and we do it
round by round.

862
00:33:22,730 --> 00:33:24,470
At each round restart

863
00:33:24,470 --> 00:33:26,525
by keep sending
us the same,

864
00:33:26,525 --> 00:33:28,430
the consumers sending at

865
00:33:28,430 --> 00:33:30,260
the same sending rate as

866
00:33:30,260 --> 00:33:32,825
illustrated by
this blue line.

867
00:33:32,825 --> 00:33:34,775
This keeps going for

868
00:33:34,775 --> 00:33:36,185
a maximum round-trip delay

869
00:33:36,185 --> 00:33:37,985
among our
forwarding paths.

870
00:33:37,985 --> 00:33:39,650
This allows the consumer

871
00:33:39,650 --> 00:33:40,970
to observe the effect of

872
00:33:40,970 --> 00:33:45,620
these rates at our
multiple folding paths.

873
00:33:45,620 --> 00:33:48,320
Afterwards, a
measurement of

874
00:33:48,320 --> 00:33:49,430
data arrival rates will

875
00:33:49,430 --> 00:33:51,050
start for a
matter of time.

876
00:33:51,050 --> 00:33:53,150
During this time,
the consumer

877
00:33:53,150 --> 00:33:54,590
tries to keep sending

878
00:33:54,590 --> 00:33:55,670
while getting

879
00:33:55,670 --> 00:33:58,385
an accurate data arrival
rate measurements.

880
00:33:58,385 --> 00:34:00,005
Then later,

881
00:34:00,005 --> 00:34:03,050
after these two
parts have ended,

882
00:34:03,050 --> 00:34:04,250
the consumer needs to make

883
00:34:04,250 --> 00:34:06,395
the decision of whether
there's congestion.

884
00:34:06,395 --> 00:34:07,805
This is done by

885
00:34:07,805 --> 00:34:09,650
thresholding the
difference between

886
00:34:09,650 --> 00:34:11,420
the data arrival
rate measurement

887
00:34:11,420 --> 00:34:13,565
and the current
interest sending rate.

888
00:34:13,565 --> 00:34:15,785
If there's more
or less the same,

889
00:34:15,785 --> 00:34:17,270
the consumer would
think there's

890
00:34:17,270 --> 00:34:19,655
no congestion and
continue to increase

891
00:34:19,655 --> 00:34:21,860
is interest sending
rate following

892
00:34:21,860 --> 00:34:23,450
a cubic curve similar

893
00:34:23,450 --> 00:34:25,895
to the idea of TCP cubic.

894
00:34:25,895 --> 00:34:29,645
After keeping going
without congestion,

895
00:34:29,645 --> 00:34:32,300
eventually the consumer
will get above

896
00:34:32,300 --> 00:34:34,205
the network capacity and

897
00:34:34,205 --> 00:34:36,425
a congestion and
will be caused.

898
00:34:36,425 --> 00:34:38,584
When this happens,

899
00:34:38,584 --> 00:34:42,095
it is expected that
the consumer will

900
00:34:42,095 --> 00:34:44,030
observe his
interest sending

901
00:34:44,030 --> 00:34:45,380
rates will be faster than

902
00:34:45,380 --> 00:34:46,760
the data arrival rate

903
00:34:46,760 --> 00:34:49,160
and by that holding
their difference,

904
00:34:49,160 --> 00:34:50,990
the consumer will
be able to detect

905
00:34:50,990 --> 00:34:53,090
the congestion
at this point

906
00:34:53,090 --> 00:34:55,670
and the trigger a
multiplicative decrease

907
00:34:55,670 --> 00:34:57,634
to avoid the congestion.

908
00:34:57,634 --> 00:35:00,050
Of course, network
congestions are not

909
00:35:00,050 --> 00:35:02,630
always caused by
this consumer,

910
00:35:02,630 --> 00:35:05,450
but can also be caused
by external factors.

911
00:35:05,450 --> 00:35:06,860
When congestions are

912
00:35:06,860 --> 00:35:08,824
caused by
external factors.

913
00:35:08,824 --> 00:35:10,400
For example, a bottleneck

914
00:35:10,400 --> 00:35:11,780
bandwidths
suddenly dropped,

915
00:35:11,780 --> 00:35:14,060
we expect as a
consumer we'll see

916
00:35:14,060 --> 00:35:15,950
some unexpected drop of

917
00:35:15,950 --> 00:35:18,110
data arrival rates and to

918
00:35:18,110 --> 00:35:19,520
react with congestion as

919
00:35:19,520 --> 00:35:21,080
quick as possible when

920
00:35:21,080 --> 00:35:22,520
the consumer observes a

921
00:35:22,520 --> 00:35:24,965
data arrival rates drop.

922
00:35:24,965 --> 00:35:26,405
It will also trigger

923
00:35:26,405 --> 00:35:27,830
a multiplicative decrease

924
00:35:27,830 --> 00:35:30,125
to a wider congestion.

925
00:35:30,125 --> 00:35:33,199
With this basic idea,

926
00:35:33,199 --> 00:35:34,985
I will talk about

927
00:35:34,985 --> 00:35:37,220
an interesting observation

928
00:35:37,220 --> 00:35:38,945
in our evaluation process,

929
00:35:38,945 --> 00:35:41,120
which is measurement
interference

930
00:35:41,120 --> 00:35:44,010
between consumers
and their caching.

931
00:35:44,860 --> 00:35:48,335
Let's start with the
scenario we are using.

932
00:35:48,335 --> 00:35:49,849
We have two consumers,

933
00:35:49,849 --> 00:35:51,860
C1 and C2 fetch

934
00:35:51,860 --> 00:35:54,950
the same data
object in order.

935
00:35:54,950 --> 00:35:57,095
C2 started early, so it's

936
00:35:57,095 --> 00:35:59,400
able to make more
progress initially.

937
00:35:59,400 --> 00:36:01,300
The forwarder here F1 has

938
00:36:01,300 --> 00:36:03,900
a very large
content store.

939
00:36:03,900 --> 00:36:06,980
We expect that after
C1 has started,

940
00:36:06,980 --> 00:36:08,960
it will initially
be satisfied by

941
00:36:08,960 --> 00:36:11,510
the orders cache that has

942
00:36:11,510 --> 00:36:14,510
its bandwidth to
the forwarder is

943
00:36:14,510 --> 00:36:16,010
much higher than
the bandwidth to

944
00:36:16,010 --> 00:36:17,725
the producer.

945
00:36:17,725 --> 00:36:19,870
It will eventually bring

946
00:36:19,870 --> 00:36:22,390
the cache and be
able to catch up

947
00:36:22,390 --> 00:36:24,625
with the other
consumer that started

948
00:36:24,625 --> 00:36:28,080
early and then be
satisfied as a producer.

949
00:36:28,080 --> 00:36:32,510
Our evaluations shows
in that our design,

950
00:36:32,510 --> 00:36:35,525
the consumer C1 will keep

951
00:36:35,525 --> 00:36:37,070
satisfied by
the cache most

952
00:36:37,070 --> 00:36:38,795
of the time in
the steady-state,

953
00:36:38,795 --> 00:36:41,030
so he is not able
to fully catch up.

954
00:36:41,030 --> 00:36:43,475
We hope to understand why.

955
00:36:43,475 --> 00:36:45,320
So we take a look at

956
00:36:45,320 --> 00:36:47,180
the C1's perspective to

957
00:36:47,180 --> 00:36:49,250
observe what's
going to happen.

958
00:36:49,250 --> 00:36:51,680
Of course, initially, C1

959
00:36:51,680 --> 00:36:54,020
will be satisfied by
the content store and

960
00:36:54,020 --> 00:36:57,050
it's observed
round-trip delay

961
00:36:57,050 --> 00:36:58,670
will be round-trip delay

962
00:36:58,670 --> 00:37:01,190
to the cache and

963
00:37:01,190 --> 00:37:03,455
if C1 eventually
catches up,

964
00:37:03,455 --> 00:37:05,990
it will be satisfied
by the producer and

965
00:37:05,990 --> 00:37:07,580
the round trip
delays events this

966
00:37:07,580 --> 00:37:09,875
will be the round-trip
delay to the producer.

967
00:37:09,875 --> 00:37:12,845
However, there is a
stage in the middle.

968
00:37:12,845 --> 00:37:15,770
In this stage, by

969
00:37:15,770 --> 00:37:17,030
the time C1's interest

970
00:37:17,030 --> 00:37:18,455
goes to the forwarder,

971
00:37:18,455 --> 00:37:20,510
the early starter's
interests

972
00:37:20,510 --> 00:37:21,980
have already passed
the forwarder,

973
00:37:21,980 --> 00:37:24,770
so forwarder just
aggregates that interests.

974
00:37:24,770 --> 00:37:27,695
However, the early
starter C2 state

975
00:37:27,695 --> 00:37:30,260
at that time had not
returned to cache.

976
00:37:30,260 --> 00:37:33,440
So C1 is not able to
be satisfied by cache.

977
00:37:33,440 --> 00:37:35,450
So C1 will wait
a little bit

978
00:37:35,450 --> 00:37:37,760
for the data solicited by

979
00:37:37,760 --> 00:37:40,340
the other consumer to
come back and then

980
00:37:40,340 --> 00:37:43,715
be used to satisfy
its own interests.

981
00:37:43,715 --> 00:37:46,175
We can see that two
round-trip delay,

982
00:37:46,175 --> 00:37:47,960
similar observes,
is between

983
00:37:47,960 --> 00:37:50,195
the two other end states.

984
00:37:50,195 --> 00:37:51,830
Also, the round-trip delay

985
00:37:51,830 --> 00:37:53,540
it observes depends on

986
00:37:53,540 --> 00:37:55,190
the progress difference

987
00:37:55,190 --> 00:37:57,110
between the two consumers.

988
00:37:57,110 --> 00:37:59,540
Since C1 is trying
to catch up and

989
00:37:59,540 --> 00:38:02,270
it's sending faster than
the other consumer,

990
00:38:02,270 --> 00:38:05,180
we would think that as
a round-trip delay,

991
00:38:05,180 --> 00:38:07,010
we'll do a gradual
change since

992
00:38:07,010 --> 00:38:08,810
the progress difference is

993
00:38:08,810 --> 00:38:10,685
making a gradual change.

994
00:38:10,685 --> 00:38:12,605
If we take a closer look

995
00:38:12,605 --> 00:38:14,300
in this stage
in the middle,

996
00:38:14,300 --> 00:38:16,100
you'll find out
that not only will

997
00:38:16,100 --> 00:38:18,980
C1 see a gradual
round-trip delay increase,

998
00:38:18,980 --> 00:38:23,180
but since the otherwise
solicited data

999
00:38:23,180 --> 00:38:25,835
will be used to satisfy
C1's interests,

1000
00:38:25,835 --> 00:38:29,300
C1's data arrival
rate will show as

1001
00:38:29,300 --> 00:38:30,920
C2's interest sending rate

1002
00:38:30,920 --> 00:38:32,660
or C2's data arrival rate.

1003
00:38:32,660 --> 00:38:34,565
Well meanwhile C1 being

1004
00:38:34,565 --> 00:38:36,185
able trying to catch up,

1005
00:38:36,185 --> 00:38:39,050
will send much
faster than C2.

1006
00:38:39,050 --> 00:38:40,340
That means that C1,

1007
00:38:40,340 --> 00:38:43,400
will also see
a mismatch of

1008
00:38:43,400 --> 00:38:44,690
its interest
sending rate and

1009
00:38:44,690 --> 00:38:46,160
data arrival rate is

1010
00:38:46,160 --> 00:38:48,530
sent faster than
it received.

1011
00:38:48,530 --> 00:38:50,645
Both of these two,

1012
00:38:50,645 --> 00:38:52,640
both delay and
rate indicates

1013
00:38:52,640 --> 00:38:54,875
that there is
a congestion,

1014
00:38:54,875 --> 00:38:57,950
which is not true in
this case, as we know.

1015
00:38:57,950 --> 00:39:02,555
People may ask,
is this an issue

1016
00:39:02,555 --> 00:39:05,150
because C1 is satisfied by

1017
00:39:05,150 --> 00:39:08,300
cache and cache is
effectively used.

1018
00:39:08,300 --> 00:39:10,595
This bottleneck
bandwidth is used by

1019
00:39:10,595 --> 00:39:12,515
this first starter and

1020
00:39:12,515 --> 00:39:14,495
is also effectively used.

1021
00:39:14,495 --> 00:39:18,620
Well, we need to
look into this.

1022
00:39:18,620 --> 00:39:21,140
The issue is that let's

1023
00:39:21,140 --> 00:39:23,930
say I change the
bottleneck link

1024
00:39:23,930 --> 00:39:26,480
from the first starter to

1025
00:39:26,480 --> 00:39:30,500
the forwarder with
very low value.

1026
00:39:30,500 --> 00:39:34,295
We know that C1 does
not even use this link.

1027
00:39:34,295 --> 00:39:36,440
When this happens, the

1028
00:39:36,440 --> 00:39:38,360
false congestion
is still there.

1029
00:39:38,360 --> 00:39:40,160
So whenever C1 is

1030
00:39:40,160 --> 00:39:42,770
trying to catch up with
the first starter,

1031
00:39:42,770 --> 00:39:45,005
it will always detect

1032
00:39:45,005 --> 00:39:47,780
a congestion and give
up its bandwidth.

1033
00:39:47,780 --> 00:39:49,430
Because of this,

1034
00:39:49,430 --> 00:39:51,950
the C2's bottleneck link

1035
00:39:51,950 --> 00:39:53,960
produced to the
forwarder which

1036
00:39:53,960 --> 00:39:55,865
is not even used by C1,

1037
00:39:55,865 --> 00:39:57,560
there'll be a
rate-limiting factor

1038
00:39:57,560 --> 00:39:59,810
of C1's performance and

1039
00:39:59,810 --> 00:40:02,195
also the bottleneck link

1040
00:40:02,195 --> 00:40:04,925
is not effectively
used in this case.

1041
00:40:04,925 --> 00:40:08,015
So I think this is an
interesting issue that

1042
00:40:08,015 --> 00:40:10,940
illustrates that
our initial design

1043
00:40:10,940 --> 00:40:13,355
does not match the
requirement of,

1044
00:40:13,355 --> 00:40:15,500
we need to be tolerant

1045
00:40:15,500 --> 00:40:17,670
who run through
time variations.

1046
00:40:17,670 --> 00:40:19,270
We also think that

1047
00:40:19,270 --> 00:40:21,070
this issue may
show up with

1048
00:40:21,070 --> 00:40:23,350
other congestion
control algorithms

1049
00:40:23,350 --> 00:40:25,060
that rely on minimum

1050
00:40:25,060 --> 00:40:26,395
round-trip delay
measurements,

1051
00:40:26,395 --> 00:40:29,600
such as TCPB Vegas or PBR.

1052
00:40:30,420 --> 00:40:32,590
We find that there are

1053
00:40:32,590 --> 00:40:35,190
true potential ways to
address this issue.

1054
00:40:35,190 --> 00:40:38,270
The first one is on
the consumer side,

1055
00:40:38,270 --> 00:40:42,275
if the consumer will
do reordering of

1056
00:40:42,275 --> 00:40:44,165
its segment
requests holders

1057
00:40:44,165 --> 00:40:47,760
whenever it sees a round
trip time increase.

1058
00:40:47,890 --> 00:40:50,450
For example, when C1

1059
00:40:50,450 --> 00:40:52,235
sees a round trip
time increase,

1060
00:40:52,235 --> 00:40:55,490
it will reorder is segment
request holder and

1061
00:40:55,490 --> 00:40:57,170
C2 will now do
the same thing

1062
00:40:57,170 --> 00:40:59,390
because C1 and
C2 as at hand,

1063
00:40:59,390 --> 00:41:01,100
we will have a different

1064
00:41:01,100 --> 00:41:03,470
interest sending holder.

1065
00:41:03,470 --> 00:41:05,870
So if C1 is
satisfied by data

1066
00:41:05,870 --> 00:41:08,300
solicited by the
other consumer,

1067
00:41:08,300 --> 00:41:10,100
it will be able to

1068
00:41:10,100 --> 00:41:12,260
increase data
reordering or round

1069
00:41:12,260 --> 00:41:14,240
trip time sample
jittering that

1070
00:41:14,240 --> 00:41:16,940
will hinge that its
in the middle stage.

1071
00:41:16,940 --> 00:41:20,060
Another way is to ask
forwarders for help.

1072
00:41:20,060 --> 00:41:21,380
If forwarders can provide

1073
00:41:21,380 --> 00:41:23,840
information about whether
queue has built up,

1074
00:41:23,840 --> 00:41:26,045
the consumer can also
understand that,

1075
00:41:26,045 --> 00:41:27,620
while it's round
trip delay

1076
00:41:27,620 --> 00:41:29,990
it observes is increasing,

1077
00:41:29,990 --> 00:41:32,030
it does not
necessarily mean

1078
00:41:32,030 --> 00:41:33,860
a congestion
and don't give

1079
00:41:33,860 --> 00:41:36,900
up bandwidth in
those cases.

1080
00:41:37,270 --> 00:41:40,895
As for the next
step of our work,

1081
00:41:40,895 --> 00:41:42,260
and we hope to explore

1082
00:41:42,260 --> 00:41:44,000
some non-cubic methods to

1083
00:41:44,000 --> 00:41:45,515
control interests sending,

1084
00:41:45,515 --> 00:41:47,690
and also continue
our study on

1085
00:41:47,690 --> 00:41:49,010
the algorithm behavior and

1086
00:41:49,010 --> 00:41:51,195
the caching and
multipath forwarding.

1087
00:41:51,195 --> 00:41:53,170
Lastly, we hope to explore

1088
00:41:53,170 --> 00:41:55,270
some potential
forwarder feedbacks

1089
00:41:55,270 --> 00:41:57,160
that benefits
performance or

1090
00:41:57,160 --> 00:41:57,955
the design of

1091
00:41:57,955 --> 00:42:00,330
the congestion
control algorithm.

1092
00:42:00,330 --> 00:42:03,575
That's all for
my talk today.

1093
00:42:03,575 --> 00:42:07,920
Thanks a lot and we'll
have any questions.

1094
00:42:08,380 --> 00:42:10,505
>> Thanks Sicheng, we're

1095
00:42:10,505 --> 00:42:11,570
running out of time.

1096
00:42:11,570 --> 00:42:12,830
There are a number
of questions on

1097
00:42:12,830 --> 00:42:15,990
this lecture and on
people are reacting.

1098
00:42:16,150 --> 00:42:19,655
One quick one, this
is end-to-end right?

1099
00:42:19,655 --> 00:42:22,714
The intermediate nodes
are not involved.

1100
00:42:22,714 --> 00:42:25,700
>> Yes, yes. That's
a great question.

1101
00:42:25,700 --> 00:42:30,275
So we hope to start
by end-to-end,

1102
00:42:30,275 --> 00:42:33,200
first because it's
simple and also,

1103
00:42:33,200 --> 00:42:36,770
we hope to have a good
understanding of what

1104
00:42:36,770 --> 00:42:38,630
are those things
end consumers can

1105
00:42:38,630 --> 00:42:40,700
do and what are the
things missing.

1106
00:42:40,700 --> 00:42:42,350
So later we could move to

1107
00:42:42,350 --> 00:42:45,380
a better design while
having more parties,

1108
00:42:45,380 --> 00:42:48,090
especially the
forwarders involved.

1109
00:42:50,030 --> 00:42:53,585
>> Please, go ahead
on the Slack channel,

1110
00:42:53,585 --> 00:42:55,270
answer a few
interesting questions

1111
00:42:55,270 --> 00:42:57,405
on measurement interval,

1112
00:42:57,405 --> 00:42:58,800
taking into account

1113
00:42:58,800 --> 00:43:01,500
the queue congestion
and so on.

1114
00:43:01,500 --> 00:43:03,005
For the sake
of time, we're

1115
00:43:03,005 --> 00:43:04,880
moving to the
next speaker.

1116
00:43:04,880 --> 00:43:06,465
Thank you again Sichen.

1117
00:43:06,465 --> 00:43:08,570
Next speaker is
Junxiao Shi.

1118
00:43:08,570 --> 00:43:10,355
He is a researcher
at NIST,

1119
00:43:10,355 --> 00:43:12,785
and he's a core
NDN developer,

1120
00:43:12,785 --> 00:43:14,130
and has been developing

1121
00:43:14,130 --> 00:43:17,400
NDN network forward
there since 2013.

1122
00:43:17,400 --> 00:43:18,885
He is going to
talk about The

1123
00:43:18,885 --> 00:43:21,030
NDN-DPDK file
server that he

1124
00:43:21,030 --> 00:43:22,700
developed in support of

1125
00:43:22,700 --> 00:43:25,010
this project. Go ahead.

1126
00:43:25,010 --> 00:43:25,920
>> As you said
it's Junxiao

1127
00:43:25,920 --> 00:43:26,820
and I'm talking about

1128
00:43:26,820 --> 00:43:28,775
NDN-DPDK File Server

1129
00:43:28,775 --> 00:43:31,750
for Data-Intensive
Science Applications.

1130
00:43:31,970 --> 00:43:34,440
NDN-DPDK started

1131
00:43:34,440 --> 00:43:36,420
as a high-speed
NDN forwarder,

1132
00:43:36,420 --> 00:43:38,820
and we achieved
100 gigabytes per

1133
00:43:38,820 --> 00:43:42,260
seconds in the ICN
Standard paper by

1134
00:43:42,260 --> 00:43:44,970
adopting vital
algorithm and reducing

1135
00:43:44,970 --> 00:43:46,440
overhead through the use

1136
00:43:46,440 --> 00:43:48,935
of the Data Plane
Development Kit.

1137
00:43:48,935 --> 00:43:51,570
Today's focus is
on the file server

1138
00:43:51,570 --> 00:43:53,795
we newly developed
this year.

1139
00:43:53,795 --> 00:43:55,085
The motivation of doing

1140
00:43:55,085 --> 00:43:57,445
this file service is
because we already have

1141
00:43:57,445 --> 00:43:59,290
a high-speed of
forwarder and it

1142
00:43:59,290 --> 00:44:01,530
goes well with
fast applications.

1143
00:44:01,530 --> 00:44:03,525
Data-intensive
science they use

1144
00:44:03,525 --> 00:44:06,410
them in big data or
mainly large files.

1145
00:44:06,410 --> 00:44:09,135
In the case of the
Large Hadron Collider,

1146
00:44:09,135 --> 00:44:13,715
it will operate a
Terabytes of data every

1147
00:44:13,715 --> 00:44:14,830
day and there is

1148
00:44:14,830 --> 00:44:15,850
already existing

1149
00:44:15,850 --> 00:44:18,220
IP-based
replication system,

1150
00:44:18,220 --> 00:44:19,775
and also IP-based client,

1151
00:44:19,775 --> 00:44:22,070
and so we cannot
change overnight.

1152
00:44:22,070 --> 00:44:23,785
A common way of doing

1153
00:44:23,785 --> 00:44:25,590
NDN file server is using

1154
00:44:25,590 --> 00:44:27,300
the repo such as

1155
00:44:27,300 --> 00:44:30,215
the NDN python repo
mentioned earlier today.

1156
00:44:30,215 --> 00:44:32,255
But the drawback
of the repo

1157
00:44:32,255 --> 00:44:35,010
is when we insert a
file to the repo,

1158
00:44:35,010 --> 00:44:36,970
it need to correct
the files into

1159
00:44:36,970 --> 00:44:39,020
data packets during
the insertion,

1160
00:44:39,020 --> 00:44:40,745
which double the
storage demand

1161
00:44:40,745 --> 00:44:42,740
and there are
Terabytes of data.

1162
00:44:42,740 --> 00:44:45,220
This is not feasible
in the case of index.

1163
00:44:45,220 --> 00:44:47,440
The NDN-DPDK file server

1164
00:44:47,440 --> 00:44:48,840
it works differently.

1165
00:44:48,840 --> 00:44:51,930
It can read from the
existing storage and

1166
00:44:51,930 --> 00:44:53,525
then create a
data package on

1167
00:44:53,525 --> 00:44:55,245
the fly weights
being requested,

1168
00:44:55,245 --> 00:44:57,860
so it does not
use more storage.

1169
00:44:57,860 --> 00:45:00,550
As a protocol, file
server has two steps,

1170
00:45:00,550 --> 00:45:03,125
the first step is to
retrieve the metadata.

1171
00:45:03,125 --> 00:45:07,765
The metadata contains
a version NDN prefix

1172
00:45:07,765 --> 00:45:09,360
to fetch this
particular version

1173
00:45:09,360 --> 00:45:10,045
of the file,

1174
00:45:10,045 --> 00:45:12,675
and it contains the file
size and timestamps.

1175
00:45:12,675 --> 00:45:14,270
It is extension of

1176
00:45:14,270 --> 00:45:16,860
the real time data
retrieval protocol.

1177
00:45:16,860 --> 00:45:18,930
The second step
is referred to as

1178
00:45:18,930 --> 00:45:21,215
a file content segment

1179
00:45:21,215 --> 00:45:23,170
by segment, currently,

1180
00:45:23,170 --> 00:45:24,495
it does not support

1181
00:45:24,495 --> 00:45:25,980
equation sign because it's

1182
00:45:25,980 --> 00:45:27,815
not needed in
the use case,

1183
00:45:27,815 --> 00:45:29,910
but we can possibly
add this if

1184
00:45:29,910 --> 00:45:32,090
we have hardware
crypto accelerator.

1185
00:45:32,090 --> 00:45:33,555
Of course, when
you factor this,

1186
00:45:33,555 --> 00:45:35,315
you can use a
condition control

1187
00:45:35,315 --> 00:45:37,310
mentioned in a
previous talk.

1188
00:45:37,310 --> 00:45:39,430
That is a way as
a file server,

1189
00:45:39,430 --> 00:45:41,250
access to the
underlying storage

1190
00:45:41,250 --> 00:45:43,520
is using the io_uring.

1191
00:45:43,520 --> 00:45:44,990
Io_uring is

1192
00:45:44,990 --> 00:45:47,670
a new asynchronous
I/O API for Linux.

1193
00:45:47,670 --> 00:45:50,170
It is available since
the Linux kernel

1194
00:45:50,170 --> 00:45:53,640
5.2 and is enhanced in
later kernel version.

1195
00:45:53,640 --> 00:45:56,030
The benefit of
io_uring is,

1196
00:45:56,030 --> 00:45:57,700
it request through
our system

1197
00:45:57,700 --> 00:46:00,185
costs [NOISE] and using
read or aio_read.

1198
00:46:00,185 --> 00:46:02,500
The way it works
is applications

1199
00:46:02,500 --> 00:46:04,950
such as NDN-DPDK
file server,

1200
00:46:04,950 --> 00:46:07,420
it prepare a reader
request which contains

1201
00:46:07,420 --> 00:46:09,910
that file descriptor,
a destination buffer,

1202
00:46:09,910 --> 00:46:11,945
and as a byte
offset that it's

1203
00:46:11,945 --> 00:46:13,620
submitted to the kernels

1204
00:46:13,620 --> 00:46:15,105
through a submission kill.

1205
00:46:15,105 --> 00:46:18,240
The submission does not
require system cost,

1206
00:46:18,240 --> 00:46:20,915
[NOISE] and the
kernel will process

1207
00:46:20,915 --> 00:46:23,045
this request and when it's

1208
00:46:23,045 --> 00:46:24,430
complete it comes back to

1209
00:46:24,430 --> 00:46:25,890
in another
completion kill,

1210
00:46:25,890 --> 00:46:26,890
which is a fellow process

1211
00:46:26,890 --> 00:46:27,790
were cooled a process

1212
00:46:27,790 --> 00:46:29,830
further such as sending
a data package.

1213
00:46:29,830 --> 00:46:33,140
[NOISE] With that,

1214
00:46:33,140 --> 00:46:34,845
this diagram is an

1215
00:46:34,845 --> 00:46:36,780
architectural of
a file server.

1216
00:46:36,780 --> 00:46:38,130
A file server connect to

1217
00:46:38,130 --> 00:46:40,330
a local NDN-DPDK forwarder

1218
00:46:40,330 --> 00:46:41,525
so I shared the Memory

1219
00:46:41,525 --> 00:46:43,085
Packet Interface,memif,

1220
00:46:43,085 --> 00:46:46,185
does the same work as
NDRC library does.

1221
00:46:46,185 --> 00:46:48,220
Then, the input test
read can perform

1222
00:46:48,220 --> 00:46:49,450
low dependency between

1223
00:46:49,450 --> 00:46:51,165
several producer threads.

1224
00:46:51,165 --> 00:46:53,145
Within our producer thread

1225
00:46:53,145 --> 00:46:54,570
incoming interests is

1226
00:46:54,570 --> 00:46:55,920
classified [NOISE] as is

1227
00:46:55,920 --> 00:46:58,455
a metadata interests
or segment interests.

1228
00:46:58,455 --> 00:47:00,650
For metadata interests,
it has had a fire

1229
00:47:00,650 --> 00:47:03,440
right away with
metadata, data packet.

1230
00:47:03,440 --> 00:47:05,230
For segment
interests it is

1231
00:47:05,230 --> 00:47:07,025
converted to a
reader request,

1232
00:47:07,025 --> 00:47:10,185
and then sent into
io_uring into the kernel.

1233
00:47:10,185 --> 00:47:13,110
When the io_ reader
requests complete,

1234
00:47:13,110 --> 00:47:15,360
it comes back to the
producer as red,

1235
00:47:15,360 --> 00:47:16,685
and then it becomes

1236
00:47:16,685 --> 00:47:18,035
a segment data which

1237
00:47:18,035 --> 00:47:19,860
is sent to the
output thread.

1238
00:47:19,860 --> 00:47:22,085
[NOISE] We use

1239
00:47:22,085 --> 00:47:24,980
this open file
descriptor table

1240
00:47:24,980 --> 00:47:26,475
in issue producers thread.

1241
00:47:26,475 --> 00:47:27,850
The purpose of this data

1242
00:47:27,850 --> 00:47:29,145
structure is to reuse

1243
00:47:29,145 --> 00:47:30,345
a file descriptor for

1244
00:47:30,345 --> 00:47:32,365
interests accessing
the same file.

1245
00:47:32,365 --> 00:47:34,590
It contains a
hash table of

1246
00:47:34,590 --> 00:47:37,055
file descriptors
indexed by a filename,

1247
00:47:37,055 --> 00:47:38,730
so that we don't need to

1248
00:47:38,730 --> 00:47:40,610
open the same file
multiple times.

1249
00:47:40,610 --> 00:47:42,425
When a file is
no longer being

1250
00:47:42,425 --> 00:47:44,310
used up by ongoing
reader request,

1251
00:47:44,310 --> 00:47:45,400
it will go into

1252
00:47:45,400 --> 00:47:47,520
the clean-up queue and
eventually closed.

1253
00:47:47,520 --> 00:47:51,120
[NOISE] We did some
preliminary benchmark

1254
00:47:51,120 --> 00:47:52,560
using two physical
machines.

1255
00:47:52,560 --> 00:47:53,845
We ran the forward and

1256
00:47:53,845 --> 00:47:56,010
a file server on the
physical machines.

1257
00:47:56,010 --> 00:47:58,290
The underlying
storage is MBME,

1258
00:47:58,290 --> 00:47:59,640
and that's over a 100

1259
00:47:59,640 --> 00:48:01,055
gigabits per second
of the linker,

1260
00:48:01,055 --> 00:48:02,265
the other machine runs

1261
00:48:02,265 --> 00:48:03,905
condition-aware fetcher,

1262
00:48:03,905 --> 00:48:05,314
which implements

1263
00:48:05,314 --> 00:48:08,045
CUBIC-like condition
control algorithm

1264
00:48:08,045 --> 00:48:09,660
that we tried to transfer

1265
00:48:09,660 --> 00:48:12,155
a single file
of 20 gigabits

1266
00:48:12,155 --> 00:48:16,085
over certain topology
within the issues.

1267
00:48:16,085 --> 00:48:18,740
We try this for different
segments sizes,

1268
00:48:18,740 --> 00:48:20,660
and a five trials each.

1269
00:48:20,660 --> 00:48:24,170
As we can see, if we use

1270
00:48:24,170 --> 00:48:25,690
a larger segment size that

1271
00:48:25,690 --> 00:48:27,620
we can get to
better good input,

1272
00:48:27,620 --> 00:48:29,425
for the larger
segment size

1273
00:48:29,425 --> 00:48:30,555
of eight kilobytes,

1274
00:48:30,555 --> 00:48:33,265
we get this good
input in this unit,

1275
00:48:33,265 --> 00:48:36,090
which is 1800
megabytes per second,

1276
00:48:36,090 --> 00:48:39,240
and this is roughly
60 percent of

1277
00:48:39,240 --> 00:48:40,710
the theoretical maximum

1278
00:48:40,710 --> 00:48:42,080
sequential reads speedup

1279
00:48:42,080 --> 00:48:44,380
of this particular
MVM device

1280
00:48:44,380 --> 00:48:46,305
on the file server side.

1281
00:48:46,305 --> 00:48:50,295
Of course, NDN-DPDK
also has a forwarder,

1282
00:48:50,295 --> 00:48:53,255
and we keep Improving
the forwarder.

1283
00:48:53,255 --> 00:48:56,055
Way important improvement
we did this year,

1284
00:48:56,055 --> 00:49:00,125
is to relieve the
input of bottleneck.

1285
00:49:00,125 --> 00:49:02,950
Because in our IC and
20th paper input as

1286
00:49:02,950 --> 00:49:04,665
thread was identified as

1287
00:49:04,665 --> 00:49:06,780
a bottleneck of
the forwarder.

1288
00:49:06,780 --> 00:49:09,275
Now we can use the
multiple input

1289
00:49:09,275 --> 00:49:10,920
as threads forwarder,

1290
00:49:10,920 --> 00:49:13,235
but this functionality is

1291
00:49:13,235 --> 00:49:14,590
subject to hideaway and

1292
00:49:14,590 --> 00:49:15,830
their travel limitations,

1293
00:49:15,830 --> 00:49:17,465
because it's a
current hideaway

1294
00:49:17,465 --> 00:49:19,265
they only understand IP.

1295
00:49:19,265 --> 00:49:21,670
This whole file, we
only got it working for

1296
00:49:21,670 --> 00:49:24,550
VXLAN transport on the
Mellanox ConnectX-5

1297
00:49:24,550 --> 00:49:26,675
, is an adapter.

1298
00:49:26,675 --> 00:49:28,460
The way it works is when

1299
00:49:28,460 --> 00:49:30,360
a packet comes
to the hardware,

1300
00:49:30,360 --> 00:49:31,935
we have a sequence of

1301
00:49:31,935 --> 00:49:34,820
received scaling
ISS rules.

1302
00:49:34,820 --> 00:49:36,740
Those rules, they
were mentioned

1303
00:49:36,740 --> 00:49:38,070
source IP address and

1304
00:49:38,070 --> 00:49:41,355
destination port to
be the VXLAN port.

1305
00:49:41,355 --> 00:49:42,450
Then, the hardware

1306
00:49:42,450 --> 00:49:43,835
while computing
the hash of

1307
00:49:43,835 --> 00:49:46,870
UDP 5-tuple,
since EBX lens,

1308
00:49:46,870 --> 00:49:48,110
a UDP source port,

1309
00:49:48,110 --> 00:49:49,740
is a random numbers,

1310
00:49:49,740 --> 00:49:51,560
this means, every packet

1311
00:49:51,560 --> 00:49:53,540
could have different
hash values.

1312
00:49:53,540 --> 00:49:56,475
We can say a Hardware
will pick up kills

1313
00:49:56,475 --> 00:49:57,780
based on the
hash value using

1314
00:49:57,780 --> 00:49:59,545
the last bit of
the hash value,

1315
00:49:59,545 --> 00:50:01,010
so if we have two kills,

1316
00:50:01,010 --> 00:50:05,415
it can't go can go to
both input as threads.

1317
00:50:05,415 --> 00:50:07,385
This effective reliefs

1318
00:50:07,385 --> 00:50:09,325
the input of bottleneck.

1319
00:50:09,325 --> 00:50:11,585
Of course, the
next talk is

1320
00:50:11,585 --> 00:50:14,055
about FPGA Acceleration,

1321
00:50:14,055 --> 00:50:16,210
would it replace all

1322
00:50:16,210 --> 00:50:19,720
these and a part of
the input thread.

1323
00:50:19,720 --> 00:50:22,050
To measure the effectives,

1324
00:50:22,050 --> 00:50:23,440
we need a benchmark,

1325
00:50:23,440 --> 00:50:25,190
and to simplify benchmark,

1326
00:50:25,190 --> 00:50:26,420
we created an

1327
00:50:26,420 --> 00:50:28,965
interactive benchmark
web application

1328
00:50:28,965 --> 00:50:32,585
that is part of an
NDN-DPDK codebase.

1329
00:50:32,585 --> 00:50:34,110
If you have a topology

1330
00:50:34,110 --> 00:50:35,800
like this and then
you can enter

1331
00:50:35,800 --> 00:50:37,630
some parameter and
the system will

1332
00:50:37,630 --> 00:50:38,980
automate it to a benchmark

1333
00:50:38,980 --> 00:50:40,775
for you and show
it as a results.

1334
00:50:40,775 --> 00:50:42,425
What you need
after two-way,

1335
00:50:42,425 --> 00:50:44,375
we did a benchmark of see

1336
00:50:44,375 --> 00:50:45,660
how effective we relieve

1337
00:50:45,660 --> 00:50:46,875
the input of bottleneck.

1338
00:50:46,875 --> 00:50:49,355
Orange part is
when we have

1339
00:50:49,355 --> 00:50:50,650
only one input thread and

1340
00:50:50,650 --> 00:50:52,565
blue part is two
input thread.

1341
00:50:52,565 --> 00:50:54,065
As a leak, I see If we

1342
00:50:54,065 --> 00:50:55,585
only have one
input thread,

1343
00:50:55,585 --> 00:50:57,570
it's a input thread
becomes a bottleneck,

1344
00:50:57,570 --> 00:50:59,875
and when we have
six, four threads,

1345
00:50:59,875 --> 00:51:04,425
and its speed is a 109
gigabits per second,

1346
00:51:04,425 --> 00:51:06,025
but when we have
two inputs thread,

1347
00:51:06,025 --> 00:51:08,150
we got to 134 gigabits

1348
00:51:08,150 --> 00:51:10,120
per second but
that's the speed.

1349
00:51:10,120 --> 00:51:12,510
If we have even more
forwarding thread

1350
00:51:12,510 --> 00:51:13,940
as a speeder
is going down,

1351
00:51:13,940 --> 00:51:15,100
[NOISE] so I
suppose there's

1352
00:51:15,100 --> 00:51:19,230
some memory and
bandwidth limitations,

1353
00:51:19,230 --> 00:51:22,340
and we all keep
digging at this area.

1354
00:51:22,340 --> 00:51:25,240
Apart from that,
we also tried to

1355
00:51:25,240 --> 00:51:27,900
reduce CPU
utilization when

1356
00:51:27,900 --> 00:51:29,955
forward is not a
processing traffic.

1357
00:51:29,955 --> 00:51:32,320
As measuring the
YaNFD paper,

1358
00:51:32,320 --> 00:51:35,880
NDN-DPDK is using a 100
percent CPU polling,

1359
00:51:35,880 --> 00:51:37,980
so polling is
fundamentally how

1360
00:51:37,980 --> 00:51:39,930
DPDK works, I
cannot change that,

1361
00:51:39,930 --> 00:51:41,145
but it doesn't have to

1362
00:51:41,145 --> 00:51:43,010
use a 100 percent CPU,

1363
00:51:43,010 --> 00:51:44,435
so we introduced

1364
00:51:44,435 --> 00:51:47,380
a new threadsleep
compile-time option.

1365
00:51:47,380 --> 00:51:50,255
If a thread process
0 packets in a pool,

1366
00:51:50,255 --> 00:51:52,230
it was sleep or for
one nanosecond,

1367
00:51:52,230 --> 00:51:54,329
and if I add
only continuous,

1368
00:51:54,329 --> 00:51:57,410
we gradually increases
sleep duration.

1369
00:51:57,410 --> 00:51:59,145
As we can see, if we have

1370
00:51:59,145 --> 00:52:02,220
a threadedsleep
option [inaudible].

1371
00:52:02,220 --> 00:52:03,660
Using set benchmark to

1372
00:52:03,660 --> 00:52:05,270
only reduce them slightly.

1373
00:52:05,270 --> 00:52:08,315
But when it's
not processing

1374
00:52:08,315 --> 00:52:11,430
any traffic
without sleeping,

1375
00:52:11,430 --> 00:52:13,420
it will use 14 CPU costs,

1376
00:52:13,420 --> 00:52:15,185
and when it's
sleeping it only use

1377
00:52:15,185 --> 00:52:18,015
half CPU cost when
added together.

1378
00:52:18,015 --> 00:52:20,960
The NDN-DPDK codebase is

1379
00:52:20,960 --> 00:52:22,175
open source on github,

1380
00:52:22,175 --> 00:52:23,525
and this year
as you can see

1381
00:52:23,525 --> 00:52:24,900
what I did to
the file server,

1382
00:52:24,900 --> 00:52:26,749
as the interactive
benchmark,

1383
00:52:26,749 --> 00:52:27,900
and also improve

1384
00:52:27,900 --> 00:52:29,970
the user
documentation so you

1385
00:52:29,970 --> 00:52:31,860
can follow that
documentation

1386
00:52:31,860 --> 00:52:34,125
that it installed
that data started.

1387
00:52:34,125 --> 00:52:37,140
We also expanded the
platform support

1388
00:52:37,140 --> 00:52:39,920
always supported
the DB11 PVM.

1389
00:52:39,920 --> 00:52:43,420
We now allow using IP
and the idea are the

1390
00:52:43,420 --> 00:52:47,290
same as an adaptor
usings the AFXDP driver.

1391
00:52:47,290 --> 00:52:50,220
We also supported PLUDP

1392
00:52:50,220 --> 00:52:52,230
and a VX Nintendo
transport.

1393
00:52:52,230 --> 00:52:55,660
We also added a support
for container net and

1394
00:52:55,660 --> 00:52:59,130
a file for file
experimental platforms.

1395
00:52:59,130 --> 00:53:01,480
[NOISE] Thank you.

1396
00:53:03,680 --> 00:53:06,325
>> Thank you, Junxiao,

1397
00:53:06,325 --> 00:53:08,190
we are only five minutes

1398
00:53:08,190 --> 00:53:09,250
left in this session,

1399
00:53:09,250 --> 00:53:11,470
so we're not taking
questions we'll move to

1400
00:53:11,470 --> 00:53:16,250
the next talk
by Michael Lo.

1401
00:53:16,250 --> 00:53:18,375
Michael, we'll give you

1402
00:53:18,375 --> 00:53:19,890
ten minutes
will be to wait

1403
00:53:19,890 --> 00:53:23,570
five minutes from the
next session, I guess.

1404
00:53:23,570 --> 00:53:26,435
You can go ahead and
start sharing screen.

1405
00:53:26,435 --> 00:53:27,750
>> Can you see the screen?

1406
00:53:27,750 --> 00:53:30,710
>> Michael? Sorry.

1407
00:53:30,710 --> 00:53:31,720
>> Sorry, you [inaudible]
[OVERLAPPING].

1408
00:53:31,720 --> 00:53:33,875
>> Go ahead and
start sharing,

1409
00:53:33,875 --> 00:53:35,405
while I introduce you.

1410
00:53:35,405 --> 00:53:37,590
Michael Lo, is

1411
00:53:37,590 --> 00:53:39,990
a graduate student
at UCLA working

1412
00:53:39,990 --> 00:53:42,790
with Professor
Jason Cong In

1413
00:53:42,790 --> 00:53:46,235
the center for domain
specific computing.

1414
00:53:46,235 --> 00:53:47,160
He's going to talk

1415
00:53:47,160 --> 00:53:48,755
about the FPGA
acceleration

1416
00:53:48,755 --> 00:53:50,375
for the NDN forward

1417
00:53:50,375 --> 00:53:52,355
or the Junxiao Chan
just talked about.

1418
00:53:52,355 --> 00:53:54,410
Go ahead Michael.

1419
00:53:54,410 --> 00:53:56,535
>> Can you see the screen?

1420
00:53:56,535 --> 00:53:58,550
>> Not yet.

1421
00:54:01,130 --> 00:54:03,825
>> I could see it.

1422
00:54:03,825 --> 00:54:07,130
>> Yeah. How about now?

1423
00:54:07,680 --> 00:54:10,370
>> I can see it.

1424
00:54:13,590 --> 00:54:17,020
>> I'll be talking
about our progress on

1425
00:54:17,020 --> 00:54:18,940
the FPGA-based
acceleration

1426
00:54:18,940 --> 00:54:21,085
for the forwarding
pipeline.

1427
00:54:21,085 --> 00:54:23,185
As a quick
background, we all

1428
00:54:23,185 --> 00:54:25,690
know how NDN work.

1429
00:54:25,690 --> 00:54:28,195
If a node is looking
for a specific data,

1430
00:54:28,195 --> 00:54:30,145
it doesn't have to
go to the producer

1431
00:54:30,145 --> 00:54:32,905
to retrieve that data

1432
00:54:32,905 --> 00:54:34,510
if its next near
node already

1433
00:54:34,510 --> 00:54:37,585
has it compared to
IP-based where you have to

1434
00:54:37,585 --> 00:54:39,430
forward your request to

1435
00:54:39,430 --> 00:54:41,215
the destination specified.

1436
00:54:41,215 --> 00:54:43,435
With NDN you don't
have to do that.

1437
00:54:43,435 --> 00:54:45,745
Here's a quick breakdown

1438
00:54:45,745 --> 00:54:47,830
of the forwarding
pipeline.

1439
00:54:47,830 --> 00:54:49,420
Let's say if we're
looking for a request

1440
00:54:49,420 --> 00:54:51,100
for /a/b,

1441
00:54:51,100 --> 00:54:55,690
and if it's in next
neighbors node,

1442
00:54:55,690 --> 00:54:56,740
then you can
simply just grab

1443
00:54:56,740 --> 00:54:58,495
the data that's in
the back cover.

1444
00:54:58,495 --> 00:55:00,280
If that data
doesn't exist,

1445
00:55:00,280 --> 00:55:01,000
you have to go through

1446
00:55:01,000 --> 00:55:02,335
the entire
forwarding logic.

1447
00:55:02,335 --> 00:55:03,790
You have to insert into

1448
00:55:03,790 --> 00:55:05,215
a pending interest table

1449
00:55:05,215 --> 00:55:06,550
and then you have to go

1450
00:55:06,550 --> 00:55:07,975
through the routing
table and figure out

1451
00:55:07,975 --> 00:55:12,410
what's the next node
it's sending to.

1452
00:55:12,690 --> 00:55:15,310
One problem with

1453
00:55:15,310 --> 00:55:19,900
the NDN architecture
is that we

1454
00:55:19,900 --> 00:55:20,800
notice that it uses

1455
00:55:20,800 --> 00:55:22,150
hierarchical names instead

1456
00:55:22,150 --> 00:55:26,860
of fixed 32 or even
128 bit address.

1457
00:55:26,860 --> 00:55:29,860
That's the one that is
also a benefit of NDN.

1458
00:55:29,860 --> 00:55:32,005
You can have variable
name lengths

1459
00:55:32,005 --> 00:55:34,910
to represent your data,
they're not fixed.

1460
00:55:34,920 --> 00:55:39,160
This is great for
the upstream user.

1461
00:55:39,160 --> 00:55:40,390
They can specify
whatever they want.

1462
00:55:40,390 --> 00:55:42,565
However, we need
to process it,

1463
00:55:42,565 --> 00:55:44,410
we need some way to

1464
00:55:44,410 --> 00:55:46,300
transform it
into a unique or

1465
00:55:46,300 --> 00:55:47,965
a fixed length
identifier so

1466
00:55:47,965 --> 00:55:51,110
that the processing
is much more easier.

1467
00:55:51,180 --> 00:55:53,800
There are two criteria
that have to be met.

1468
00:55:53,800 --> 00:55:55,450
Each prefix needs to have

1469
00:55:55,450 --> 00:55:57,940
a unique hash or
a unique name.

1470
00:55:57,940 --> 00:55:59,590
If we want to
represent it as

1471
00:55:59,590 --> 00:56:01,210
a fixed number of bits,

1472
00:56:01,210 --> 00:56:03,310
then we use some
hashing algorithm.

1473
00:56:03,310 --> 00:56:06,250
In this case,
it's a SIP hash.

1474
00:56:06,250 --> 00:56:08,440
The SIP hash
algorithm used by

1475
00:56:08,440 --> 00:56:10,690
NDN is slightly
different than

1476
00:56:10,690 --> 00:56:15,040
the general SIP hash used.

1477
00:56:15,040 --> 00:56:17,185
The main difference for

1478
00:56:17,185 --> 00:56:18,670
the SIP hash used
in the NDN is

1479
00:56:18,670 --> 00:56:19,960
that every end of prefix,

1480
00:56:19,960 --> 00:56:21,070
you have to go through

1481
00:56:21,070 --> 00:56:23,550
additional six rounds of

1482
00:56:23,550 --> 00:56:25,680
these XOR and additional

1483
00:56:25,680 --> 00:56:27,240
ADD and ROTATE operations

1484
00:56:27,240 --> 00:56:29,665
to produce the
64 bit hash.

1485
00:56:29,665 --> 00:56:31,525
I'll just go over
a quick example.

1486
00:56:31,525 --> 00:56:33,010
Let's say for
example, we have

1487
00:56:33,010 --> 00:56:38,800
this
/aaaaa/bbbbb/ccccc/ddddd.

1488
00:56:38,800 --> 00:56:41,665
First we traverse
the string.

1489
00:56:41,665 --> 00:56:44,395
We see that slash
a is one prefix.

1490
00:56:44,395 --> 00:56:47,680
We have to do with six
rounds of computation.

1491
00:56:47,680 --> 00:56:48,580
The total number of

1492
00:56:48,580 --> 00:56:49,600
rounds we have
done so far is

1493
00:56:49,600 --> 00:56:51,535
six and we've
produced one hash.

1494
00:56:51,535 --> 00:56:53,440
Now as we traverse
even more,

1495
00:56:53,440 --> 00:56:55,000
we finally hit
eight bytes.

1496
00:56:55,000 --> 00:56:57,640
We have to do a two
round computation.

1497
00:56:57,640 --> 00:56:59,290
We have done
eight rounds so

1498
00:56:59,290 --> 00:57:01,465
far and we still only
produced one hash.

1499
00:57:01,465 --> 00:57:02,785
As you can see, as we

1500
00:57:02,785 --> 00:57:04,675
traverse through
the entire string,

1501
00:57:04,675 --> 00:57:07,780
we need to do 30 rounds
of computation just

1502
00:57:07,780 --> 00:57:11,875
for a name of
25 characters.

1503
00:57:11,875 --> 00:57:14,515
As you can see,
this can get

1504
00:57:14,515 --> 00:57:16,870
computationally more
complex depending

1505
00:57:16,870 --> 00:57:18,070
on your input name,

1506
00:57:18,070 --> 00:57:20,155
especially if you
have a lot of

1507
00:57:20,155 --> 00:57:24,260
prefixes in your name
and they're short.

1508
00:57:24,480 --> 00:57:26,950
Just to summarize,
we've done 30 rounds

1509
00:57:26,950 --> 00:57:28,060
of computation for

1510
00:57:28,060 --> 00:57:30,010
a 25-character
input and we

1511
00:57:30,010 --> 00:57:33,340
only produced four hashes.

1512
00:57:33,340 --> 00:57:35,830
The next step is to

1513
00:57:35,830 --> 00:57:37,840
look up in the
dispatch table

1514
00:57:37,840 --> 00:57:39,940
where your dispatch to

1515
00:57:39,940 --> 00:57:42,160
the thread now
handle this input.

1516
00:57:42,160 --> 00:57:47,200
A lot of downside of
using a dispatch table

1517
00:57:47,200 --> 00:57:49,570
is you need to try

1518
00:57:49,570 --> 00:57:51,160
to figure out how

1519
00:57:51,160 --> 00:57:52,510
big your table
size should be,

1520
00:57:52,510 --> 00:57:55,975
otherwise you're
running to issues.

1521
00:57:55,975 --> 00:57:58,540
This is why you

1522
00:57:58,540 --> 00:58:00,115
need a specified
prefix depth.

1523
00:58:00,115 --> 00:58:01,450
Then depending on
your table size,

1524
00:58:01,450 --> 00:58:02,890
you use the last n-bits of

1525
00:58:02,890 --> 00:58:05,810
the hash to index
into that table.

1526
00:58:07,020 --> 00:58:09,400
As stated, this can lead

1527
00:58:09,400 --> 00:58:12,370
to some issues with
bouncing your tables.

1528
00:58:12,370 --> 00:58:13,570
One problem is if you have

1529
00:58:13,570 --> 00:58:14,725
too large of a table,

1530
00:58:14,725 --> 00:58:16,240
then you have really poor

1531
00:58:16,240 --> 00:58:18,460
locality during lookup

1532
00:58:18,460 --> 00:58:21,250
because one hash may be

1533
00:58:21,250 --> 00:58:22,750
in cache and then
the next hash

1534
00:58:22,750 --> 00:58:24,040
that comes in may
not be in cache.

1535
00:58:24,040 --> 00:58:25,360
You got to evict

1536
00:58:25,360 --> 00:58:27,580
the entries and
bringing it in.

1537
00:58:27,580 --> 00:58:30,220
Then maybe another
hash comes in and

1538
00:58:30,220 --> 00:58:33,310
you fix the previous
entry, so on like that.

1539
00:58:33,310 --> 00:58:35,905
However, if you have
a smaller table,

1540
00:58:35,905 --> 00:58:38,815
it can lead to imbalance
thread workload.

1541
00:58:38,815 --> 00:58:40,690
As an example here,

1542
00:58:40,690 --> 00:58:42,790
let's say we're using
the last 16 bits

1543
00:58:42,790 --> 00:58:45,205
to index the
dispatch table.

1544
00:58:45,205 --> 00:58:47,275
The last 16 bits
are all the same,

1545
00:58:47,275 --> 00:58:52,585
but the other 48 bits
are not the same.

1546
00:58:52,585 --> 00:58:55,240
But in this case, all
these four hashes

1547
00:58:55,240 --> 00:58:57,100
will be dispatched
to one thread.

1548
00:58:57,100 --> 00:58:58,825
As you can see, if you

1549
00:58:58,825 --> 00:59:00,760
use the last bits
in this case,

1550
00:59:00,760 --> 00:59:02,740
it will be sensing two
different threads.

1551
00:59:02,740 --> 00:59:04,090
If you use the last 18,

1552
00:59:04,090 --> 00:59:05,800
it would be sensing
four different threads.

1553
00:59:05,800 --> 00:59:08,335
But like I said,

1554
00:59:08,335 --> 00:59:09,340
as you use more bits,

1555
00:59:09,340 --> 00:59:12,290
your table size
will increase.

1556
00:59:13,380 --> 00:59:16,735
For our design
exploration on the FPGA,

1557
00:59:16,735 --> 00:59:18,955
our goal is to
try to identify

1558
00:59:18,955 --> 00:59:20,590
any overlaps
in computation

1559
00:59:20,590 --> 00:59:22,220
as much as possible.

1560
00:59:22,220 --> 00:59:24,090
For the SIP
hash algorithm,

1561
00:59:24,090 --> 00:59:26,280
there are some
computational overlaps.

1562
00:59:26,280 --> 00:59:30,150
Then for the
dispatch level,

1563
00:59:30,150 --> 00:59:31,470
we can actually
do it while

1564
00:59:31,470 --> 00:59:34,445
the hashing is still
being computed.

1565
00:59:34,445 --> 00:59:36,940
But it really
depends on the depth

1566
00:59:36,940 --> 00:59:38,650
specified to see if

1567
00:59:38,650 --> 00:59:41,020
we can actually hide
these overlaps.

1568
00:59:41,020 --> 00:59:43,270
One advantage
for that FPGA

1569
00:59:43,270 --> 00:59:45,010
over the CPU in
this case is that

1570
00:59:45,010 --> 00:59:47,530
because these
compositional overlaps

1571
00:59:47,530 --> 00:59:49,855
or these parallel lookups,

1572
00:59:49,855 --> 00:59:51,790
they are relatively fast

1573
00:59:51,790 --> 00:59:53,485
task and they're short.

1574
00:59:53,485 --> 00:59:55,270
It's not really worth it

1575
00:59:55,270 --> 00:59:57,925
to spawn a CPU thread
just to do it.

1576
00:59:57,925 --> 00:59:59,920
Essentially you're
just incurring

1577
00:59:59,920 --> 01:00:01,930
the CPU spawning
thread overhead.

1578
01:00:01,930 --> 01:00:03,520
But with the FPGA design,

1579
01:00:03,520 --> 01:00:04,870
you don't have
this issue at all,

1580
01:00:04,870 --> 01:00:06,025
you simply have this

1581
01:00:06,025 --> 01:00:08,390
RE baked into your design.

1582
01:00:08,730 --> 01:00:12,685
Where's the SIP hash
computation overlap?

1583
01:00:12,685 --> 01:00:14,875
In the NDN.

1584
01:00:14,875 --> 01:00:16,960
Every time you need
an end of prefix,

1585
01:00:16,960 --> 01:00:19,375
you have to do a final
six round computation,

1586
01:00:19,375 --> 01:00:20,785
and this actually doesn't

1587
01:00:20,785 --> 01:00:22,705
affect the next
prefix at all.

1588
01:00:22,705 --> 01:00:24,580
For example, in this case,

1589
01:00:24,580 --> 01:00:25,900
I'm computing the prefix

1590
01:00:25,900 --> 01:00:28,795
of /aa in onetime step.

1591
01:00:28,795 --> 01:00:31,240
I need to compute

1592
01:00:31,240 --> 01:00:35,665
the final six rounds
and a prefix of /aa.

1593
01:00:35,665 --> 01:00:37,750
But at the same time,
I can also start

1594
01:00:37,750 --> 01:00:40,690
computing the
prefix of /bbbb.

1595
01:00:40,690 --> 01:00:43,255
We already have
some competition

1596
01:00:43,255 --> 01:00:47,270
over last one,
bring these hashes.

1597
01:00:47,610 --> 01:00:51,520
Another thing is during
lookup is that let's

1598
01:00:51,520 --> 01:00:54,805
say we specified
at depth equal 2,

1599
01:00:54,805 --> 01:00:57,670
we actually just
need the hash at

1600
01:00:57,670 --> 01:00:59,590
/bbbb to be sent to

1601
01:00:59,590 --> 01:01:01,000
the lookup table
while the rest of

1602
01:01:01,000 --> 01:01:02,800
the hashes are still
being computed.

1603
01:01:02,800 --> 01:01:05,995
However, there isn't
really much benefit if,

1604
01:01:05,995 --> 01:01:07,630
for example, let's
say your depth is

1605
01:01:07,630 --> 01:01:08,740
specified greater than

1606
01:01:08,740 --> 01:01:10,240
the number of
prefixes on the name.

1607
01:01:10,240 --> 01:01:11,290
For example, let's say

1608
01:01:11,290 --> 01:01:12,670
my depth is equal to 5,

1609
01:01:12,670 --> 01:01:15,640
then we won't really
see any benefits of

1610
01:01:15,640 --> 01:01:17,560
these lookup
overlapping parallel

1611
01:01:17,560 --> 01:01:18,730
hash reputation because I

1612
01:01:18,730 --> 01:01:22,000
have to wait until the
end of the name is

1613
01:01:22,000 --> 01:01:23,260
computed before
I can send it

1614
01:01:23,260 --> 01:01:26,510
to the naming
dispatch table.

1615
01:01:26,880 --> 01:01:28,960
Also in our design,

1616
01:01:28,960 --> 01:01:31,825
we implemented
a custom cache.

1617
01:01:31,825 --> 01:01:34,675
Instead of evicting,
let's say,

1618
01:01:34,675 --> 01:01:38,020
a 64-bit line like in CPU,

1619
01:01:38,020 --> 01:01:39,550
we actually just store

1620
01:01:39,550 --> 01:01:44,210
the index of those
recently hit.

1621
01:01:44,610 --> 01:01:47,590
Here's the overall
architectural design

1622
01:01:47,590 --> 01:01:50,185
on the FPGA is
very simple.

1623
01:01:50,185 --> 01:01:53,050
We have two kernels.

1624
01:01:53,050 --> 01:01:55,150
One that specifically
does the hashing,

1625
01:01:55,150 --> 01:01:55,630
another one that

1626
01:01:55,630 --> 01:01:57,100
specifically
does the lookup.

1627
01:01:57,100 --> 01:01:59,200
Essentially the
CPU is sending

1628
01:01:59,200 --> 01:02:02,020
named input to the
hashing kernel first.

1629
01:02:02,020 --> 01:02:03,550
Inside our
hashing kernels,

1630
01:02:03,550 --> 01:02:05,050
we can handle up to date

1631
01:02:05,050 --> 01:02:07,525
named strings in parallel.

1632
01:02:07,525 --> 01:02:09,640
The lookup kernel,
they only handle

1633
01:02:09,640 --> 01:02:11,560
one input lookup at a time

1634
01:02:11,560 --> 01:02:15,910
where it uses a
multiplexer to go in

1635
01:02:15,910 --> 01:02:17,560
a round robin fashion

1636
01:02:17,560 --> 01:02:20,830
to look up requests

1637
01:02:20,830 --> 01:02:22,330
from each
processing element

1638
01:02:22,330 --> 01:02:24,490
from the cache-in kernel.

1639
01:02:24,490 --> 01:02:28,885
Here's our testing
results or methodology.

1640
01:02:28,885 --> 01:02:31,675
It's a standalone
comparison.

1641
01:02:31,675 --> 01:02:34,405
We've only compared the
hashing computation

1642
01:02:34,405 --> 01:02:36,670
against our CPU
and a lookup

1643
01:02:36,670 --> 01:02:39,370
done on the CPU
is not done

1644
01:02:39,370 --> 01:02:40,690
in an end-to-end where we

1645
01:02:40,690 --> 01:02:41,980
integrate it into
a forwarder.

1646
01:02:41,980 --> 01:02:43,945
We haven't done
that step yet,

1647
01:02:43,945 --> 01:02:46,360
but we'll try to do
that in the future.

1648
01:02:46,360 --> 01:02:48,280
Here's our CPU that

1649
01:02:48,280 --> 01:02:49,930
we use it to
compare against.

1650
01:02:49,930 --> 01:02:53,110
As you can see, it
has quite a small L1,

1651
01:02:53,110 --> 01:02:56,150
but relatively large
L2 and L3 cache.

1652
01:02:56,630 --> 01:02:59,370
>> Yeah. Here,

1653
01:02:59,370 --> 01:03:01,290
we compare against
one thread

1654
01:03:01,290 --> 01:03:03,615
versus one
processing element.

1655
01:03:03,615 --> 01:03:04,980
On the horizontal axis,

1656
01:03:04,980 --> 01:03:07,080
it's the number of

1657
01:03:07,080 --> 01:03:08,460
bits used in the
lookup table,

1658
01:03:08,460 --> 01:03:10,350
and then on the
vertical axis is

1659
01:03:10,350 --> 01:03:12,930
the depth specify
for lookup,

1660
01:03:12,930 --> 01:03:14,190
and in the blue is

1661
01:03:14,190 --> 01:03:15,450
the time it takes for CPU,

1662
01:03:15,450 --> 01:03:17,430
and the gold is
the time for FPGA.

1663
01:03:17,430 --> 01:03:18,870
As you can see,
as you go along

1664
01:03:18,870 --> 01:03:21,540
the vertical axis,

1665
01:03:21,540 --> 01:03:24,210
the CPUs, you can
start to see that

1666
01:03:24,210 --> 01:03:25,260
the caching on the

1667
01:03:25,260 --> 01:03:26,655
CPU really starts
to be effective.

1668
01:03:26,655 --> 01:03:30,195
Going from from depth
of two to depth of 32,

1669
01:03:30,195 --> 01:03:31,440
you're really just having

1670
01:03:31,440 --> 01:03:33,000
just cache
thrashing around.

1671
01:03:33,000 --> 01:03:34,080
As for FPGA, we

1672
01:03:34,080 --> 01:03:35,100
don't really see
that problem at

1673
01:03:35,100 --> 01:03:37,695
all because they
are hidden away.

1674
01:03:37,695 --> 01:03:40,050
Yeah, and then we
do a comparison

1675
01:03:40,050 --> 01:03:42,030
of up to eight
processing elements.

1676
01:03:42,030 --> 01:03:44,760
One thing we
noticed that is for

1677
01:03:44,760 --> 01:03:47,550
the fourth
processing elements

1678
01:03:47,550 --> 01:03:48,315
on the FPGA and

1679
01:03:48,315 --> 01:03:49,770
a processing
element on FPGA,

1680
01:03:49,770 --> 01:03:52,230
we don't see any
further improvements.

1681
01:03:52,230 --> 01:03:52,920
We believe this is

1682
01:03:52,920 --> 01:03:54,030
some communication
overhead

1683
01:03:54,030 --> 01:03:56,380
between the CPU and FPGA.

1684
01:03:57,440 --> 01:04:00,150
As a part of future work,

1685
01:04:00,150 --> 01:04:02,160
one thing I didn't
really mentioned

1686
01:04:02,160 --> 01:04:03,980
is that the FPGA

1687
01:04:03,980 --> 01:04:05,375
actually requires

1688
01:04:05,375 --> 01:04:08,090
batching of your
name inputs.

1689
01:04:08,090 --> 01:04:10,100
So essentially,
we can't do

1690
01:04:10,100 --> 01:04:13,485
any real time
computation right now.

1691
01:04:13,485 --> 01:04:15,135
Let's say if you have

1692
01:04:15,135 --> 01:04:17,715
packet arriving
every microsecond,

1693
01:04:17,715 --> 01:04:19,545
the FPGA expects that you

1694
01:04:19,545 --> 01:04:22,620
batch up to like
for example,

1695
01:04:22,620 --> 01:04:23,910
in our design
of [inaudible]

1696
01:04:23,910 --> 01:04:25,470
at least 32 packets at

1697
01:04:25,470 --> 01:04:26,580
a time before it can

1698
01:04:26,580 --> 01:04:28,380
process it and
like I said again,

1699
01:04:28,380 --> 01:04:29,250
this is to reduce

1700
01:04:29,250 --> 01:04:30,420
communication
overhead between

1701
01:04:30,420 --> 01:04:32,940
CPU and FPGA
and of course,

1702
01:04:32,940 --> 01:04:34,590
this will be feasible
in online environment

1703
01:04:34,590 --> 01:04:36,345
as your latency will
be really high.

1704
01:04:36,345 --> 01:04:37,740
As part of our
future work, we're

1705
01:04:37,740 --> 01:04:39,690
looking to instead of

1706
01:04:39,690 --> 01:04:41,310
having extra data copy

1707
01:04:41,310 --> 01:04:42,960
being moved around
from CPU to FPGA,

1708
01:04:42,960 --> 01:04:45,975
we're looking into
just allocating

1709
01:04:45,975 --> 01:04:48,000
a physical memory space on

1710
01:04:48,000 --> 01:04:49,200
the CPU side
where the FPGA

1711
01:04:49,200 --> 01:04:51,370
can directly access it.

1712
01:04:53,930 --> 01:04:55,980
We also hope to support

1713
01:04:55,980 --> 01:04:57,420
Longest Prefix Matching.

1714
01:04:57,420 --> 01:04:59,640
Previous papers
have been exploring

1715
01:04:59,640 --> 01:05:01,110
longest prefix
matching and how to

1716
01:05:01,110 --> 01:05:03,105
reduce the number of
lookups required.

1717
01:05:03,105 --> 01:05:05,670
We hope to incorporate

1718
01:05:05,670 --> 01:05:08,925
those designs into the
FPGA design and also,

1719
01:05:08,925 --> 01:05:11,610
it is possible for NDN
interest packets to

1720
01:05:11,610 --> 01:05:15,855
be using tokens instead
of named inputs.

1721
01:05:15,855 --> 01:05:20,130
This is for receiving
data packets that

1722
01:05:20,130 --> 01:05:21,810
are requested and
we hope to also

1723
01:05:21,810 --> 01:05:24,360
support token based
inputs and then finally,

1724
01:05:24,360 --> 01:05:26,790
we hope to integrate
all our work into

1725
01:05:26,790 --> 01:05:30,150
the NDN DPDK repository.

1726
01:05:30,150 --> 01:05:32,925
>> All right. Thank
you very much.

1727
01:05:32,925 --> 01:05:35,295
There's some
discussion on Slack.

1728
01:05:35,295 --> 01:05:36,615
You can take a look

1729
01:05:36,615 --> 01:05:39,930
and we move to
the next session,

1730
01:05:39,930 --> 01:05:42,870
which is named
Tactical and Wireless,

1731
01:05:42,870 --> 01:05:45,840
and it's shared
by Tamer Rafael.

1732
01:05:45,840 --> 01:05:47,250
Tamer received his PhD

1733
01:05:47,250 --> 01:05:48,300
in Computer Engineering

1734
01:05:48,300 --> 01:05:51,029
from Virginia
Polytechnic Institute

1735
01:05:51,029 --> 01:05:52,425
and he's currently a

1736
01:05:52,425 --> 01:05:54,870
Principal Information
Security Scientist

1737
01:05:54,870 --> 01:05:56,865
at Mitre Corporation.

1738
01:05:56,865 --> 01:06:00,180
Tamer, go ahead please.

1739
01:06:00,180 --> 01:06:02,445
>> Can you all hear me?

1740
01:06:02,445 --> 01:06:03,645
>> Yes.

1741
01:06:03,645 --> 01:06:07,110
>> Okay, great. Thank
you. This session,

1742
01:06:07,110 --> 01:06:09,120
we have three talks.

1743
01:06:09,120 --> 01:06:12,435
The first talk is going
to be from DARPA.

1744
01:06:12,435 --> 01:06:13,920
DARPA Secure Handhelds on

1745
01:06:13,920 --> 01:06:15,570
Assured Resilient
Networks at

1746
01:06:15,570 --> 01:06:17,640
the Tactical Edge SHARE.

1747
01:06:17,640 --> 01:06:19,320
The talk is going
to be given

1748
01:06:19,320 --> 01:06:20,910
by Dr. Mary Schurgot.

1749
01:06:20,910 --> 01:06:22,290
Dr. Mary Schurgot joined

1750
01:06:22,290 --> 01:06:24,120
DARPA in March 2020 as

1751
01:06:24,120 --> 01:06:25,560
a Program Manager in

1752
01:06:25,560 --> 01:06:27,405
Strategic
Technology Office.

1753
01:06:27,405 --> 01:06:28,890
Her research
interest includes

1754
01:06:28,890 --> 01:06:30,330
secure and efficient
data sharing,

1755
01:06:30,330 --> 01:06:32,340
automated decision
aids, and

1756
01:06:32,340 --> 01:06:33,405
the design of
new networking

1757
01:06:33,405 --> 01:06:34,694
innovation paradigms.

1758
01:06:34,694 --> 01:06:36,450
Before DARPA, Dr.
Mary Schurgot was

1759
01:06:36,450 --> 01:06:37,320
the Practical Director

1760
01:06:37,320 --> 01:06:38,310
of Machine Learning and

1761
01:06:38,310 --> 01:06:40,230
Edge capability that CACI

1762
01:06:40,230 --> 01:06:42,585
previously LGS
Innovations,

1763
01:06:42,585 --> 01:06:43,800
where she
developed and led

1764
01:06:43,800 --> 01:06:45,030
programs at the
intersection

1765
01:06:45,030 --> 01:06:47,565
of analytics, cyber,
and networking.

1766
01:06:47,565 --> 01:06:49,905
Dr. Schurgot, the
floor is yours.

1767
01:06:49,905 --> 01:06:52,110
>> Thanks, Tamer.
Can you hear me

1768
01:06:52,110 --> 01:06:54,735
and see my screen
and see me?

1769
01:06:54,735 --> 01:06:56,820
>> Yes, ma'am.

1770
01:06:56,820 --> 01:07:00,210
>> Thanks, Tamer.
[LAUGHTER] Hi, everyone.

1771
01:07:00,210 --> 01:07:02,130
I'm very excited
to be here again.

1772
01:07:02,130 --> 01:07:03,900
Thank you for
the invitation.

1773
01:07:03,900 --> 01:07:07,320
I'll try to get you
some of your time back.

1774
01:07:07,320 --> 01:07:09,060
You might be familiar with

1775
01:07:09,060 --> 01:07:10,935
the SHARE program
and then I'll

1776
01:07:10,935 --> 01:07:12,750
talk about where we
are with that and

1777
01:07:12,750 --> 01:07:14,549
then talk about
them MINC program,

1778
01:07:14,549 --> 01:07:16,840
which is my new program.

1779
01:07:17,720 --> 01:07:19,860
Again, I'm going quickly

1780
01:07:19,860 --> 01:07:20,970
through this
because I know this

1781
01:07:20,970 --> 01:07:24,135
is a review for
a lot of you.

1782
01:07:24,135 --> 01:07:28,140
The SHARE program started
in 2016 timeframe,

1783
01:07:28,140 --> 01:07:29,760
and the goal there
was really to

1784
01:07:29,760 --> 01:07:32,490
enable practical
data sharing at

1785
01:07:32,490 --> 01:07:35,220
multiple security
levels with a goal of

1786
01:07:35,220 --> 01:07:36,450
enabling sharing between

1787
01:07:36,450 --> 01:07:39,330
US forces and
coalition partners.

1788
01:07:39,330 --> 01:07:41,370
In contrast to
how things are

1789
01:07:41,370 --> 01:07:43,230
done today at the
Tactical Edge,

1790
01:07:43,230 --> 01:07:45,495
SHARE was trying to bring

1791
01:07:45,495 --> 01:07:48,000
Secure Enclave
Technology and

1792
01:07:48,000 --> 01:07:49,470
MINC data networking to

1793
01:07:49,470 --> 01:07:52,050
the secure handheld
or to a mobile phone.

1794
01:07:52,050 --> 01:07:54,660
What you're seeing
on the bottom row

1795
01:07:54,660 --> 01:07:56,010
there are the three main

1796
01:07:56,010 --> 01:07:57,480
components to SHARE,

1797
01:07:57,480 --> 01:07:58,560
the first being that

1798
01:07:58,560 --> 01:08:00,315
we've shown that
we can move

1799
01:08:00,315 --> 01:08:02,190
containerization
software from

1800
01:08:02,190 --> 01:08:04,860
the Cloud to
handheld devices.

1801
01:08:04,860 --> 01:08:06,210
Essentially, a secure

1802
01:08:06,210 --> 01:08:08,070
enclaves that are
storing data of

1803
01:08:08,070 --> 01:08:09,630
different sensitivity
with levels

1804
01:08:09,630 --> 01:08:11,550
on a mobile device and

1805
01:08:11,550 --> 01:08:13,710
then we incorporate that

1806
01:08:13,710 --> 01:08:15,135
with MINC data networking,

1807
01:08:15,135 --> 01:08:17,025
where we're
double encrypting

1808
01:08:17,025 --> 01:08:18,720
the data packets and using

1809
01:08:18,720 --> 01:08:20,970
NDN to transfer

1810
01:08:20,970 --> 01:08:22,590
those packets
throughout the network,

1811
01:08:22,590 --> 01:08:23,760
cache the data on

1812
01:08:23,760 --> 01:08:25,380
the end user devices

1813
01:08:25,380 --> 01:08:27,735
and then the
third focus area

1814
01:08:27,735 --> 01:08:29,280
has been all about

1815
01:08:29,280 --> 01:08:31,020
configuration
management and making

1816
01:08:31,020 --> 01:08:34,900
it easy for the war
fighter to use SHARE.

1817
01:08:35,450 --> 01:08:37,350
Again, for this crowd,

1818
01:08:37,350 --> 01:08:38,025
I don't really have to

1819
01:08:38,025 --> 01:08:39,810
dwell on MINC
data networking,

1820
01:08:39,810 --> 01:08:42,090
but I will on this
slide point out that

1821
01:08:42,090 --> 01:08:43,260
SHARE is integrated with

1822
01:08:43,260 --> 01:08:45,075
the Tactical Assault Kit.

1823
01:08:45,075 --> 01:08:47,160
TAK is a common
application that's

1824
01:08:47,160 --> 01:08:49,950
used at the Tactical Edge.

1825
01:08:49,950 --> 01:08:53,010
It's for
exchanging command

1826
01:08:53,010 --> 01:08:54,270
and control and
situational

1827
01:08:54,270 --> 01:08:55,590
awareness applications.

1828
01:08:55,590 --> 01:08:57,450
So you can think of it as

1829
01:08:57,450 --> 01:09:00,180
an application running
on a handheld.

1830
01:09:00,180 --> 01:09:02,100
There's a map interface.

1831
01:09:02,100 --> 01:09:04,965
Users can exchange
chat messages,

1832
01:09:04,965 --> 01:09:06,900
images, other's position,

1833
01:09:06,900 --> 01:09:08,970
location information
displayed on

1834
01:09:08,970 --> 01:09:11,565
the map and traditionally,

1835
01:09:11,565 --> 01:09:13,980
there's a client
server architecture

1836
01:09:13,980 --> 01:09:16,620
within the TAK
ecosystem that SHARE

1837
01:09:16,620 --> 01:09:19,350
integrated with TAK
we move towards

1838
01:09:19,350 --> 01:09:20,400
the MINC data networking

1839
01:09:20,400 --> 01:09:22,560
paradigms and here you'll

1840
01:09:22,560 --> 01:09:24,660
see that data is

1841
01:09:24,660 --> 01:09:27,540
requested based on
interests and the data is

1842
01:09:27,540 --> 01:09:29,730
cached on the
handheld devices and

1843
01:09:29,730 --> 01:09:31,950
at strategic points
on the network and

1844
01:09:31,950 --> 01:09:34,200
those dashed
lines really is

1845
01:09:34,200 --> 01:09:36,630
meant to represent in
a tactical network,

1846
01:09:36,630 --> 01:09:38,340
you have links
coming up and down.

1847
01:09:38,340 --> 01:09:39,825
You have a lot
of mobility.

1848
01:09:39,825 --> 01:09:41,820
Again, you have very
intermittent links

1849
01:09:41,820 --> 01:09:43,260
that will having
the ability to

1850
01:09:43,260 --> 01:09:44,910
cache data on the phone

1851
01:09:44,910 --> 01:09:48,100
is really invaluable
in this setting.

1852
01:09:49,250 --> 01:09:53,100
Another offshoot of the
SHARE work has been

1853
01:09:53,100 --> 01:09:57,420
a collaboration with
another part of

1854
01:09:57,420 --> 01:10:00,930
the DOD and that's
been and are

1855
01:10:00,930 --> 01:10:03,300
marrying up SHARE
capabilities

1856
01:10:03,300 --> 01:10:05,355
with 5G technologies.

1857
01:10:05,355 --> 01:10:07,050
As part of the
SHARE programs,

1858
01:10:07,050 --> 01:10:10,800
we've demonstrated
the secure isolation

1859
01:10:10,800 --> 01:10:13,230
on the phone with
those secure enclaves.

1860
01:10:13,230 --> 01:10:15,120
But then we've also
married it up with

1861
01:10:15,120 --> 01:10:18,375
the network
slicing concept.

1862
01:10:18,375 --> 01:10:20,820
In the figure that
you see here, again,

1863
01:10:20,820 --> 01:10:25,035
you can see those
end user devices

1864
01:10:25,035 --> 01:10:27,390
are viewing with

1865
01:10:27,390 --> 01:10:30,480
the SHARE software
and then further

1866
01:10:30,480 --> 01:10:32,220
isolating data
as it traverses

1867
01:10:32,220 --> 01:10:33,570
the network is
this concept

1868
01:10:33,570 --> 01:10:34,950
of network slicing.

1869
01:10:34,950 --> 01:10:37,140
We have had demonstrations

1870
01:10:37,140 --> 01:10:39,750
showcasing the value of

1871
01:10:39,750 --> 01:10:42,060
MINC data networking with

1872
01:10:42,060 --> 01:10:44,535
the secure slicing and

1873
01:10:44,535 --> 01:10:45,690
that's some
work that we've

1874
01:10:45,690 --> 01:10:49,290
actually wrapped up as

1875
01:10:49,290 --> 01:10:50,970
we actually are wrapping

1876
01:10:50,970 --> 01:10:53,440
up the SHARE program.

1877
01:10:54,800 --> 01:10:58,260
Just to tie a bow on
the SHARE work again,

1878
01:10:58,260 --> 01:10:59,955
as we're wrapping up

1879
01:10:59,955 --> 01:11:01,620
the SHARE phase of
work and moving

1880
01:11:01,620 --> 01:11:04,215
on into my new
program MINC.

1881
01:11:04,215 --> 01:11:06,855
DARPA is transitioning.

1882
01:11:06,855 --> 01:11:08,070
We've been working with

1883
01:11:08,070 --> 01:11:10,350
the 75th Ranger
Regiment and

1884
01:11:10,350 --> 01:11:11,880
parts of the US Army

1885
01:11:11,880 --> 01:11:14,220
on their specific
use cases,

1886
01:11:14,220 --> 01:11:15,750
and we will be
transitioning

1887
01:11:15,750 --> 01:11:19,450
technology to various
elements of the DoD.

1888
01:11:19,450 --> 01:11:20,660
We are continuing

1889
01:11:20,660 --> 01:11:23,075
our conversations
with NIST.

1890
01:11:23,075 --> 01:11:25,200
As a community,

1891
01:11:25,200 --> 01:11:27,615
we're very eager
to stay involved,

1892
01:11:27,615 --> 01:11:30,300
and I think there will
be opportunities as I

1893
01:11:30,300 --> 01:11:32,040
transition to
my MINC program

1894
01:11:32,040 --> 01:11:33,780
to continue that
involvement.

1895
01:11:33,780 --> 01:11:36,190
Let me tell you
about MINC.

1896
01:11:36,440 --> 01:11:39,255
MINC is a newer program.

1897
01:11:39,255 --> 01:11:40,590
It was announced in

1898
01:11:40,590 --> 01:11:42,780
the April timeframe
of this year.

1899
01:11:42,780 --> 01:11:44,925
We have not yet announced

1900
01:11:44,925 --> 01:11:46,920
who has been selected
for the program,

1901
01:11:46,920 --> 01:11:49,995
but looking forward to
announcing that soon.

1902
01:11:49,995 --> 01:11:51,840
MINC stands for mission

1903
01:11:51,840 --> 01:11:53,610
integrated
network control.

1904
01:11:53,610 --> 01:11:56,310
The two main
objectives of MINC is

1905
01:11:56,310 --> 01:11:57,420
to make it easier to

1906
01:11:57,420 --> 01:11:59,070
initially configure
a network,

1907
01:11:59,070 --> 01:12:00,840
but then to
also be able to

1908
01:12:00,840 --> 01:12:03,165
adopt that network
benefit you.

1909
01:12:03,165 --> 01:12:05,580
The networks that I'm
talking about, again,

1910
01:12:05,580 --> 01:12:08,385
are these very
heterogeneous

1911
01:12:08,385 --> 01:12:10,950
tactical networks

1912
01:12:10,950 --> 01:12:12,150
that are composed
of a lot of

1913
01:12:12,150 --> 01:12:13,530
legacy hardware,

1914
01:12:13,530 --> 01:12:16,020
a lot of legacy
tactical radios,

1915
01:12:16,020 --> 01:12:17,550
which make it
a particularly

1916
01:12:17,550 --> 01:12:19,839
challenging problem.

1917
01:12:19,850 --> 01:12:22,650
Again, there's
contrast between

1918
01:12:22,650 --> 01:12:25,035
today and what the
program would provide.

1919
01:12:25,035 --> 01:12:26,715
Today we have very much,

1920
01:12:26,715 --> 01:12:28,020
high load war fighting,

1921
01:12:28,020 --> 01:12:29,955
networking and
security domains,

1922
01:12:29,955 --> 01:12:31,560
and we want to get
to a future where

1923
01:12:31,560 --> 01:12:34,230
we have seamless
connectivity,

1924
01:12:34,230 --> 01:12:36,300
where we can
seamlessly bring up

1925
01:12:36,300 --> 01:12:39,270
a link as we build
effects chains,

1926
01:12:39,270 --> 01:12:40,860
being able to
provide the cons in

1927
01:12:40,860 --> 01:12:43,530
networking for those
effects chain.

1928
01:12:43,530 --> 01:12:45,870
There are really two
key characteristics

1929
01:12:45,870 --> 01:12:47,580
having to do with MINC.

1930
01:12:47,580 --> 01:12:49,590
The first is this
idea of an always

1931
01:12:49,590 --> 01:12:51,795
on secure control overlay.

1932
01:12:51,795 --> 01:12:53,220
The purpose of
that control

1933
01:12:53,220 --> 01:12:54,420
overlay is to be able

1934
01:12:54,420 --> 01:12:56,910
to discover
network resources,

1935
01:12:56,910 --> 01:13:00,195
whether that be CMS,
compute or storage.

1936
01:13:00,195 --> 01:13:02,715
Then the second
characteristic

1937
01:13:02,715 --> 01:13:04,110
is to be able to compose

1938
01:13:04,110 --> 01:13:05,490
these network resources on

1939
01:13:05,490 --> 01:13:08,030
demand into a
network of networks.

1940
01:13:08,030 --> 01:13:09,650
Hopefully you're
already starting

1941
01:13:09,650 --> 01:13:12,155
to visualize this idea of

1942
01:13:12,155 --> 01:13:14,840
a software programmable
software-defined

1943
01:13:14,840 --> 01:13:17,049
networking type
of environments.

1944
01:13:17,049 --> 01:13:20,415
But we're actually
trying to reimagine

1945
01:13:20,415 --> 01:13:24,105
software-defined
networking for the DoD.

1946
01:13:24,105 --> 01:13:25,350
Back to this idea that

1947
01:13:25,350 --> 01:13:27,479
we have heterogeneous
networks

1948
01:13:27,479 --> 01:13:29,940
with legacy equipment in

1949
01:13:29,940 --> 01:13:31,680
contrast to
commercial networks,

1950
01:13:31,680 --> 01:13:33,690
and the software-defined
networking

1951
01:13:33,690 --> 01:13:35,535
paradigm within
commercial networks,

1952
01:13:35,535 --> 01:13:40,110
you could have many
different data plans,

1953
01:13:40,110 --> 01:13:41,670
many different
control planes,

1954
01:13:41,670 --> 01:13:43,560
so we need to be able
to connect those

1955
01:13:43,560 --> 01:13:46,110
together with a secure
control overlay.

1956
01:13:46,110 --> 01:13:48,210
That's really what
the first part

1957
01:13:48,210 --> 01:13:49,680
of MINC is trying
to do with

1958
01:13:49,680 --> 01:13:53,220
the first focus area
MINC is trying to do.

1959
01:13:53,220 --> 01:13:55,140
Of course, give

1960
01:13:55,140 --> 01:13:57,060
an awareness of
network resources,

1961
01:13:57,060 --> 01:13:58,230
so being able to discover

1962
01:13:58,230 --> 01:13:59,730
those network
resources and

1963
01:13:59,730 --> 01:14:01,110
have the means to task

1964
01:14:01,110 --> 01:14:02,910
those network resources,

1965
01:14:02,910 --> 01:14:04,575
that would all come from

1966
01:14:04,575 --> 01:14:06,030
a management plane or

1967
01:14:06,030 --> 01:14:08,610
some orchestration
framework.

1968
01:14:08,610 --> 01:14:10,725
Hopefully, again,

1969
01:14:10,725 --> 01:14:12,630
alluded to software-defined
networking

1970
01:14:12,630 --> 01:14:13,830
before I got to it,

1971
01:14:13,830 --> 01:14:15,675
and now hopefully
you're starting to

1972
01:14:15,675 --> 01:14:18,120
envision an
opportunity for things

1973
01:14:18,120 --> 01:14:20,370
like name data
networking or

1974
01:14:20,370 --> 01:14:21,690
general constructs like

1975
01:14:21,690 --> 01:14:23,730
information-centric
networking.

1976
01:14:23,730 --> 01:14:26,100
The idea with MINC
is that we can

1977
01:14:26,100 --> 01:14:28,830
use information-centric
networking or

1978
01:14:28,830 --> 01:14:30,795
name data networking
specifically

1979
01:14:30,795 --> 01:14:32,430
to be able to compose

1980
01:14:32,430 --> 01:14:34,980
that security control
overlay that rides

1981
01:14:34,980 --> 01:14:36,240
on top of the underlying

1982
01:14:36,240 --> 01:14:37,860
heterogeneous networks.

1983
01:14:37,860 --> 01:14:39,570
Some other concepts
that we're

1984
01:14:39,570 --> 01:14:41,325
bringing in from the
commercial space

1985
01:14:41,325 --> 01:14:44,760
include network function
virtualization,

1986
01:14:44,760 --> 01:14:47,160
which goes hand
in hand with STN,

1987
01:14:47,160 --> 01:14:48,435
and also this idea of

1988
01:14:48,435 --> 01:14:50,775
an intent-driven
networking.

1989
01:14:50,775 --> 01:14:53,535
Within MINC, we
really want to

1990
01:14:53,535 --> 01:14:55,710
reimagine intent-driven
networking

1991
01:14:55,710 --> 01:14:57,585
as mission-driven
networking.

1992
01:14:57,585 --> 01:14:58,920
How can we go from

1993
01:14:58,920 --> 01:15:02,250
mission objectives to
network objectives?

1994
01:15:02,250 --> 01:15:05,385
That then we read
it over as part of

1995
01:15:05,385 --> 01:15:07,560
the management plane or
as part of what we're

1996
01:15:07,560 --> 01:15:08,730
calling distributed
network

1997
01:15:08,730 --> 01:15:10,930
orchestration in MINC.

1998
01:15:11,000 --> 01:15:14,745
In addition to the
secure control overlay,

1999
01:15:14,745 --> 01:15:16,710
I talked a bit about that.

2000
01:15:16,710 --> 01:15:18,420
That's our focus areas 1.

2001
01:15:18,420 --> 01:15:20,310
Now that we have
this ability

2002
01:15:20,310 --> 01:15:23,230
to reprogram in software,

2003
01:15:23,230 --> 01:15:24,680
we have this ability to

2004
01:15:24,680 --> 01:15:27,515
discover resiliently
and reliably

2005
01:15:27,515 --> 01:15:30,425
discover network
resources and

2006
01:15:30,425 --> 01:15:32,510
actually cached data about

2007
01:15:32,510 --> 01:15:33,830
those network
resources and

2008
01:15:33,830 --> 01:15:35,915
their associated
control parameters.

2009
01:15:35,915 --> 01:15:38,210
We now have this
opportunity to

2010
01:15:38,210 --> 01:15:41,045
employ distributed
network orchestration.

2011
01:15:41,045 --> 01:15:42,680
Part of that
distributed network

2012
01:15:42,680 --> 01:15:44,975
orchestration is not only

2013
01:15:44,975 --> 01:15:47,300
configuring the
underlying radios

2014
01:15:47,300 --> 01:15:49,385
that are forming
these networks,

2015
01:15:49,385 --> 01:15:50,899
but then to also

2016
01:15:50,899 --> 01:15:53,090
potentially recommend
movement of

2017
01:15:53,090 --> 01:15:55,160
communications
assets to better

2018
01:15:55,160 --> 01:15:58,915
enable networking
and communications.

2019
01:15:58,915 --> 01:16:01,770
Then another component
of focus area

2020
01:16:01,770 --> 01:16:04,650
2 is not only
managing the network,

2021
01:16:04,650 --> 01:16:07,095
but the data or
information as well.

2022
01:16:07,095 --> 01:16:08,700
In the spirit of network

2023
01:16:08,700 --> 01:16:10,380
function virtualization,

2024
01:16:10,380 --> 01:16:13,185
we're generalizing that
contract to include

2025
01:16:13,185 --> 01:16:17,220
network information and
security management.

2026
01:16:17,220 --> 01:16:19,035
Then of course, I
talked a bit about

2027
01:16:19,035 --> 01:16:20,745
intent-driven networking

2028
01:16:20,745 --> 01:16:22,140
on military missions,

2029
01:16:22,140 --> 01:16:25,365
and that's folded
into focus area 3,

2030
01:16:25,365 --> 01:16:28,020
which will be integrating

2031
01:16:28,020 --> 01:16:30,450
all of this into a system.

2032
01:16:30,450 --> 01:16:32,790
Just a quick time check.

2033
01:16:32,790 --> 01:16:34,635
I just have two
slides left.

2034
01:16:34,635 --> 01:16:37,380
As I mentioned, we

2035
01:16:37,380 --> 01:16:38,400
haven't announced who is

2036
01:16:38,400 --> 01:16:39,900
selected for the
program yet,

2037
01:16:39,900 --> 01:16:41,460
but we will be kicking off

2038
01:16:41,460 --> 01:16:43,245
the program in the
next few months.

2039
01:16:43,245 --> 01:16:44,940
I'm very much
looking forward

2040
01:16:44,940 --> 01:16:46,500
to a year from
now being able to

2041
01:16:46,500 --> 01:16:48,420
report about the progress

2042
01:16:48,420 --> 01:16:49,980
that we've made
in using and

2043
01:16:49,980 --> 01:16:52,290
applying name data
networking concepts

2044
01:16:52,290 --> 01:16:54,990
to forming a secure
control overlay.

2045
01:16:54,990 --> 01:16:56,190
That's what we'll
be building

2046
01:16:56,190 --> 01:16:57,435
out in Phase 1,

2047
01:16:57,435 --> 01:16:59,100
really focusing on

2048
01:16:59,100 --> 01:17:02,145
that secure control
overlay and developing

2049
01:17:02,145 --> 01:17:05,640
a MINC-enabled
Blue Force network

2050
01:17:05,640 --> 01:17:07,860
situational awareness
application.

2051
01:17:07,860 --> 01:17:09,810
As the program progresses,

2052
01:17:09,810 --> 01:17:11,385
we'll be continuing to

2053
01:17:11,385 --> 01:17:13,800
develop out the
algorithms and maturing

2054
01:17:13,800 --> 01:17:15,840
the capabilities
and adding

2055
01:17:15,840 --> 01:17:18,255
more and more
MINC-enabled applications

2056
01:17:18,255 --> 01:17:20,310
as the phases progress.

2057
01:17:20,310 --> 01:17:22,260
Last but not least,

2058
01:17:22,260 --> 01:17:24,240
I talked about
my SHARE slide,

2059
01:17:24,240 --> 01:17:26,010
how we've worked with

2060
01:17:26,010 --> 01:17:27,645
the 75th Ranger Regiment,

2061
01:17:27,645 --> 01:17:29,550
and we want to continue
that momentum in

2062
01:17:29,550 --> 01:17:32,220
the MINC program and
really make MINC

2063
01:17:32,220 --> 01:17:33,750
informed by what
the operator

2064
01:17:33,750 --> 01:17:34,860
is looking for
and to be able

2065
01:17:34,860 --> 01:17:38,295
to fill that need at
the tactical edge.

2066
01:17:38,295 --> 01:17:41,200
Back over to
you, Chandler.

2067
01:17:42,050 --> 01:17:44,355
>> Thank you,
Dr. Schurgot.

2068
01:17:44,355 --> 01:17:46,890
I don't see any questions

2069
01:17:46,890 --> 01:17:49,530
in the chat, but I
have one real quick.

2070
01:17:49,530 --> 01:17:52,140
In terms of lessons
learned from

2071
01:17:52,140 --> 01:17:53,790
the SHARE program and how

2072
01:17:53,790 --> 01:17:56,010
that could be fed back
into their community,

2073
01:17:56,010 --> 01:17:57,615
could you speak
a little bit on

2074
01:17:57,615 --> 01:17:59,625
what was done there.

2075
01:17:59,625 --> 01:18:03,420
>> Sure. We've talked

2076
01:18:03,420 --> 01:18:05,070
about this at other
community meetings,

2077
01:18:05,070 --> 01:18:06,990
but the SHARE performers,

2078
01:18:06,990 --> 01:18:08,850
the actual folks
developing

2079
01:18:08,850 --> 01:18:10,860
the capabilities have made

2080
01:18:10,860 --> 01:18:14,085
some enhancements
and changes

2081
01:18:14,085 --> 01:18:16,230
to the underlying
NDN codebase.

2082
01:18:16,230 --> 01:18:17,550
We have added things

2083
01:18:17,550 --> 01:18:19,770
like persistent
subscriptions,

2084
01:18:19,770 --> 01:18:21,360
which I know is
a little against

2085
01:18:21,360 --> 01:18:23,670
the NDN paradigm,

2086
01:18:23,670 --> 01:18:26,895
a bit controversial
amongst this crowd.

2087
01:18:26,895 --> 01:18:27,870
But we have made

2088
01:18:27,870 --> 01:18:29,700
additional security
improvements and

2089
01:18:29,700 --> 01:18:32,970
the long-term goal
is to be able to get

2090
01:18:32,970 --> 01:18:34,770
the best of breed
solution from

2091
01:18:34,770 --> 01:18:36,960
SHARE and potentially
MINC and really

2092
01:18:36,960 --> 01:18:38,070
contribute that back to

2093
01:18:38,070 --> 01:18:39,465
the community
and work towards

2094
01:18:39,465 --> 01:18:43,050
a more standardized DoD

2095
01:18:43,050 --> 01:18:45,640
and NDN type capability.

2096
01:18:46,760 --> 01:18:50,500
>> That's awesome. Thank
you, Dr. Schurgot.

2097
01:18:52,560 --> 01:18:55,250
to our next speaker.

2098
01:18:55,250 --> 01:18:58,100
Our next talk is by
Mohammed Elbadry.

2099
01:18:58,100 --> 01:19:00,520
It's Towards a Unification

2100
01:19:00,520 --> 01:19:03,890
of Name and Address
Based Communication.

2101
01:19:04,030 --> 01:19:06,920
Let me just read the
bio of Mohammed.

2102
01:19:06,920 --> 01:19:08,855
He is a PhD candidate at

2103
01:19:08,855 --> 01:19:10,220
Computer Engineering
department

2104
01:19:10,220 --> 01:19:11,420
of Stony Brook University.

2105
01:19:11,420 --> 01:19:12,920
His research focuses on

2106
01:19:12,920 --> 01:19:14,300
wireless medium
Access Control

2107
01:19:14,300 --> 01:19:16,625
design. On to you sir.

2108
01:19:16,625 --> 01:19:18,705
>> Thank you very much.

2109
01:19:18,705 --> 01:19:20,555
Let me share my screen.

2110
01:19:20,555 --> 01:19:22,745
Can you see the slides?

2111
01:19:22,745 --> 01:19:26,130
>> I can see it
from my end.

2112
01:19:27,120 --> 01:19:30,345
>> Hi, everyone.
I'll be going over,

2113
01:19:30,345 --> 01:19:31,550
Toward Unification of Name

2114
01:19:31,550 --> 01:19:33,920
and Address Based
Communication.

2115
01:19:33,920 --> 01:19:36,675
The motivation behind
the work is that

2116
01:19:36,675 --> 01:19:38,630
an NFD has been out
for multiple years.

2117
01:19:38,630 --> 01:19:40,100
There is a mature codebase

2118
01:19:40,100 --> 01:19:41,300
right now that's
available that

2119
01:19:41,300 --> 01:19:42,575
anyone can use with

2120
01:19:42,575 --> 01:19:44,000
a lot of features and a

2121
01:19:44,000 --> 01:19:45,800
lot capabilities and
that's with layer.

2122
01:19:45,800 --> 01:19:47,660
However, the industry
hasn't fully

2123
01:19:47,660 --> 01:19:50,270
adopted NFD due
to decades of

2124
01:19:50,270 --> 01:19:52,815
vested interest
in TCP/IP network

2125
01:19:52,815 --> 01:19:54,945
and they've already done

2126
01:19:54,945 --> 01:19:56,150
development and transition

2127
01:19:56,150 --> 01:19:57,965
costs would be a lot.

2128
01:19:57,965 --> 01:20:00,200
What we believe
NFD needs is

2129
01:20:00,200 --> 01:20:01,780
a success story
where address-based

2130
01:20:01,780 --> 01:20:05,390
[inaudible] pretty much
not out of the park;

2131
01:20:05,390 --> 01:20:06,950
there is no competition
or a chance

2132
01:20:06,950 --> 01:20:09,495
for address-based stack
to compete at all.

2133
01:20:09,495 --> 01:20:11,135
For us to do that,

2134
01:20:11,135 --> 01:20:14,210
we looked at where
name-based can excel.

2135
01:20:14,210 --> 01:20:16,145
One of the fields that

2136
01:20:16,145 --> 01:20:18,230
in industry is
starting to form but

2137
01:20:18,230 --> 01:20:20,130
hasn't fully
developed yet is

2138
01:20:20,130 --> 01:20:22,415
basically decentralized
wild edges.

2139
01:20:22,415 --> 01:20:23,720
A lot of other presenters

2140
01:20:23,720 --> 01:20:26,225
before me also covered.

2141
01:20:26,225 --> 01:20:28,490
The reasons are
standard procedures

2142
01:20:28,490 --> 01:20:30,020
are still in the
formation process.

2143
01:20:30,020 --> 01:20:31,755
There is not a well-known

2144
01:20:31,755 --> 01:20:33,740
tested procedure on
how to do things or

2145
01:20:33,740 --> 01:20:36,290
not well known address-based
libraries that

2146
01:20:36,290 --> 01:20:37,650
people can just go to

2147
01:20:37,650 --> 01:20:39,335
and that solves
their problem,

2148
01:20:39,335 --> 01:20:41,030
articles, or salesforce.

2149
01:20:41,030 --> 01:20:42,675
An edge name-based

2150
01:20:42,675 --> 01:20:44,265
multicast
dissemination also

2151
01:20:44,265 --> 01:20:45,769
needed one to many
communication

2152
01:20:45,769 --> 01:20:47,480
is a problem on the edge.

2153
01:20:47,480 --> 01:20:49,670
That address-based
communication hasn't

2154
01:20:49,670 --> 01:20:51,195
really provided
a solution for

2155
01:20:51,195 --> 01:20:52,490
just due to the
nature also

2156
01:20:52,490 --> 01:20:55,650
limitations of address-based
communication.

2157
01:20:55,930 --> 01:20:57,980
Essentially, we have

2158
01:20:57,980 --> 01:20:59,750
address-based
communication where

2159
01:20:59,750 --> 01:21:01,190
the industry
is and we have

2160
01:21:01,190 --> 01:21:02,900
the name-based
communication,

2161
01:21:02,900 --> 01:21:03,950
which is essentially

2162
01:21:03,950 --> 01:21:05,450
our goal to transition to

2163
01:21:05,450 --> 01:21:08,755
and what we need is
essentially a bridge.

2164
01:21:08,755 --> 01:21:11,265
How do we get
industry there.

2165
01:21:11,265 --> 01:21:13,570
I heard earlier that there

2166
01:21:13,570 --> 01:21:15,500
was a conversation,
debate,

2167
01:21:15,500 --> 01:21:18,300
discussion between
multiple libraries

2168
01:21:18,300 --> 01:21:19,950
or one big library in

2169
01:21:19,950 --> 01:21:23,810
favor of a small
TCP/IP library

2170
01:21:23,810 --> 01:21:25,730
was tweaking
name-based services.

2171
01:21:25,730 --> 01:21:28,010
The idea of it
is to introduce

2172
01:21:28,010 --> 01:21:31,095
industry people who
are using pretty much

2173
01:21:31,095 --> 01:21:33,260
TCP/IP stack and
address-based communication

2174
01:21:33,260 --> 01:21:35,675
to name-based communication
in the benefits

2175
01:21:35,675 --> 01:21:37,515
of name-based
communication without

2176
01:21:37,515 --> 01:21:39,260
transitioning everything
so that way it

2177
01:21:39,260 --> 01:21:41,225
gets small services
that name-based

2178
01:21:41,225 --> 01:21:43,185
excels over

2179
01:21:43,185 --> 01:21:45,690
address-based
communication easily.

2180
01:21:45,690 --> 01:21:47,740
A simple API would be

2181
01:21:47,740 --> 01:21:50,030
data multicast
dissemination on the edge.

2182
01:21:50,030 --> 01:21:51,830
Right now, data
dissemination on

2183
01:21:51,830 --> 01:21:54,195
the edge specifically
when it's wireless,

2184
01:21:54,195 --> 01:21:56,315
edge communication,
edge to edge,

2185
01:21:56,315 --> 01:21:58,760
there is no good
system side broadcast

2186
01:21:58,760 --> 01:22:00,080
which is not reliable.

2187
01:22:00,080 --> 01:22:03,195
But if there's an API
similar to the sample,

2188
01:22:03,195 --> 01:22:04,610
which just takes the file

2189
01:22:04,610 --> 01:22:05,645
and handles of course,

2190
01:22:05,645 --> 01:22:08,420
all the assembly
and fragmentation,

2191
01:22:08,420 --> 01:22:10,670
developers would
be up to try

2192
01:22:10,670 --> 01:22:12,160
it at least to see
how it goes and

2193
01:22:12,160 --> 01:22:13,850
how it works and without

2194
01:22:13,850 --> 01:22:14,960
changing all those other

2195
01:22:14,960 --> 01:22:16,625
communication and
transitioning.

2196
01:22:16,625 --> 01:22:18,110
The other thing I
want to cover is,

2197
01:22:18,110 --> 01:22:20,390
instead of looking
at name-based stack,

2198
01:22:20,390 --> 01:22:21,740
I want to consider looking

2199
01:22:21,740 --> 01:22:23,030
at a unified paradigm.

2200
01:22:23,030 --> 01:22:24,854
What I mean by
unifying paradigm

2201
01:22:24,854 --> 01:22:29,045
is address-based and
name-based in one.

2202
01:22:29,045 --> 01:22:31,280
The reason why we
started looking

2203
01:22:31,280 --> 01:22:32,750
at unified paradigm
instead of

2204
01:22:32,750 --> 01:22:34,760
name-based is that
because Access Control

2205
01:22:34,760 --> 01:22:35,420
on the edge is

2206
01:22:35,420 --> 01:22:36,980
pretty much
transmitter initiates.

2207
01:22:36,980 --> 01:22:38,760
So you need to
communicate to someone;

2208
01:22:38,760 --> 01:22:40,365
you send an ID and

2209
01:22:40,365 --> 01:22:42,445
you send data to
the Access Control.

2210
01:22:42,445 --> 01:22:44,240
There's other use
case which we're

2211
01:22:44,240 --> 01:22:45,635
very familiar with,

2212
01:22:45,635 --> 01:22:47,150
which is applications

2213
01:22:47,150 --> 01:22:48,440
are multicasting
data driven.

2214
01:22:48,440 --> 01:22:49,695
So receiver initiates and

2215
01:22:49,695 --> 01:22:50,510
that's where name-based,

2216
01:22:50,510 --> 01:22:53,135
you subscribe to data
and you get data.

2217
01:22:53,135 --> 01:22:55,670
Now these two, one
is transmitter

2218
01:22:55,670 --> 01:22:56,720
initiated and other one

2219
01:22:56,720 --> 01:22:58,085
is receiver initiated,

2220
01:22:58,085 --> 01:22:59,420
one is address-based
and one

2221
01:22:59,420 --> 01:23:01,400
is pretty much
data-driven.

2222
01:23:01,400 --> 01:23:03,770
We started looking
at MAC layer,

2223
01:23:03,770 --> 01:23:05,450
this is purely MAC layer

2224
01:23:05,450 --> 01:23:06,980
medium Access
Control and we start

2225
01:23:06,980 --> 01:23:08,740
looking at Unified
paradigm MAC layer

2226
01:23:08,740 --> 01:23:10,875
and looked at
algorithms that exist

2227
01:23:10,875 --> 01:23:12,195
that MAC layer needs

2228
01:23:12,195 --> 01:23:14,060
to pretty much
operate and do.

2229
01:23:14,060 --> 01:23:16,590
Rate control algorithms
and reliability,

2230
01:23:16,590 --> 01:23:18,170
beamforming, frame
aggregation,

2231
01:23:18,170 --> 01:23:19,265
and a lot more.

2232
01:23:19,265 --> 01:23:20,750
But we started focusing

2233
01:23:20,750 --> 01:23:21,950
on these and we
started building

2234
01:23:21,950 --> 01:23:24,350
a small layer called
algorithm adaptation

2235
01:23:24,350 --> 01:23:25,875
layer and we connected

2236
01:23:25,875 --> 01:23:27,785
all of these
algorithms too.

2237
01:23:27,785 --> 01:23:29,300
We started saying, can we

2238
01:23:29,300 --> 01:23:30,380
apply the same algorithm

2239
01:23:30,380 --> 01:23:32,630
with the smaller
adaptive layer so

2240
01:23:32,630 --> 01:23:35,045
we can deploy the
same algorithm

2241
01:23:35,045 --> 01:23:37,485
on name-based and
address-based?

2242
01:23:37,485 --> 01:23:39,030
We're actually able to

2243
01:23:39,030 --> 01:23:41,090
demonstrate a little
bit right now.

2244
01:23:41,090 --> 01:23:43,040
We took one of the
examples which is

2245
01:23:43,040 --> 01:23:45,320
rate control
algorithm and we'll

2246
01:23:45,320 --> 01:23:46,490
discuss how we can deploy

2247
01:23:46,490 --> 01:23:48,350
that algorithm same
exact algorithm's

2248
01:23:48,350 --> 01:23:50,325
minor adaptation
from address-based

2249
01:23:50,325 --> 01:23:51,555
to name-based
communication,

2250
01:23:51,555 --> 01:23:52,820
why it's important.

2251
01:23:52,820 --> 01:23:56,690
We cover what is
rate control.

2252
01:23:56,690 --> 01:23:58,220
Imagine you have
two radios,

2253
01:23:58,220 --> 01:23:59,960
Node A and Node B and

2254
01:23:59,960 --> 01:24:01,160
Node A is trying
to send data to

2255
01:24:01,160 --> 01:24:04,885
Node B in Wi-Fi or 8211.

2256
01:24:04,885 --> 01:24:06,590
What data rate
to transmit at?

2257
01:24:06,590 --> 01:24:07,070
There are a lot of

2258
01:24:07,070 --> 01:24:08,445
data rates that
you can transmit

2259
01:24:08,445 --> 01:24:10,670
that and the selection

2260
01:24:10,670 --> 01:24:12,170
is usually based
on a table.

2261
01:24:12,170 --> 01:24:13,520
You change the modulation,

2262
01:24:13,520 --> 01:24:14,570
you change the code rate,

2263
01:24:14,570 --> 01:24:16,515
the spatial streams,
error coding,

2264
01:24:16,515 --> 01:24:18,815
and then you get
different data rates.

2265
01:24:18,815 --> 01:24:20,510
Usually that change is

2266
01:24:20,510 --> 01:24:21,950
done verifying conditions.

2267
01:24:21,950 --> 01:24:23,210
So you have a
packet, you send

2268
01:24:23,210 --> 01:24:24,650
fragment and its
multiple frames,

2269
01:24:24,650 --> 01:24:26,300
and then you
change it based

2270
01:24:26,300 --> 01:24:27,110
on the medium condition,

2271
01:24:27,110 --> 01:24:28,130
so you change dynamically.

2272
01:24:28,130 --> 01:24:29,655
Sometimes the condition
is very good,

2273
01:24:29,655 --> 01:24:32,330
you transmit at 600
Mbps and then it drops

2274
01:24:32,330 --> 01:24:33,800
down to 15 as

2275
01:24:33,800 --> 01:24:36,170
the connection is
not so good anymore.

2276
01:24:36,170 --> 01:24:38,870
The way it works
is that basically

2277
01:24:38,870 --> 01:24:41,715
Node B before the A
starts to transmit to B,

2278
01:24:41,715 --> 01:24:43,830
it will basically
share supported rates,

2279
01:24:43,830 --> 01:24:49,230
B will say I can receive
some data rates.

2280
01:24:49,230 --> 01:24:51,410
Let's say in this
table we have 1, 6,

2281
01:24:51,410 --> 01:24:53,665
9, 24, 54 Mbps.

2282
01:24:53,665 --> 01:24:55,415
Now, it will start
transmitting.

2283
01:24:55,415 --> 01:24:57,855
What it will do is

2284
01:24:57,855 --> 01:24:59,030
that it will
search for as many

2285
01:24:59,030 --> 01:25:00,530
first frame at
some data rate.

2286
01:25:00,530 --> 01:25:01,640
If it gets
acknowledgement,

2287
01:25:01,640 --> 01:25:03,620
that means it
received it by

2288
01:25:03,620 --> 01:25:08,010
higher data rate for
the lower data rate.

2289
01:25:08,010 --> 01:25:09,620
As a scenario
walks through,

2290
01:25:09,620 --> 01:25:11,235
it's sends at nine Mbps.

2291
01:25:11,235 --> 01:25:12,650
It passes, it goes to

2292
01:25:12,650 --> 01:25:15,240
a higher one which is
pretty much 24 Mbps.

2293
01:25:15,240 --> 01:25:16,605
If it loses it,

2294
01:25:16,605 --> 01:25:17,960
it'll try to retransmit

2295
01:25:17,960 --> 01:25:20,535
the same frame at a
lower data rates.

2296
01:25:20,535 --> 01:25:21,680
If it passes,

2297
01:25:21,680 --> 01:25:23,475
it continues and
then it goes up.

2298
01:25:23,475 --> 01:25:25,370
This is a simple algorithm

2299
01:25:25,370 --> 01:25:26,655
which is essentially
go up or

2300
01:25:26,655 --> 01:25:28,670
down and that's
quite using

2301
01:25:28,670 --> 01:25:31,890
unicast and address-based
communication.

2302
01:25:32,680 --> 01:25:37,025
Now, what about
name-based rate control?

2303
01:25:37,025 --> 01:25:38,450
We don't have
any ID, so we

2304
01:25:38,450 --> 01:25:39,770
don't know who's
A who is B,

2305
01:25:39,770 --> 01:25:42,050
we don't know who
we're sending to.

2306
01:25:42,050 --> 01:25:44,505
We don't know who
the receivers are.

2307
01:25:44,505 --> 01:25:45,845
We don't know if
it's one receiver

2308
01:25:45,845 --> 01:25:47,930
or multiple receivers.

2309
01:25:47,930 --> 01:25:51,170
We could technically
restore rate controls.

2310
01:25:51,170 --> 01:25:52,605
Every time we get
new interests,

2311
01:25:52,605 --> 01:25:55,400
we could restart the
rate control and

2312
01:25:55,400 --> 01:25:56,825
assume it's new number

2313
01:25:56,825 --> 01:25:58,890
of receivers or
set of receivers,

2314
01:25:58,890 --> 01:26:00,200
and start trying to

2315
01:26:00,200 --> 01:26:01,250
find the optimal
data rate.

2316
01:26:01,250 --> 01:26:02,600
The problem is
that the data

2317
01:26:02,600 --> 01:26:04,625
packet is very small.

2318
01:26:04,625 --> 01:26:07,085
That by the time final
optimal data rate,

2319
01:26:07,085 --> 01:26:08,420
we'll have to
restart again

2320
01:26:08,420 --> 01:26:10,910
because the data
packet ended.

2321
01:26:11,080 --> 01:26:13,700
What we ended up doing is

2322
01:26:13,700 --> 01:26:15,349
embed an ID information

2323
01:26:15,349 --> 01:26:16,520
per interest to allow read

2324
01:26:16,520 --> 01:26:18,765
control and we don't
use that for filtering.

2325
01:26:18,765 --> 01:26:20,300
It's still name-based
communication.

2326
01:26:20,300 --> 01:26:21,350
We use ID just

2327
01:26:21,350 --> 01:26:23,355
internally to

2328
01:26:23,355 --> 01:26:25,215
actually recognize
who we're sending to.

2329
01:26:25,215 --> 01:26:26,360
It's basically to identify

2330
01:26:26,360 --> 01:26:28,325
general centric
information.

2331
01:26:28,325 --> 01:26:30,500
What that enabled
us to do is that

2332
01:26:30,500 --> 01:26:32,025
now we can
identify each node

2333
01:26:32,025 --> 01:26:34,100
internally and we
were actually able

2334
01:26:34,100 --> 01:26:36,195
to use the address-based

2335
01:26:36,195 --> 01:26:37,280
read control algorithms

2336
01:26:37,280 --> 01:26:38,330
that have already been

2337
01:26:38,330 --> 01:26:41,060
designed and tested
as a black box.

2338
01:26:41,060 --> 01:26:43,280
Use the ID that
we obtained for

2339
01:26:43,280 --> 01:26:45,170
the packets,
supported rates,

2340
01:26:45,170 --> 01:26:48,230
and history and obtain
a data rate to control

2341
01:26:48,230 --> 01:26:52,265
the data rate for a
name-based communication.

2342
01:26:52,265 --> 01:26:55,730
That way we can send
name-based frames

2343
01:26:55,730 --> 01:26:58,160
with rate control
that's been

2344
01:26:58,160 --> 01:27:00,680
developed for address-based
communication.

2345
01:27:00,680 --> 01:27:02,845
What we obtained
from these results

2346
01:27:02,845 --> 01:27:04,735
is that if we just
use broadcast

2347
01:27:04,735 --> 01:27:05,330
where we use

2348
01:27:05,330 --> 01:27:07,205
name-based communication
without actually

2349
01:27:07,205 --> 01:27:08,630
identifying the
note we are sending

2350
01:27:08,630 --> 01:27:10,280
to and using
great control,

2351
01:27:10,280 --> 01:27:12,210
the latency of 30 seconds

2352
01:27:12,210 --> 01:27:13,990
by the unified
stack transmission,

2353
01:27:13,990 --> 01:27:16,110
we got it down
to 0.9 seconds.

2354
01:27:16,110 --> 01:27:18,680
The loss rate is
12-20 percent,

2355
01:27:18,680 --> 01:27:21,290
which is just broadcast
because we're able

2356
01:27:21,290 --> 01:27:24,015
to leverage the
unicast transmission.

2357
01:27:24,015 --> 01:27:24,920
We have one consumer,

2358
01:27:24,920 --> 01:27:26,090
one producer transmission,

2359
01:27:26,090 --> 01:27:27,780
we're able to get
the loss rate down,

2360
01:27:27,780 --> 01:27:29,175
and we were also
able to get

2361
01:27:29,175 --> 01:27:31,350
the medium utilization
down at the same time.

2362
01:27:31,350 --> 01:27:32,450
One of the main reasons

2363
01:27:32,450 --> 01:27:35,235
is when you're transmitting
at broadcasts,

2364
01:27:35,235 --> 01:27:36,680
you pretty much
transmit at base rate

2365
01:27:36,680 --> 01:27:38,675
one Mbps, six Mbps.

2366
01:27:38,675 --> 01:27:40,550
But when you do
the rate control,

2367
01:27:40,550 --> 01:27:41,990
which means at a
much higher rate,

2368
01:27:41,990 --> 01:27:46,280
65 Mbps and can go
up to 600 Mbps.

2369
01:27:46,840 --> 01:27:49,360
Essentially, rate
control algorithm is

2370
01:27:49,360 --> 01:27:49,910
critical for

2371
01:27:49,910 --> 01:27:51,525
good performance
wireless communication,

2372
01:27:51,525 --> 01:27:54,980
and we need long pretty
much communication

2373
01:27:54,980 --> 01:27:56,900
across multiple
data frames.

2374
01:27:56,900 --> 01:27:58,580
It finds the optimal
rate and doesn't

2375
01:27:58,580 --> 01:28:01,800
restart again or the
overhead is too much.

2376
01:28:01,800 --> 01:28:03,470
We started looking at

2377
01:28:03,470 --> 01:28:05,530
existing access that exist

2378
01:28:05,530 --> 01:28:08,450
in the MAC layer to
form a unified stack.

2379
01:28:08,450 --> 01:28:09,680
What we have is filtering.

2380
01:28:09,680 --> 01:28:11,490
We can do name and
address-based filtering.

2381
01:28:11,490 --> 01:28:12,650
We could do discovery,

2382
01:28:12,650 --> 01:28:13,905
which can be
attribute-based

2383
01:28:13,905 --> 01:28:16,195
discovery for address-based
communication.

2384
01:28:16,195 --> 01:28:18,625
We could do read
control for unicast,

2385
01:28:18,625 --> 01:28:20,870
multicast robustness
protocol designs.

2386
01:28:20,870 --> 01:28:21,605
We also could do

2387
01:28:21,605 --> 01:28:23,480
single consumer
producer selection.

2388
01:28:23,480 --> 01:28:24,400
Frame aggregation.

2389
01:28:24,400 --> 01:28:26,050
This is an address-based
communication,

2390
01:28:26,050 --> 01:28:27,250
and that's basically
you package

2391
01:28:27,250 --> 01:28:28,450
your multiple
frames together to

2392
01:28:28,450 --> 01:28:29,895
form an MPDU,

2393
01:28:29,895 --> 01:28:30,440
and that's where

2394
01:28:30,440 --> 01:28:31,780
higher data rate
transmission is

2395
01:28:31,780 --> 01:28:33,950
absolutely necessary.
Beam forming.

2396
01:28:33,950 --> 01:28:35,740
That's when you have
multiple antennas and

2397
01:28:35,740 --> 01:28:38,030
you want to send in a
specific direction.

2398
01:28:38,030 --> 01:28:40,030
What needs to be
done and still is

2399
01:28:40,030 --> 01:28:41,825
missing is multicast
rate control,

2400
01:28:41,825 --> 01:28:44,695
the multi-consumer
producer selection.

2401
01:28:44,695 --> 01:28:48,080
In short, we provided

2402
01:28:48,080 --> 01:28:50,565
a way to possibility
to attract

2403
01:28:50,565 --> 01:28:52,155
industry professional
by targeting

2404
01:28:52,155 --> 01:28:54,590
edge market and a
specific APIs to just

2405
01:28:54,590 --> 01:28:56,810
provide name-based
services instead

2406
01:28:56,810 --> 01:28:58,970
of the whole stack
to attract people,

2407
01:28:58,970 --> 01:29:01,080
and then eventually moved
to the whole stack.

2408
01:29:01,080 --> 01:29:02,090
Proposal for

2409
01:29:02,090 --> 01:29:03,440
a lightweight
name-based services and

2410
01:29:03,440 --> 01:29:04,790
marketing for low
barrier entry

2411
01:29:04,790 --> 01:29:06,140
and immediate benefit,

2412
01:29:06,140 --> 01:29:08,510
and a unified MAC
that benefits

2413
01:29:08,510 --> 01:29:11,010
both name and address-based
communication.

2414
01:29:11,010 --> 01:29:12,740
Thank you.

2415
01:29:17,270 --> 01:29:22,035
>> Thank you. I have a
question, real quick.

2416
01:29:22,035 --> 01:29:25,740
It is, did you
evaluate this

2417
01:29:25,740 --> 01:29:27,510
more or less
qualitatively or you

2418
01:29:27,510 --> 01:29:28,425
actually end up trying to

2419
01:29:28,425 --> 01:29:30,045
prototype any piece of it.

2420
01:29:30,045 --> 01:29:32,340
>> We did actually
prototypes.

2421
01:29:32,340 --> 01:29:35,565
The slide that had the
latency lost trait

2422
01:29:35,565 --> 01:29:37,170
and medium utilization and

2423
01:29:37,170 --> 01:29:38,010
policies were actually

2424
01:29:38,010 --> 01:29:39,330
obtained from real system.

2425
01:29:39,330 --> 01:29:40,680
We build a system on

2426
01:29:40,680 --> 01:29:43,215
a Raspberry Pi and
was an alpha jungle,

2427
01:29:43,215 --> 01:29:45,765
and you modify the
firmware and the kernel,

2428
01:29:45,765 --> 01:29:47,970
remove the existing
address space stack

2429
01:29:47,970 --> 01:29:50,085
and then actually
performed the experiments.

2430
01:29:50,085 --> 01:29:53,415
>> That's very
cool. All right,

2431
01:29:53,415 --> 01:29:55,485
sounds good. Thank
you so much.

2432
01:29:55,485 --> 01:29:57,220
>> Thank you.

2433
01:29:58,760 --> 01:30:02,235
>> Our final speaker.

2434
01:30:02,235 --> 01:30:08,775
This is POC followed
by, I believe a demo.

2435
01:30:08,775 --> 01:30:13,350
The POC is NEAR
platform supporting

2436
01:30:13,350 --> 01:30:18,340
augmented reality over
NDN by Jinghao Zhao.

2437
01:30:18,350 --> 01:30:23,070
He is a fourth year
PhD student at UCLA.

2438
01:30:23,070 --> 01:30:24,720
Research interests include

2439
01:30:24,720 --> 01:30:25,950
mobile edge systems,

2440
01:30:25,950 --> 01:30:28,560
wireless networks,
and mobile security.

2441
01:30:28,560 --> 01:30:31,050
Onto you, I think you

2442
01:30:31,050 --> 01:30:33,555
have a demo;
is that right?

2443
01:30:33,555 --> 01:30:35,340
>> Yes.

2444
01:30:35,340 --> 01:30:37,090
>> All right.

2445
01:30:38,510 --> 01:30:40,980
>> Let me share my screen

2446
01:30:40,980 --> 01:30:48,210
[OVERLAPPING] right now.

2447
01:30:48,210 --> 01:30:51,660
>> I think you
are [inaudible].

2448
01:30:51,660 --> 01:30:53,550
>> Yeah. Everyone,

2449
01:30:53,550 --> 01:30:55,470
I'm glad to introduce

2450
01:30:55,470 --> 01:30:59,280
our latest work and I
am Jinghao from UCLA.

2451
01:30:59,280 --> 01:31:01,050
Today I'm going
to introduce

2452
01:31:01,050 --> 01:31:02,985
the NEAR platforms
NDN wireless,

2453
01:31:02,985 --> 01:31:05,830
AR Platforms to you.

2454
01:31:06,020 --> 01:31:08,730
Keeping the
requirements of

2455
01:31:08,730 --> 01:31:12,000
the high-quality
AR contents and

2456
01:31:12,000 --> 01:31:13,680
the mobile edge computing

2457
01:31:13,680 --> 01:31:14,730
actually provides us in

2458
01:31:14,730 --> 01:31:16,080
new opportunities for it's

2459
01:31:16,080 --> 01:31:18,450
leverage easy
accelerator's,

2460
01:31:18,450 --> 01:31:19,950
storage, and also

2461
01:31:19,950 --> 01:31:21,990
the more management
functions.

2462
01:31:21,990 --> 01:31:24,390
For the January
Edge AR systems,

2463
01:31:24,390 --> 01:31:26,250
which you already
requires first in to

2464
01:31:26,250 --> 01:31:28,245
support virus AR
applications.

2465
01:31:28,245 --> 01:31:29,790
For example, is a merging

2466
01:31:29,790 --> 01:31:31,050
likes a remote training

2467
01:31:31,050 --> 01:31:33,480
the industrial wearables
and also sound

2468
01:31:33,480 --> 01:31:36,825
AR gains assisted
by the Edge Server.

2469
01:31:36,825 --> 01:31:39,000
Also the Edge server
need to handle

2470
01:31:39,000 --> 01:31:41,580
this high dynamic from
this mobile devices

2471
01:31:41,580 --> 01:31:43,260
like the user mobility or

2472
01:31:43,260 --> 01:31:44,745
some workload mobility or

2473
01:31:44,745 --> 01:31:46,020
even network dynamics

2474
01:31:46,020 --> 01:31:47,730
and application
processing.

2475
01:31:47,730 --> 01:31:49,305
Also for that one,

2476
01:31:49,305 --> 01:31:50,910
which the AR requires,

2477
01:31:50,910 --> 01:31:51,930
the Edge Server has

2478
01:31:51,930 --> 01:31:54,510
a very low network
latency and also

2479
01:31:54,510 --> 01:31:56,010
the high bandwidth
to support

2480
01:31:56,010 --> 01:31:59,055
its high-quality
AR contents.

2481
01:31:59,055 --> 01:32:02,280
To harbor for the
current AR systems,

2482
01:32:02,280 --> 01:32:03,690
it's more like
for example,

2483
01:32:03,690 --> 01:32:06,060
it involves crossly or
information slides.

2484
01:32:06,060 --> 01:32:09,105
The application's
needs the cost of

2485
01:32:09,105 --> 01:32:12,720
processing and also for
the network systems,

2486
01:32:12,720 --> 01:32:14,640
it also involves
crossly or likes to

2487
01:32:14,640 --> 01:32:16,770
transport layer and
also the lower layer,

2488
01:32:16,770 --> 01:32:19,020
the physical layer,
even the max needs

2489
01:32:19,020 --> 01:32:20,369
some higher the
information

2490
01:32:20,369 --> 01:32:21,630
for better optimization.

2491
01:32:21,630 --> 01:32:23,295
However, the
current system

2492
01:32:23,295 --> 01:32:25,965
has this multi-layered
indirection cannot,

2493
01:32:25,965 --> 01:32:28,260
more like share
information course

2494
01:32:28,260 --> 01:32:31,440
these contents to the
network and vice versa.

2495
01:32:31,440 --> 01:32:35,010
The second is that the
current limitation is

2496
01:32:35,010 --> 01:32:37,470
the virus applications and

2497
01:32:37,470 --> 01:32:39,810
also the developers
using the same ash,

2498
01:32:39,810 --> 01:32:41,115
you really need to develop

2499
01:32:41,115 --> 01:32:42,720
your own security schemes

2500
01:32:42,720 --> 01:32:44,505
and also the
network stacks,

2501
01:32:44,505 --> 01:32:45,569
different processing

2502
01:32:45,569 --> 01:32:47,415
management, even
a security.

2503
01:32:47,415 --> 01:32:48,840
The way she is
hard to manage

2504
01:32:48,840 --> 01:32:50,220
for this IS system.

2505
01:32:50,220 --> 01:32:52,560
Also we have many
configurations

2506
01:32:52,560 --> 01:32:54,900
for the crossly or
any prone to error.

2507
01:32:54,900 --> 01:32:56,760
The last issue is that

2508
01:32:56,760 --> 01:32:58,290
for the current
AR actually

2509
01:32:58,290 --> 01:32:59,370
still using this unit

2510
01:32:59,370 --> 01:33:01,665
cost-based delivery
as the lower layer.

2511
01:33:01,665 --> 01:33:03,420
That's even a
separate cost

2512
01:33:03,420 --> 01:33:05,100
of wireless
medium is still

2513
01:33:05,100 --> 01:33:06,750
perform this unicast and

2514
01:33:06,750 --> 01:33:08,880
cannot scale to
multiple users.

2515
01:33:08,880 --> 01:33:10,560
Especially for
this narrows,

2516
01:33:10,560 --> 01:33:12,225
who requires massive
connections?

2517
01:33:12,225 --> 01:33:14,100
For example, the
theme park or

2518
01:33:14,100 --> 01:33:16,770
the commencements
narrow in the campus.

2519
01:33:16,770 --> 01:33:19,350
We want to peel
the AR platform

2520
01:33:19,350 --> 01:33:20,820
that supports the
following features.

2521
01:33:20,820 --> 01:33:21,960
The first is that we want

2522
01:33:21,960 --> 01:33:24,150
to elaborate data-centric
transmission

2523
01:33:24,150 --> 01:33:26,460
with the built-in
multicasts support

2524
01:33:26,460 --> 01:33:27,990
to ensure scalability.

2525
01:33:27,990 --> 01:33:30,720
Also we want to integrate
the optimizations

2526
01:33:30,720 --> 01:33:32,280
for different
components and

2527
01:33:32,280 --> 01:33:33,900
to build the system.

2528
01:33:33,900 --> 01:33:36,420
We want to integrate is
in your wireless and

2529
01:33:36,420 --> 01:33:39,105
the widh this crossly
applications,

2530
01:33:39,105 --> 01:33:41,635
accelerations and
securities, et cetera.

2531
01:33:41,635 --> 01:33:43,100
Also we want to provide

2532
01:33:43,100 --> 01:33:45,830
this platform as an open
source platform for

2533
01:33:45,830 --> 01:33:47,810
future developments
and also for

2534
01:33:47,810 --> 01:33:49,100
the performance comparison

2535
01:33:49,100 --> 01:33:50,965
for future new designs.

2536
01:33:50,965 --> 01:33:54,840
Here we introduce our
integration efforts

2537
01:33:54,840 --> 01:33:56,850
as the NEAR platform,

2538
01:33:56,850 --> 01:33:59,680
the NDN wireless
ultimately reality.

2539
01:33:59,680 --> 01:34:01,190
Our platform includes

2540
01:34:01,190 --> 01:34:02,435
the following components.

2541
01:34:02,435 --> 01:34:04,145
The first is
that we support

2542
01:34:04,145 --> 01:34:06,020
different AR modules for

2543
01:34:06,020 --> 01:34:07,865
a virus AR applications.

2544
01:34:07,865 --> 01:34:09,740
Also the network
side that we apply,

2545
01:34:09,740 --> 01:34:11,180
the NDN wireless and with

2546
01:34:11,180 --> 01:34:13,324
the high-performance
link-layer multicast

2547
01:34:13,324 --> 01:34:15,245
as the basically
transmission scheme.

2548
01:34:15,245 --> 01:34:16,985
We also integrated GPU/

2549
01:34:16,985 --> 01:34:18,800
FPGA based accelerators

2550
01:34:18,800 --> 01:34:22,160
into our system and plus
all the AR content.

2551
01:34:22,160 --> 01:34:23,870
Also the
communications are

2552
01:34:23,870 --> 01:34:26,290
using the name-based
security.

2553
01:34:26,290 --> 01:34:28,410
Here is the overview of

2554
01:34:28,410 --> 01:34:30,435
our basic system
structure.

2555
01:34:30,435 --> 01:34:32,220
The near platform
containing

2556
01:34:32,220 --> 01:34:33,434
the following components.

2557
01:34:33,434 --> 01:34:35,820
The first is that for
the producer side,

2558
01:34:35,820 --> 01:34:37,800
we have the
producers to publish

2559
01:34:37,800 --> 01:34:39,450
all the real-time
camera views

2560
01:34:39,450 --> 01:34:41,355
from its mobile cameras.

2561
01:34:41,355 --> 01:34:43,470
All the information was

2562
01:34:43,470 --> 01:34:44,730
the camera frames will

2563
01:34:44,730 --> 01:34:45,930
be retrieved by

2564
01:34:45,930 --> 01:34:48,030
the Edge Server and Edge
Server performance,

2565
01:34:48,030 --> 01:34:49,530
the AR module processing

2566
01:34:49,530 --> 01:34:51,150
and with different tasks.

2567
01:34:51,150 --> 01:34:52,620
Also leveraging

2568
01:34:52,620 --> 01:34:56,430
these accelerations
with GPU/FPGA.

2569
01:34:56,430 --> 01:34:58,260
After the processing
of the AR contents

2570
01:34:58,260 --> 01:35:00,435
will be published through
all the consumers.

2571
01:35:00,435 --> 01:35:02,340
As a consumer
as are sharing

2572
01:35:02,340 --> 01:35:04,500
the same contents
will leveraging

2573
01:35:04,500 --> 01:35:06,420
this link-layer
multicast either access

2574
01:35:06,420 --> 01:35:09,839
points to retrieve
this information

2575
01:35:09,839 --> 01:35:12,600
and all the contents
are also protected by

2576
01:35:12,600 --> 01:35:16,425
the integrated
security with NDN.

2577
01:35:16,425 --> 01:35:18,975
First these ads for,

2578
01:35:18,975 --> 01:35:20,790
I we introduced likes

2579
01:35:20,790 --> 01:35:22,650
the different
overall modules,

2580
01:35:22,650 --> 01:35:24,270
and later I will
introduce more details

2581
01:35:24,270 --> 01:35:26,280
as far as our
NEAR designs.

2582
01:35:26,280 --> 01:35:28,305
First, as far as
the AR Modules,

2583
01:35:28,305 --> 01:35:30,300
we will later show a
demo video to show

2584
01:35:30,300 --> 01:35:32,790
the virus functions
and also how is

2585
01:35:32,790 --> 01:35:34,860
the AR platform leveraging

2586
01:35:34,860 --> 01:35:37,590
that NDN for the processing
and organization.

2587
01:35:37,590 --> 01:35:39,690
Generally, we support
the following modules,

2588
01:35:39,690 --> 01:35:41,460
including the object phase

2589
01:35:41,460 --> 01:35:42,870
and post detection.

2590
01:35:42,870 --> 01:35:44,280
Also we support is

2591
01:35:44,280 --> 01:35:46,980
3D model rendering and
AR video overlay to

2592
01:35:46,980 --> 01:35:48,945
more like party
is this narrows

2593
01:35:48,945 --> 01:35:51,090
for the commercial
product,

2594
01:35:51,090 --> 01:35:53,430
these planing and also
for advertisements.

2595
01:35:53,430 --> 01:35:55,740
We also involves the
multiple producer

2596
01:35:55,740 --> 01:35:57,705
and multiple
consumers scheme,

2597
01:35:57,705 --> 01:35:59,310
like using this
sheer view.

2598
01:35:59,310 --> 01:36:00,630
For example, here in

2599
01:36:00,630 --> 01:36:04,020
this sheer view functions,

2600
01:36:04,020 --> 01:36:06,780
the two producers are

2601
01:36:06,780 --> 01:36:08,160
producing this camera view

2602
01:36:08,160 --> 01:36:09,135
from its own side,

2603
01:36:09,135 --> 01:36:11,310
but it's more like in
a similar location.

2604
01:36:11,310 --> 01:36:14,100
There are some sheered
views inside it.

2605
01:36:14,100 --> 01:36:15,810
As Edge server
will retrieve

2606
01:36:15,810 --> 01:36:18,060
the frames from the
post streams and

2607
01:36:18,060 --> 01:36:19,380
combine them together and

2608
01:36:19,380 --> 01:36:20,850
moldy caused
the streams to

2609
01:36:20,850 --> 01:36:22,260
all the consumers to more

2610
01:36:22,260 --> 01:36:24,750
like provide this
panorama views.

2611
01:36:24,750 --> 01:36:26,940
We also support the
chroma key video

2612
01:36:26,940 --> 01:36:28,980
for the interaxial
opera so that

2613
01:36:28,980 --> 01:36:31,260
the consumers can
more like watch

2614
01:36:31,260 --> 01:36:32,280
this opera ways these

2615
01:36:32,280 --> 01:36:33,840
stages as their
backgrounds,

2616
01:36:33,840 --> 01:36:36,150
which we will
show demos later.

2617
01:36:36,150 --> 01:36:39,735
For all these AR contents

2618
01:36:39,735 --> 01:36:41,835
to ensure the
high-quality performers

2619
01:36:41,835 --> 01:36:43,260
and the way that
a traditional

2620
01:36:43,260 --> 01:36:44,790
2D contents depend why is

2621
01:36:44,790 --> 01:36:48,180
for each contents can
as high as 40 Mbps.

2622
01:36:48,180 --> 01:36:50,775
For the recent likes
the volumetric videos,

2623
01:36:50,775 --> 01:36:53,025
these directly streaming
in the 3D models

2624
01:36:53,025 --> 01:36:55,695
from the edge to
the consumer side.

2625
01:36:55,695 --> 01:36:58,020
All the each
client's needs,

2626
01:36:58,020 --> 01:36:59,700
even nee [MUSIC] ds 100

2627
01:36:59,700 --> 01:37:02,535
Mbps to ensure as
30 FPS playout.

2628
01:37:02,535 --> 01:37:04,905
Power for the current
access points which

2629
01:37:04,905 --> 01:37:07,500
support the smartphones
with a two-by-two MIMO.

2630
01:37:07,500 --> 01:37:09,930
It can only support very

2631
01:37:09,930 --> 01:37:12,435
limited like the
numbers of clients.

2632
01:37:12,435 --> 01:37:13,305
For example,

2633
01:37:13,305 --> 01:37:15,330
for the highest
physical layer rate

2634
01:37:15,330 --> 01:37:16,470
for the 802.11n,

2635
01:37:16,470 --> 01:37:17,700
it can only support

2636
01:37:17,700 --> 01:37:21,645
up to three users to
enjoy this Phy rate AR.

2637
01:37:21,645 --> 01:37:23,370
Even for the latest ax

2638
01:37:23,370 --> 01:37:25,365
it can only
support 12 users.

2639
01:37:25,365 --> 01:37:27,315
Due to the
protocol overhead,

2640
01:37:27,315 --> 01:37:28,650
here we just calculate

2641
01:37:28,650 --> 01:37:30,330
the maximum numbers can be

2642
01:37:30,330 --> 01:37:32,415
scored it's using
this physical rates.

2643
01:37:32,415 --> 01:37:35,190
Part of the protocol
overheard plus the noise

2644
01:37:35,190 --> 01:37:38,130
and also cannot achieve

2645
01:37:38,130 --> 01:37:41,295
the highest rates
when keep running

2646
01:37:41,295 --> 01:37:45,285
this AR functions
due to mobility and

2647
01:37:45,285 --> 01:37:48,705
we need the numbers will
be further reduced.

2648
01:37:48,705 --> 01:37:50,760
Why important questions
is that how we

2649
01:37:50,760 --> 01:37:52,785
can scale our AR supports,

2650
01:37:52,785 --> 01:37:54,165
choose the modules and

2651
01:37:54,165 --> 01:37:55,845
even massive connections,

2652
01:37:55,845 --> 01:37:58,830
promising all
the consumers.

2653
01:37:58,830 --> 01:38:00,630
To appeal this NEAR,

2654
01:38:00,630 --> 01:38:02,400
leverage is the
NDN wireless.

2655
01:38:02,400 --> 01:38:04,560
We want to leverage
the NDN naturally

2656
01:38:04,560 --> 01:38:06,720
supports for the multicast

2657
01:38:06,720 --> 01:38:09,090
and also combining

2658
01:38:09,090 --> 01:38:11,205
this lower layer
wireless technology.

2659
01:38:11,205 --> 01:38:12,900
Power for the
current wireless,

2660
01:38:12,900 --> 01:38:14,220
the link layer
still performs

2661
01:38:14,220 --> 01:38:16,995
the multiple-unicast.

2662
01:38:16,995 --> 01:38:19,800
Device centric
transmission rather

2663
01:38:19,800 --> 01:38:22,335
than the content centric.

2664
01:38:22,335 --> 01:38:25,110
We perform integrate

2665
01:38:25,110 --> 01:38:26,640
the high-performance

2666
01:38:26,640 --> 01:38:28,050
link-layer multicast into

2667
01:38:28,050 --> 01:38:29,490
the near platform to

2668
01:38:29,490 --> 01:38:31,290
elaborate in this
state for data plan of

2669
01:38:31,290 --> 01:38:34,050
NDN through more
automatically groups

2670
01:38:34,050 --> 01:38:35,910
the users with the
same interests.

2671
01:38:35,910 --> 01:38:37,665
Also performed this high

2672
01:38:37,665 --> 01:38:39,465
rate link-layer multicast.

2673
01:38:39,465 --> 01:38:41,865
The physical layer can
achieve as high as

2674
01:38:41,865 --> 01:38:46,365
450 Mbps and the
urinary experiments.

2675
01:38:46,365 --> 01:38:48,120
The peak application
speed can be

2676
01:38:48,120 --> 01:38:51,970
greater than 120 Mbps.

2677
01:38:52,300 --> 01:38:55,035
Furthermore than
the wireless,

2678
01:38:55,035 --> 01:38:58,170
we also integrated the
acceleration modules

2679
01:38:58,170 --> 01:38:59,855
into our NEAR platform.

2680
01:38:59,855 --> 01:39:02,110
We can support
both the GPU

2681
01:39:02,110 --> 01:39:04,635
and FPGA as accelerators.

2682
01:39:04,635 --> 01:39:08,815
All the modules are
supported, for example,

2683
01:39:08,815 --> 01:39:10,495
when you want to leverage

2684
01:39:10,495 --> 01:39:13,350
the FPGA as accelerators,
all the frames,

2685
01:39:13,350 --> 01:39:15,420
the sale and
computations will be

2686
01:39:15,420 --> 01:39:18,075
uploaded through the
FPGA-based accelerator.

2687
01:39:18,075 --> 01:39:20,110
Then after the processing
and the labeling,

2688
01:39:20,110 --> 01:39:21,950
all the contents
will be published by

2689
01:39:21,950 --> 01:39:24,580
the Edge to all
the consumers.

2690
01:39:24,580 --> 01:39:26,990
We also integrated
security into

2691
01:39:26,990 --> 01:39:29,210
the NEAR following the
NDN specifications,

2692
01:39:29,210 --> 01:39:32,230
which including the
consumer authentication

2693
01:39:32,230 --> 01:39:33,830
and also the integrity and

2694
01:39:33,830 --> 01:39:35,715
encryptions for
the AR contents,

2695
01:39:35,715 --> 01:39:38,180
and also we
included the access

2696
01:39:38,180 --> 01:39:41,165
controls with consumers'
certificates,

2697
01:39:41,165 --> 01:39:43,390
basically giving
the benefits

2698
01:39:43,390 --> 01:39:44,690
of the multicast,

2699
01:39:44,690 --> 01:39:47,320
which has scaled through
massive connections.

2700
01:39:47,320 --> 01:39:48,730
However, directly applying

2701
01:39:48,730 --> 01:39:50,620
the multicast
through this Edge AR

2702
01:39:50,620 --> 01:39:53,690
cannot have

2703
01:39:53,690 --> 01:39:56,805
the expected performance
as we saw before.

2704
01:39:56,805 --> 01:39:59,220
We need to tackle
the following issues

2705
01:39:59,220 --> 01:40:00,720
during our requirements.

2706
01:40:00,720 --> 01:40:02,120
The first thing is how we

2707
01:40:02,120 --> 01:40:03,960
can handle the
AR frame loss.

2708
01:40:03,960 --> 01:40:06,405
The second, how we
can fully leverage

2709
01:40:06,405 --> 01:40:08,265
multicasts because
sometimes we

2710
01:40:08,265 --> 01:40:09,905
find the NFET cannot.

2711
01:40:09,905 --> 01:40:11,200
Even as the NFET have

2712
01:40:11,200 --> 01:40:13,010
the schemes for the
interest compression.

2713
01:40:13,010 --> 01:40:14,685
However, it cannot
be leveraged by

2714
01:40:14,685 --> 01:40:16,160
the multiple consumers

2715
01:40:16,160 --> 01:40:17,855
asking for the same data.

2716
01:40:17,855 --> 01:40:21,440
The last issue is
how we design and to

2717
01:40:21,440 --> 01:40:23,700
secure and protags
the AR contents

2718
01:40:23,700 --> 01:40:26,280
for this group
transmission.

2719
01:40:26,280 --> 01:40:28,740
For the first issue,

2720
01:40:28,740 --> 01:40:30,980
first before our design,

2721
01:40:30,980 --> 01:40:32,120
which has the traditional

2722
01:40:32,120 --> 01:40:33,915
like video streaming
namespace,

2723
01:40:33,915 --> 01:40:36,045
which split the
AR contents

2724
01:40:36,045 --> 01:40:37,795
with the I-frame
and P-frame.

2725
01:40:37,795 --> 01:40:39,820
However, we find that
during transmissions,

2726
01:40:39,820 --> 01:40:41,020
the I-frame are already

2727
01:40:41,020 --> 01:40:42,615
frequently lost and cannot

2728
01:40:42,615 --> 01:40:44,385
be received by
the consumer

2729
01:40:44,385 --> 01:40:46,880
and it blocks
the AR playouts.

2730
01:40:48,030 --> 01:40:51,055
High packet loss
rates only happens

2731
01:40:51,055 --> 01:40:54,350
for the I-frames and
P-frames are just fine.

2732
01:40:54,350 --> 01:40:56,960
After thinking
out the reason,

2733
01:40:56,960 --> 01:40:58,180
the root cause is that

2734
01:40:58,180 --> 01:41:00,135
the average
I-frame size is

2735
01:41:00,135 --> 01:41:02,115
much more larger than
the P-frame size,

2736
01:41:02,115 --> 01:41:03,975
and for the average
I-frame size,

2737
01:41:03,975 --> 01:41:05,450
it will have the 100 pace,

2738
01:41:05,450 --> 01:41:06,795
and for the P-frame size,

2739
01:41:06,795 --> 01:41:08,920
the average size
is only 10 pace,

2740
01:41:08,920 --> 01:41:11,480
and given the max
frames only can support

2741
01:41:11,480 --> 01:41:14,045
the 1480 bytes for

2742
01:41:14,045 --> 01:41:15,310
each frame and in

2743
01:41:15,310 --> 01:41:17,755
the payload sites and
for each I-frame,

2744
01:41:17,755 --> 01:41:20,670
it requires 68
frames to transmit.

2745
01:41:20,670 --> 01:41:21,940
However, for the P-frame,

2746
01:41:21,940 --> 01:41:23,795
it only requires
seven frames.

2747
01:41:23,795 --> 01:41:25,505
The multicast has
lower layers,

2748
01:41:25,505 --> 01:41:28,275
doesn't ensure these have

2749
01:41:28,275 --> 01:41:30,935
any retransmission
schemes at lower layers.

2750
01:41:30,935 --> 01:41:33,520
Even when you deploy
the higher layers,

2751
01:41:33,520 --> 01:41:35,695
the application
retransmission schemes,

2752
01:41:35,695 --> 01:41:38,245
I will still
suffer from this.

2753
01:41:38,245 --> 01:41:40,045
Even when only
one frame is

2754
01:41:40,045 --> 01:41:42,095
lost from the 68 frames,

2755
01:41:42,095 --> 01:41:43,450
the total I-frames cannot

2756
01:41:43,450 --> 01:41:45,255
be retransmitted
successfully,

2757
01:41:45,255 --> 01:41:47,085
and even if we have
two transmissions,

2758
01:41:47,085 --> 01:41:48,160
we'll still
suffer from this

2759
01:41:48,160 --> 01:41:50,135
lower layer packet loss.

2760
01:41:50,135 --> 01:41:52,515
It requires a NEAR to have

2761
01:41:52,515 --> 01:41:54,345
this new namespace designs

2762
01:41:54,345 --> 01:41:56,330
to organize this
AR contents.

2763
01:41:56,330 --> 01:41:57,500
To solve this issues,

2764
01:41:57,500 --> 01:42:00,585
we more transfer from
the IP frame like

2765
01:42:00,585 --> 01:42:02,385
this maybe through
this uniform

2766
01:42:02,385 --> 01:42:04,060
last chunk naming.

2767
01:42:04,060 --> 01:42:05,450
We just split the

2768
01:42:05,450 --> 01:42:06,875
AR contents with
this chunk.

2769
01:42:06,875 --> 01:42:08,265
With each chunk, we have

2770
01:42:08,265 --> 01:42:10,600
the uniform content
length and we design

2771
01:42:10,600 --> 01:42:12,980
the following namespace
for both producer

2772
01:42:12,980 --> 01:42:15,700
and also the Edge to
produce AR contents.

2773
01:42:15,700 --> 01:42:16,995
For a producer,

2774
01:42:16,995 --> 01:42:19,735
each producer will have
a unique producer ID.

2775
01:42:19,735 --> 01:42:22,480
Also for the producers

2776
01:42:22,480 --> 01:42:24,400
located in the
same positions,

2777
01:42:24,400 --> 01:42:26,535
they will have
the same group ID

2778
01:42:26,535 --> 01:42:29,075
which is used for
later AR functions.

2779
01:42:29,075 --> 01:42:30,820
In the naming,
we also include

2780
01:42:30,820 --> 01:42:32,510
the qualities, the
chunk numbers,

2781
01:42:32,510 --> 01:42:33,830
and frame types to

2782
01:42:33,830 --> 01:42:35,440
help the applications
to perform

2783
01:42:35,440 --> 01:42:37,900
more like the adaptively
retransmissions

2784
01:42:37,900 --> 01:42:39,285
based on the frame types.

2785
01:42:39,285 --> 01:42:41,450
For the AR contents,
we further add

2786
01:42:41,450 --> 01:42:44,200
the Edge ID and the
AR tasks into it,

2787
01:42:44,200 --> 01:42:47,205
so that consumers
automatically grouped

2788
01:42:47,205 --> 01:42:48,950
by this AR task

2789
01:42:48,950 --> 01:42:51,025
ask for the same
configurations,

2790
01:42:51,025 --> 01:42:52,335
so that it doesn't need

2791
01:42:52,335 --> 01:42:55,155
any extra information
such as signaling.

2792
01:42:55,155 --> 01:42:57,675
Leveraging the naming
information in

2793
01:42:57,675 --> 01:43:00,370
the NEAR can benefit
through two aspects.

2794
01:43:00,370 --> 01:43:02,805
The first thing is
that the namespace

2795
01:43:02,805 --> 01:43:04,940
has simplified the
idea of management.

2796
01:43:04,940 --> 01:43:05,980
For example, we do not

2797
01:43:05,980 --> 01:43:07,740
need any extra signals.

2798
01:43:07,740 --> 01:43:09,200
We're more like embed

2799
01:43:09,200 --> 01:43:10,660
the signaling over data so

2800
01:43:10,660 --> 01:43:14,535
that all the consumers

2801
01:43:14,535 --> 01:43:15,885
share the same task with

2802
01:43:15,885 --> 01:43:17,720
the same
configurations can be

2803
01:43:17,720 --> 01:43:20,090
automatically grouped
by the network and

2804
01:43:20,090 --> 01:43:21,350
doesn't need the
applications

2805
01:43:21,350 --> 01:43:23,100
to handle it anymore.

2806
01:43:23,100 --> 01:43:25,180
The second way
is that also

2807
01:43:25,180 --> 01:43:27,055
the namespace design can

2808
01:43:27,055 --> 01:43:28,905
benefit different
AR tasks.

2809
01:43:28,905 --> 01:43:30,990
For example, in our
Shareview function,

2810
01:43:30,990 --> 01:43:32,620
here we involve
two producers,

2811
01:43:32,620 --> 01:43:34,035
as at in the demo.

2812
01:43:34,035 --> 01:43:36,240
The first producer and
second producer will

2813
01:43:36,240 --> 01:43:38,605
be as the Edge will
retrieve its own views.

2814
01:43:38,605 --> 01:43:40,730
Here we have two
separate views

2815
01:43:40,730 --> 01:43:42,240
and then the Edge needs to

2816
01:43:42,240 --> 01:43:43,895
combine them
together and only

2817
01:43:43,895 --> 01:43:45,940
combines the views
in the same group.

2818
01:43:45,940 --> 01:43:47,925
If we do not have
these namings,

2819
01:43:47,925 --> 01:43:49,180
we need to perform

2820
01:43:49,180 --> 01:43:51,380
this very expensive
serial processing which

2821
01:43:51,380 --> 01:43:54,255
can not support the
real-time AR experience.

2822
01:43:54,255 --> 01:43:56,560
Give this AR grouping

2823
01:43:56,560 --> 01:43:58,245
information
inside the NEAR,

2824
01:43:58,245 --> 01:43:59,620
the Edge Server
can directly

2825
01:43:59,620 --> 01:44:00,975
apply the aggregations

2826
01:44:00,975 --> 01:44:02,270
and the clustering based

2827
01:44:02,270 --> 01:44:03,770
on the namimg information.

2828
01:44:03,770 --> 01:44:06,295
Then after you cluster
these group of frames,

2829
01:44:06,295 --> 01:44:09,360
you can apply this
feature point extraction

2830
01:44:09,360 --> 01:44:10,965
and transformation
to combine

2831
01:44:10,965 --> 01:44:12,675
the two views
together and publish

2832
01:44:12,675 --> 01:44:14,270
this whole
panorama view and

2833
01:44:14,270 --> 01:44:16,940
publish to all consumers.

2834
01:44:17,140 --> 01:44:19,580
The second issue we

2835
01:44:19,580 --> 01:44:21,675
faced is that we find that

2836
01:44:21,675 --> 01:44:24,400
the interest
compression actually

2837
01:44:24,400 --> 01:44:27,505
is frequently missed in
the real experiments.

2838
01:44:27,505 --> 01:44:30,705
Even the NFD will compress
the interest when

2839
01:44:30,705 --> 01:44:32,385
needs that have
the same interests

2840
01:44:32,385 --> 01:44:33,835
extended by the consumer.

2841
01:44:33,835 --> 01:44:35,530
However, if the consumers

2842
01:44:35,530 --> 01:44:36,770
are now synchronized and

2843
01:44:36,770 --> 01:44:38,150
this one where you're
already frequently

2844
01:44:38,150 --> 01:44:39,505
missed, for example,

2845
01:44:39,505 --> 01:44:41,780
the consumer A may ask
for the latest chunk,

2846
01:44:41,780 --> 01:44:44,950
the chunk 1 to the
Edge and the Edge have

2847
01:44:44,950 --> 01:44:47,150
the chunk 1 so
it immediately

2848
01:44:47,150 --> 01:44:48,920
respond with the
chunk 1 data.

2849
01:44:48,920 --> 01:44:50,435
However, just maybe after

2850
01:44:50,435 --> 01:44:51,850
even several milliseconds,

2851
01:44:51,850 --> 01:44:53,780
the consumer B
sends his chunks

2852
01:44:53,780 --> 01:44:56,425
wants interests and
ask for the chunk 1,

2853
01:44:56,425 --> 01:44:58,005
even as they
keep requesting

2854
01:44:58,005 --> 01:45:00,470
the same chunks round

2855
01:45:00,470 --> 01:45:02,100
by round and with
more consumers.

2856
01:45:02,100 --> 01:45:05,690
However, the address
will just more

2857
01:45:05,690 --> 01:45:07,930
extend this chunk
1 multiple times

2858
01:45:07,930 --> 01:45:09,960
rather than the
multicast ones.

2859
01:45:09,960 --> 01:45:12,600
To solve these issues

2860
01:45:12,600 --> 01:45:14,740
which blows in NEAR with

2861
01:45:14,740 --> 01:45:16,680
these chunk
prefetching schemes,

2862
01:45:16,680 --> 01:45:18,230
before it's retrieving

2863
01:45:18,230 --> 01:45:19,660
the actual AR contents,

2864
01:45:19,660 --> 01:45:21,545
what it will do
is that it will

2865
01:45:21,545 --> 01:45:23,770
first send this
metadata interests to

2866
01:45:23,770 --> 01:45:25,875
retrieve the latest
chunk numbers from

2867
01:45:25,875 --> 01:45:27,430
the Edge plus other

2868
01:45:27,430 --> 01:45:29,380
maybe the stream
informations.

2869
01:45:29,380 --> 01:45:32,425
Also, after it got
the latest chunks,

2870
01:45:32,425 --> 01:45:34,725
what the consumers
will do is that

2871
01:45:34,725 --> 01:45:37,040
it not only sends
this interests

2872
01:45:37,040 --> 01:45:39,160
to reassure the latest
chunk but retrieves

2873
01:45:39,160 --> 01:45:40,730
future chunks and also

2874
01:45:40,730 --> 01:45:43,005
maintains the outstanding
interest window.

2875
01:45:43,005 --> 01:45:44,895
For example, in this demo,

2876
01:45:44,895 --> 01:45:45,770
we showed as it

2877
01:45:45,770 --> 01:45:47,475
was maintaining
the window size

2878
01:45:47,475 --> 01:45:50,145
30 and after it's got
this chunk number 1,

2879
01:45:50,145 --> 01:45:51,390
the latest chance number,

2880
01:45:51,390 --> 01:45:53,320
it will send the
interest to retrieve

2881
01:45:53,320 --> 01:45:55,590
the future 11-40 chunks

2882
01:45:55,590 --> 01:45:57,700
and directly send
all the interests

2883
01:45:57,700 --> 01:45:59,110
to the Edge Server.

2884
01:45:59,110 --> 01:46:00,850
Whenever in the
future that chunks

2885
01:46:00,850 --> 01:46:03,080
11 is produced,
for example,

2886
01:46:03,080 --> 01:46:05,070
by the AR processing

2887
01:46:05,070 --> 01:46:06,610
then the chunky 11 can be

2888
01:46:06,610 --> 01:46:08,895
directly multicast
to all the consumers

2889
01:46:08,895 --> 01:46:11,695
without the multiple
transmissions.

2890
01:46:11,695 --> 01:46:14,525
Then after the
consumers, for example,

2891
01:46:14,525 --> 01:46:16,305
A and B receive this data

2892
01:46:16,305 --> 01:46:17,860
and you can
send this chunk

2893
01:46:17,860 --> 01:46:19,760
41 to move this window

2894
01:46:19,760 --> 01:46:22,545
forward and send
new interest.

2895
01:46:22,545 --> 01:46:24,555
This one is more like,

2896
01:46:24,555 --> 01:46:25,760
we do not need

2897
01:46:25,760 --> 01:46:27,920
a very strict
synchronizations between

2898
01:46:27,920 --> 01:46:30,225
all the consumers
and we can enjoy

2899
01:46:30,225 --> 01:46:31,685
this multicast benefits

2900
01:46:31,685 --> 01:46:33,315
for most of the cases.

2901
01:46:33,315 --> 01:46:35,240
We also deploy this

2902
01:46:35,240 --> 01:46:37,305
application
retransmissions.

2903
01:46:37,305 --> 01:46:39,910
Even for the application
retransmissions,

2904
01:46:39,910 --> 01:46:42,160
we are all using the
multicast because

2905
01:46:42,160 --> 01:46:43,430
the lower layers may miss

2906
01:46:43,430 --> 01:46:44,770
the similar packet loss at

2907
01:46:44,770 --> 01:46:45,860
the lower layer and

2908
01:46:45,860 --> 01:46:47,220
also the
retransmissions can

2909
01:46:47,220 --> 01:46:50,610
also benefit multiple
users packet loss.

2910
01:46:50,610 --> 01:46:53,530
Last issue we'll
tackle is how

2911
01:46:53,530 --> 01:46:56,010
we ensure the AR
content security.

2912
01:46:56,010 --> 01:46:58,270
Integrate this
security into the NEAR

2913
01:46:58,270 --> 01:47:00,280
following the NDN
specifications and

2914
01:47:00,280 --> 01:47:02,085
all the data contents
from both sides

2915
01:47:02,085 --> 01:47:03,345
like the mobile to Server

2916
01:47:03,345 --> 01:47:04,360
and also the Edge Server

2917
01:47:04,360 --> 01:47:05,805
to mobile are signed with

2918
01:47:05,805 --> 01:47:08,715
the producer's
certificates

2919
01:47:08,715 --> 01:47:11,880
using this RSA signature.

2920
01:47:11,880 --> 01:47:16,060
This ensures that the
packets are produced by

2921
01:47:16,060 --> 01:47:18,100
the valid producers and

2922
01:47:18,100 --> 01:47:19,995
also after
receiving the data,

2923
01:47:19,995 --> 01:47:22,220
the consumers will
check the certificates

2924
01:47:22,220 --> 01:47:24,645
whether corresponding
keys are

2925
01:47:24,645 --> 01:47:27,160
in the local key cache.

2926
01:47:27,160 --> 01:47:28,550
If it doesn't zero, it

2927
01:47:28,550 --> 01:47:29,960
will go to the
KeyLocator to

2928
01:47:29,960 --> 01:47:31,005
fetch the keys to

2929
01:47:31,005 --> 01:47:33,845
validate the
data's integrity.

2930
01:47:33,845 --> 01:47:37,310
To ensure the
security furthermore,

2931
01:47:37,310 --> 01:47:39,015
we act the encryption and

2932
01:47:39,015 --> 01:47:41,400
access controls for
the AR contents.

2933
01:47:41,400 --> 01:47:42,740
For all the traffic

2934
01:47:42,740 --> 01:47:44,090
from the producer to Edge,

2935
01:47:44,090 --> 01:47:45,190
we encrypt the data

2936
01:47:45,190 --> 01:47:47,160
with pre-shared
content keys.

2937
01:47:47,160 --> 01:47:49,265
For the Edge to consumers,

2938
01:47:49,265 --> 01:47:50,750
we perform this two-stage

2939
01:47:50,750 --> 01:47:52,760
like the content
encryption,

2940
01:47:52,760 --> 01:47:55,280
learn from the NDN-NAC.

2941
01:47:55,860 --> 01:47:59,605
The two-stage
means that first,

2942
01:47:59,605 --> 01:48:02,450
the consumers will
send the interest to

2943
01:48:02,450 --> 01:48:04,060
retrieve this content keys

2944
01:48:04,060 --> 01:48:05,510
and also in the interest,

2945
01:48:05,510 --> 01:48:07,710
we will include
the consumer's ID

2946
01:48:07,710 --> 01:48:09,370
with these public keys.

2947
01:48:09,370 --> 01:48:12,140
The Edge Servers
can check whether

2948
01:48:12,140 --> 01:48:14,060
these IDs and public keys

2949
01:48:14,060 --> 01:48:15,795
are in this access
control list.

2950
01:48:15,795 --> 01:48:17,390
If it's allowed to access

2951
01:48:17,390 --> 01:48:18,870
this specific task,

2952
01:48:18,870 --> 01:48:21,665
the corresponding content
key for this task

2953
01:48:21,665 --> 01:48:24,735
will be sent to the
mobile consumer.

2954
01:48:24,735 --> 01:48:26,145
Then the mobile consumer

2955
01:48:26,145 --> 01:48:27,375
would pick like this.

2956
01:48:27,375 --> 01:48:29,230
This key will also
be encrypted with

2957
01:48:29,230 --> 01:48:31,875
the public key shared
by this consumer and

2958
01:48:31,875 --> 01:48:33,600
later the consumer
can extract

2959
01:48:33,600 --> 01:48:36,280
this content key with
his private key and

2960
01:48:36,280 --> 01:48:38,510
uses this content
key to decode

2961
01:48:38,510 --> 01:48:40,040
all the group content like

2962
01:48:40,040 --> 01:48:43,515
the AR contents in
this specific AR task.

2963
01:48:43,515 --> 01:48:45,685
All the content
keys we also

2964
01:48:45,685 --> 01:48:47,780
update the IV every
time to ensure

2965
01:48:47,780 --> 01:48:49,710
that the packet cannot

2966
01:48:49,710 --> 01:48:53,130
suffer from the
key reuse attack.

2967
01:48:53,570 --> 01:48:56,340
Then we will show
a demo video

2968
01:48:56,340 --> 01:48:57,780
about our platform,

2969
01:48:57,780 --> 01:49:01,080
and in this demo
prototype we use

2970
01:49:01,080 --> 01:49:04,050
Ubuntu 18 as
the Edge server

2971
01:49:04,050 --> 01:49:06,990
and with the Intel i7 CPU,

2972
01:49:06,990 --> 01:49:09,570
with the RTX 2080S GPU.

2973
01:49:09,570 --> 01:49:11,160
Also for the
access points,

2974
01:49:11,160 --> 01:49:14,235
we're using two access
points with the N750

2975
01:49:14,235 --> 01:49:17,715
and also the AC
1750 routers,

2976
01:49:17,715 --> 01:49:19,470
which support the
wireless with

2977
01:49:19,470 --> 01:49:21,955
the high rate
link-layer multicast.

2978
01:49:21,955 --> 01:49:24,500
Also, we involve
different mobile clients

2979
01:49:24,500 --> 01:49:27,020
as the producer and
also the consumers,

2980
01:49:27,020 --> 01:49:28,955
including the Google
Pixel phones and

2981
01:49:28,955 --> 01:49:30,170
also the Xiaomi phones

2982
01:49:30,170 --> 01:49:32,850
with different
Androids like

2983
01:49:32,850 --> 01:49:34,470
the smartphones
and all things

2984
01:49:34,470 --> 01:49:35,640
are enroute and with

2985
01:49:35,640 --> 01:49:37,275
the commercial
products and

2986
01:49:37,275 --> 01:49:40,150
here is the demo
we want to show.

2987
01:49:40,580 --> 01:49:42,900
First, we show the

2988
01:49:42,900 --> 01:49:46,515
NEAR basic platform
setting and

2989
01:49:46,515 --> 01:49:48,225
the Edge server
is running on

2990
01:49:48,225 --> 01:49:49,980
Ubuntu server and also

2991
01:49:49,980 --> 01:49:51,480
the access point
are connected

2992
01:49:51,480 --> 01:49:53,970
to the servers
through a switch.

2993
01:49:53,970 --> 01:49:55,530
In the NEAR platform,

2994
01:49:55,530 --> 01:49:57,449
the producer
key publishing

2995
01:49:57,449 --> 01:49:59,670
the latest frames from
each camera view.

2996
01:49:59,670 --> 01:50:00,900
For example, here we show

2997
01:50:00,900 --> 01:50:02,880
the producer points
to Street View,

2998
01:50:02,880 --> 01:50:05,220
and the Edge server will

2999
01:50:05,220 --> 01:50:07,875
retrieve the street view
from the producers.

3000
01:50:07,875 --> 01:50:09,540
The Edge server
will process

3001
01:50:09,540 --> 01:50:11,280
the stream with
the Yolo modulus

3002
01:50:11,280 --> 01:50:12,780
and with the accelerators

3003
01:50:12,780 --> 01:50:14,910
to achieve this
real-time processing.

3004
01:50:14,910 --> 01:50:18,030
Also the NEAR support
both the GPUs and

3005
01:50:18,030 --> 01:50:19,440
FPGAs to support

3006
01:50:19,440 --> 01:50:21,615
this Yolo and open post
[inaudible] tasks.

3007
01:50:21,615 --> 01:50:23,265
After the processing,

3008
01:50:23,265 --> 01:50:25,109
the consumers
could retrieve

3009
01:50:25,109 --> 01:50:26,730
the latest AR streams with

3010
01:50:26,730 --> 01:50:28,575
the corresponding
naming and

3011
01:50:28,575 --> 01:50:31,170
according to the
namespace before.

3012
01:50:31,170 --> 01:50:32,730
All the contents will be

3013
01:50:32,730 --> 01:50:34,815
transmitted through the
link-layer multicast.

3014
01:50:34,815 --> 01:50:36,360
As we can see,
all the contents

3015
01:50:36,360 --> 01:50:37,620
only need to transmit once

3016
01:50:37,620 --> 01:50:38,850
and all the consumers can

3017
01:50:38,850 --> 01:50:41,320
receive it at
the same time.

3018
01:50:41,420 --> 01:50:44,820
Then we introduce the
several AR modules

3019
01:50:44,820 --> 01:50:46,545
supported by our platform.

3020
01:50:46,545 --> 01:50:48,240
As we can see, we first

3021
01:50:48,240 --> 01:50:50,190
show that the Edge
can leverage in

3022
01:50:50,190 --> 01:50:52,230
their namings to group
consumers interests

3023
01:50:52,230 --> 01:50:54,690
and performs
corresponding processing.

3024
01:50:54,690 --> 01:50:56,655
By retrieving the latest

3025
01:50:56,655 --> 01:50:59,595
published like the real
time camera stream,

3026
01:50:59,595 --> 01:51:03,120
the Edge perform this
object recognition and

3027
01:51:03,120 --> 01:51:05,130
published real-time
results to

3028
01:51:05,130 --> 01:51:08,290
all the consumers with
link-layer multicast.

3029
01:51:10,190 --> 01:51:13,725
Also, we support the
face detection task.

3030
01:51:13,725 --> 01:51:15,135
Leveraging the face mask

3031
01:51:15,135 --> 01:51:16,515
with the accelerators,

3032
01:51:16,515 --> 01:51:20,085
the Edge servers
can support,

3033
01:51:20,085 --> 01:51:21,600
process multiple faces,

3034
01:51:21,600 --> 01:51:23,790
even hundreds of faces
at the same time,

3035
01:51:23,790 --> 01:51:25,515
and with the
real-time experiment

3036
01:51:25,515 --> 01:51:27,045
supporting the Edge AR.

3037
01:51:27,045 --> 01:51:28,410
As we can see
here in the view,

3038
01:51:28,410 --> 01:51:29,880
we also have a
content like

3039
01:51:29,880 --> 01:51:31,815
the consumers here
and which can

3040
01:51:31,815 --> 01:51:34,740
show that the videos are

3041
01:51:34,740 --> 01:51:36,630
transmitted from
the producer to

3042
01:51:36,630 --> 01:51:39,045
the consumer with the
real-time experiments.

3043
01:51:39,045 --> 01:51:40,950
The OpenPose
module provides

3044
01:51:40,950 --> 01:51:43,275
this jointly detection
of the human body,

3045
01:51:43,275 --> 01:51:45,450
head, and facial
and full key points

3046
01:51:45,450 --> 01:51:46,590
and even further,

3047
01:51:46,590 --> 01:51:48,870
we can include all
this informations

3048
01:51:48,870 --> 01:51:50,475
into the namings so that

3049
01:51:50,475 --> 01:51:51,660
all the consumers can

3050
01:51:51,660 --> 01:51:52,680
retrieve the informations

3051
01:51:52,680 --> 01:51:53,910
they want according

3052
01:51:53,910 --> 01:51:55,785
to the naming information.

3053
01:51:55,785 --> 01:51:58,170
Leveraging the
ADSR with NDI

3054
01:51:58,170 --> 01:52:00,690
the mobile can detect
the human skeletons.

3055
01:52:00,690 --> 01:52:02,714
Here we show
the AR overlays

3056
01:52:02,714 --> 01:52:04,080
and the AR overlay video

3057
01:52:04,080 --> 01:52:07,455
just detects the
markers in the sense,

3058
01:52:07,455 --> 01:52:09,810
and puts videos
as overlay on it.

3059
01:52:09,810 --> 01:52:11,460
This one is
targeted as some

3060
01:52:11,460 --> 01:52:14,010
advertisement scenarios
so that for example,

3061
01:52:14,010 --> 01:52:15,330
the motion can perform

3062
01:52:15,330 --> 01:52:17,310
some AR advertisements

3063
01:52:17,310 --> 01:52:20,010
on the specific products.

3064
01:52:20,010 --> 01:52:22,770
Also we include this
3D model rendering and

3065
01:52:22,770 --> 01:52:24,690
all these 3D models
are rendered

3066
01:52:24,690 --> 01:52:27,135
as the edge adds
server sides.

3067
01:52:27,135 --> 01:52:28,380
For example, after

3068
01:52:28,380 --> 01:52:29,985
recognizing the
market position,

3069
01:52:29,985 --> 01:52:32,550
it can render the
3D models with

3070
01:52:32,550 --> 01:52:34,920
corresponding angles
and the consumers

3071
01:52:34,920 --> 01:52:36,615
can move the
different angles.

3072
01:52:36,615 --> 01:52:38,280
According to the
producer's view,

3073
01:52:38,280 --> 01:52:41,130
it can change in the
different angles to show

3074
01:52:41,130 --> 01:52:42,840
that this 3D products for

3075
01:52:42,840 --> 01:52:44,280
the advertisements
and also

3076
01:52:44,280 --> 01:52:46,740
for future product
displaying.

3077
01:52:46,740 --> 01:52:48,900
For the shareview
function,

3078
01:52:48,900 --> 01:52:50,610
we include
multiple producers

3079
01:52:50,610 --> 01:52:52,575
and multiple consumers.

3080
01:52:52,575 --> 01:52:53,895
For example, here we have

3081
01:52:53,895 --> 01:52:55,860
two producers
inside the view,

3082
01:52:55,860 --> 01:52:57,390
and the server-side,

3083
01:52:57,390 --> 01:52:59,100
we retrieve the views

3084
01:52:59,100 --> 01:53:00,210
from post the left side,

3085
01:53:00,210 --> 01:53:01,470
the left consumer,
and right

3086
01:53:01,470 --> 01:53:04,050
side the right producer.

3087
01:53:04,050 --> 01:53:05,790
After this, grouped by

3088
01:53:05,790 --> 01:53:07,020
this naming and you will

3089
01:53:07,020 --> 01:53:08,730
perform the feature
point extraction

3090
01:53:08,730 --> 01:53:10,695
and combine the two
videos together.

3091
01:53:10,695 --> 01:53:12,390
Then all the shareview

3092
01:53:12,390 --> 01:53:13,890
will be just
published through

3093
01:53:13,890 --> 01:53:15,810
the multicast to
all the consumers

3094
01:53:15,810 --> 01:53:17,550
to have this
multiple producer,

3095
01:53:17,550 --> 01:53:18,900
multiple consumer support

3096
01:53:18,900 --> 01:53:20,640
with real time processing.

3097
01:53:20,640 --> 01:53:23,280
The chroma key video
which is to support

3098
01:53:23,280 --> 01:53:26,070
this processing
from producer,

3099
01:53:26,070 --> 01:53:27,510
we add the chroma keys

3100
01:53:27,510 --> 01:53:28,995
at the Edge server side,

3101
01:53:28,995 --> 01:53:30,990
and then we can locate it

3102
01:53:30,990 --> 01:53:33,390
as the consumer side
on this real objects,

3103
01:53:33,390 --> 01:53:35,460
for example, the
stage to support

3104
01:53:35,460 --> 01:53:39,700
this interactive
operas applications.

3105
01:53:39,710 --> 01:53:43,305
We also compare
the performance

3106
01:53:43,305 --> 01:53:46,260
under the multiple
consumers to test

3107
01:53:46,260 --> 01:53:49,080
the performance of this
link-layer multicast

3108
01:53:49,080 --> 01:53:50,625
and also combining with

3109
01:53:50,625 --> 01:53:52,575
a whole NEAR platform.

3110
01:53:52,575 --> 01:53:54,675
As we can see,
to test this,

3111
01:53:54,675 --> 01:53:55,770
we want to compare the

3112
01:53:55,770 --> 01:53:57,270
performance with the NEAR,

3113
01:53:57,270 --> 01:54:00,405
with the unicast
streaming.

3114
01:54:00,405 --> 01:54:02,280
We using the same videos

3115
01:54:02,280 --> 01:54:03,795
to show the difference.

3116
01:54:03,795 --> 01:54:07,185
Using this video is to
2K source and also we

3117
01:54:07,185 --> 01:54:10,470
have these four consumers
involved in it.

3118
01:54:10,470 --> 01:54:13,230
We have a 60 Mbps
background traffic to

3119
01:54:13,230 --> 01:54:16,155
simulate the very
heavy congestions.

3120
01:54:16,155 --> 01:54:18,120
As we can see, for
the NEAR platform

3121
01:54:18,120 --> 01:54:19,455
can keep publishing

3122
01:54:19,455 --> 01:54:22,410
the 2K sources that
are very fluent

3123
01:54:22,410 --> 01:54:25,500
and with them in here
very high [inaudible].

3124
01:54:25,500 --> 01:54:26,550
For the unicast,

3125
01:54:26,550 --> 01:54:28,155
is suffer from
the congestion

3126
01:54:28,155 --> 01:54:30,210
and sometimes
the resources

3127
01:54:30,210 --> 01:54:32,100
cannot be delivered to

3128
01:54:32,100 --> 01:54:33,270
the consumers on time

3129
01:54:33,270 --> 01:54:34,830
and we're stuck in there.

3130
01:54:34,830 --> 01:54:36,540
Even for these
four consumers

3131
01:54:36,540 --> 01:54:38,385
with heavy backgrounds.

3132
01:54:38,385 --> 01:54:41,445
Until we add more
consumers into it,

3133
01:54:41,445 --> 01:54:45,420
the NEAR will not add
further [inaudible].

3134
01:54:45,420 --> 01:54:47,730
Only some few
extra overheads

3135
01:54:47,730 --> 01:54:49,590
will cost by the
retransmission plus

3136
01:54:49,590 --> 01:54:51,810
a major overhead like
the video transmissions

3137
01:54:51,810 --> 01:54:54,375
because we're using
only multicasts ones

3138
01:54:54,375 --> 01:54:56,820
and doesn't like unicasts

3139
01:54:56,820 --> 01:54:59,820
the scalability is much

3140
01:54:59,820 --> 01:55:02,080
worse than our platform.

3141
01:55:02,720 --> 01:55:07,620
We will release our
closing our websites.

3142
01:55:07,620 --> 01:55:09,810
We are glad to introduce

3143
01:55:09,810 --> 01:55:12,120
our platform
and welcome for

3144
01:55:12,120 --> 01:55:14,700
[inaudible] to
leveraging our platform

3145
01:55:14,700 --> 01:55:17,295
and also we can design
more modules into it.

3146
01:55:17,295 --> 01:55:21,900
Thanks. I'm glad to

3147
01:55:21,900 --> 01:55:24,490
answer any questions
if you have.

3148
01:55:24,680 --> 01:55:27,210
>> This is very cool.

3149
01:55:27,210 --> 01:55:29,940
Thank you. I have
a quick question.

3150
01:55:29,940 --> 01:55:31,769
When you were talking
about the scalability,

3151
01:55:31,769 --> 01:55:34,140
I think you compared
unicast and multicast.

3152
01:55:34,140 --> 01:55:35,640
Is there anything
that also

3153
01:55:35,640 --> 01:55:37,305
looks at the number
of consumers?

3154
01:55:37,305 --> 01:55:37,920
Because I think in

3155
01:55:37,920 --> 01:55:39,405
your slide you
talked about four,

3156
01:55:39,405 --> 01:55:41,040
would this be affected
at all if let's

3157
01:55:41,040 --> 01:55:43,365
say the number of
consumers go up to 20?

3158
01:55:43,365 --> 01:55:47,190
>> Yeah. Due to

3159
01:55:47,190 --> 01:55:48,930
the limitation of
our device numbers,

3160
01:55:48,930 --> 01:55:52,410
we only have six phones

3161
01:55:52,410 --> 01:55:53,700
at most and so that we

3162
01:55:53,700 --> 01:55:55,485
connect all the phones
onto the server,

3163
01:55:55,485 --> 01:55:57,360
and what we see
is that actually,

3164
01:55:57,360 --> 01:55:59,505
the throughput doesn't
increase a lot.

3165
01:55:59,505 --> 01:56:01,560
But doesn't like
the unicast

3166
01:56:01,560 --> 01:56:03,555
when we add six
consumers in there,

3167
01:56:03,555 --> 01:56:05,070
the throughput will be

3168
01:56:05,070 --> 01:56:07,005
six times as the
original one.

3169
01:56:07,005 --> 01:56:09,060
But for our NEAR is
more like maintaining

3170
01:56:09,060 --> 01:56:12,130
a similar throughput
all the time.

3171
01:56:15,020 --> 01:56:17,115
>> Appreciate it.

3172
01:56:17,115 --> 01:56:19,140
>> Thank you.
[OVERLAPPING]

3173
01:56:19,140 --> 01:56:20,655
>> Thank you so much.

3174
01:56:20,655 --> 01:56:21,780
>> Back to you
[inaudible].

3175
01:56:21,780 --> 01:56:27,450
>> Thank you very much,

3176
01:56:27,450 --> 01:56:29,385
Tamer and all
the speakers.

3177
01:56:29,385 --> 01:56:34,060
We are on time for
the 20-minute break.

3178
01:56:34,850 --> 01:56:37,185
It's almost 3:30.

3179
01:56:37,185 --> 01:56:38,880
We will be back
in 20 minutes

3180
01:56:38,880 --> 01:56:42,090
at 3:50, for session 4.

3181
01:56:42,090 --> 01:56:46,000
We'll see you all in
20 minutes. Thanks.